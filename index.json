[{"categories":["kubernetes"],"content":" 本篇讲述 kubernetes 的横向 pod 伸缩(HorizontalPodAutoscaler) 控制器的数据结构，逻辑处理，metrics 计算以及相关细节的源码解读。 ","date":"2022-01-20","objectID":"/posts/hpa-controller/:0:0","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["kubernetes"],"content":"1. 前言 在 k8s 环境内弹性伸缩并不是一个陌生的概念，是一个常见且不难理解的事件。就是根据特定的事件或数据来触发可伸缩资源的伸缩能力。一般有 HPA 和 VPA 两个概念，HPA 全称 Horizontal Pod Autoscaler 即横向 pod 的自动伸缩，VPA 全称 Vertical Pod Autoscaler 即纵向 pod 的自动伸缩。 ","date":"2022-01-20","objectID":"/posts/hpa-controller/:1:0","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["kubernetes"],"content":"1.1. HPA HPA 关注 pod 的数量，根据现有 pod 的数据(cpu, memory)或外部数据(metrics)来计算实际需要的 pod 数量，从而调整 pod 的总数。HPA 操作的对象需要实现 ScaleInterface 。 ScaleInterface // ScaleInterface can fetch and update scales for // resources in a particular namespace which implement // the scale subresource. type ScaleInterface interface { // Get fetches the scale of the given scalable resource. Get(ctx context.Context, resource schema.GroupResource, name string, opts metav1.GetOptions) (*autoscalingapi.Scale, error) // Update updates the scale of the given scalable resource. Update(ctx context.Context, resource schema.GroupResource, scale *autoscalingapi.Scale, opts metav1.UpdateOptions) (*autoscalingapi.Scale, error) // Patch patches the scale of the given scalable resource. Patch(ctx context.Context, gvr schema.GroupVersionResource, name string, pt types.PatchType, data []byte, opts metav1.PatchOptions) (*autoscalingapi.Scale, error) } k8s 原生资源中 HPA 可操作性的对象是以下三个: Deployment ReplicaSet StatefulSet 一般业务场景用 HPA 能满足需求，即业务高峰增加 pod 数更好处理业务，业务低峰降低pod 数节省资源。 ","date":"2022-01-20","objectID":"/posts/hpa-controller/:1:1","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["kubernetes"],"content":"1.2. VPA VPA 关注的是 pod 的资源，根据当前资源利用率等数据为 pod 提供更多的资源（cpu，memory 等）。本人对 VPA 也是表面理解，所以这里不做详细的解读。 VPA 更适合大计算、离线计算、机器学习等场景，需要大量的 CPU，GPU，内存来进行计算。 ","date":"2022-01-20","objectID":"/posts/hpa-controller/:1:2","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["kubernetes"],"content":"2. 基础用法 通过以下命令开启对某个资源的 HPA 能力： ➜ kubectl autoscale (-f FILENAME | TYPE NAME | TYPE/NAME) [--min=MINPODS] --max=MAXPODS [--cpu-percent=CPU] [options] Warning 需要开启 metric server 才能读取到cpu 利用率，默认是不开启的。详情请看官方文档: https://github.com/kubernetes-sigs/metrics-server 实际使用如下： # 对 deployment/klyn-deploy 进行 CPU 监控，超过 10%的平均利用率即进行scale up，最大 3 个 pod 最小 1 个 ➜ kubectl autoscale deployment klyn-deploy --cpu-percent=10 --min=1 --max=3 然后可以通过 describe 命令查看创建后 HPA 的详情： ➜ kubectl describe hpa klyn-deploy Warning: autoscaling/v2beta2 HorizontalPodAutoscaler is deprecated in v1.23+, unavailable in v1.26+ Name: klyn-deploy Namespace: default Labels: \u003cnone\u003e Annotations: \u003cnone\u003e CreationTimestamp: Thu, 20 Jan 2022 11:43:43 +0800 Reference: Deployment/klyn-deploy Metrics: ( current / target ) resource cpu on pods (as a percentage of request): 4% (10m) / 10% # 可以看到已经读到 cpu 数据 Min replicas: 1 Max replicas: 3 Deployment pods: 1 current / 1 desired Conditions: Type Status Reason Message ---- ------ ------ ------- AbleToScale True ReadyForNewScale recommended size matches current size ScalingActive True ValidMetricFound the HPA was able to successfully calculate a replica count from cpu resource utilization (percentage of request) ScalingLimited False DesiredWithinRange the desired count is within the acceptable range Events: \u003cnone\u003e 可以从上述详情看到 HPA 资源的详细信息以及最下面的步骤信息，当进行伸缩时会同步伸缩过程和原因到 Events 字段上。 之后可以通过压测的方式将 cpu 的利用率提升然后可以到 Deployment 的 replicas 数量的提升，并压测结束一段时间(会有冷却时间)后又降到 1 个 replicas. ","date":"2022-01-20","objectID":"/posts/hpa-controller/:2:0","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["kubernetes"],"content":"3. 数据结构 HPA 资源 YAML 结构： apiVersion:autoscaling/v2kind:HorizontalPodAutoscalermetadata:creationTimestamp:\"2022-01-20T03:43:43Z\"name:klyn-deploynamespace:defaultresourceVersion:\"6602029\"uid:385f4234-025b-453d-8270-788f7ce3ced6spec:maxReplicas:3metrics:- resource:name:cputarget:averageUtilization:10type:Utilizationtype:ResourceminReplicas:1scaleTargetRef:apiVersion:apps/v1kind:Deploymentname:klyn-deploystatus:conditions:- lastTransitionTime:\"2022-01-20T03:43:58Z\"message:recommended size matches current sizereason:ReadyForNewScalestatus:\"True\"type:AbleToScale- lastTransitionTime:\"2022-01-20T03:43:58Z\"message:the HPA was able to successfully calculate a replica count from cpu resourceutilization (percentage of request)reason:ValidMetricFoundstatus:\"True\"type:ScalingActive- lastTransitionTime:\"2022-01-20T03:43:58Z\"message:the desired count is within the acceptable rangereason:DesiredWithinRangestatus:\"False\"type:ScalingLimitedcurrentMetrics:- resource:current:averageUtilization:3averageValue:9mname:cputype:ResourcecurrentReplicas:1desiredReplicas:1lastScaleTime:\"2022-01-20T03:51:44Z\" 上面对 HPA 的概念和如何使用有了一定的认知，从这里开始对 HPA Controller 的源码进行解读。 数据结构： // HorizontalController is responsible for the synchronizing HPA objects stored // in the system with the actual deployments/replication controllers they // control. type HorizontalController struct { // Scale 资源的读写（如 Deployment 的 Scale） scaleNamespacer scaleclient.ScalesGetter // HorizontalPodAutoscaler 资源的读写 hpaNamespacer autoscalingclient.HorizontalPodAutoscalersGetter // 用于根据类型和版本获取资源信息 mapper apimeta.RESTMapper // 计算 replica 数量 replicaCalc *ReplicaCalculator // 订阅 HPA 资源，处理资源变化 eventRecorder record.EventRecorder // 每次缩容之间等待时间 downscaleStabilisationWindow time.Duration // hpaLister is able to list/get HPAs from the shared cache from the informer passed in to // NewHorizontalController. // 用于读取 hpa 对象 hpaLister autoscalinglisters.HorizontalPodAutoscalerLister hpaListerSynced cache.InformerSynced // podLister is able to list/get Pods from the shared cache from the informer passed in to // NewHorizontalController. // 用于读取 pod 资源 podLister corelisters.PodLister podListerSynced cache.InformerSynced // Controllers that need to be synced // 只会启动一个 worker，即如果有大量的 HPA 资源时，一部分资源的扩缩容可能不那么及时 queue workqueue.RateLimitingInterface // Latest unstabilized recommendations for each autoscaler. // 记录推荐伸缩数量 recommendations map[string][]timestampedRecommendation // Latest autoscaler events // 记录伸缩事件 scaleUpEvents map[string][]timestampedScaleEvent scaleDownEvents map[string][]timestampedScaleEvent } ","date":"2022-01-20","objectID":"/posts/hpa-controller/:3:0","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["kubernetes"],"content":"4. 控制器逻辑 ","date":"2022-01-20","objectID":"/posts/hpa-controller/:4:0","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["kubernetes"],"content":"4.1. 伸缩过程 伸缩过程的触发不是实时的，而是从 queue 里消费数据，进行一次伸缩流程，再次将资源名放入 queue, 完成一次循环。 详细流程如下： 4.1.1. 从 queue 读取一条消息，根据消息中的信息，获取 hpa 对象 func (a *HorizontalController) processNextWorkItem() bool { key, quit := a.queue.Get() if quit { return false } // 处理完标记完成 defer a.queue.Done(key) // 处理函数入口 deleted, err := a.reconcileKey(key.(string)) if err != nil { utilruntime.HandleError(err) } // Add request processing HPA to queue with resyncPeriod delay. // Requests are always added to queue with resyncPeriod delay. If there's already request // for the HPA in the queue then a new request is always dropped. Requests spend resyncPeriod // in queue so HPAs are processed every resyncPeriod. // Request is added here just in case last resync didn't insert request into the queue. This // happens quite often because there is race condition between adding request after resyncPeriod // and removing them from queue. Request can be added by resync before previous request is // removed from queue. If we didn't add request here then in this case one request would be dropped // and HPA would processed after 2 x resyncPeriod. if !deleted { // 如果 hpa 没有被删除，再次放回队列里，经过默认时间间隔（15s，k8s 启动参数可配置）后再读取处理一次 a.queue.AddRateLimited(key) } return true } func (a *HorizontalController) reconcileKey(key string) (deleted bool, err error) { namespace, name, err := cache.SplitMetaNamespaceKey(key) if err != nil { return true, err } // 读取 hpa 对象 `*autoscalingv1.HorizontalPodAutoscaler` hpa, err := a.hpaLister.HorizontalPodAutoscalers(namespace).Get(name) if errors.IsNotFound(err) { klog.Infof(\"Horizontal Pod Autoscaler %s has been deleted in %s\", name, namespace) delete(a.recommendations, key) delete(a.scaleUpEvents, key) delete(a.scaleDownEvents, key) return true, nil } if err != nil { return false, err } // 处理本次伸缩逻辑 return false, a.reconcileAutoscaler(hpa, key) } 4.1.2. 为了兼容老版本，读取时 hpa 对象为 v1 版本，读取后在代码里会先统一转换为 v2 版本,从而之后的逻辑统一 func (a *HorizontalController) reconcileAutoscaler(hpav1Shared *autoscalingv1.HorizontalPodAutoscaler, key string) error { // make a copy so that we never mutate the shared informer cache (conversion can mutate the object) hpav1 := hpav1Shared.DeepCopy() // then, convert to autoscaling/v2, which makes our lives easier when calculating metrics hpaRaw, err := unsafeConvertToVersionVia(hpav1, autoscalingv2.SchemeGroupVersion) if err != nil { a.eventRecorder.Event(hpav1, v1.EventTypeWarning, \"FailedConvertHPA\", err.Error()) return fmt.Errorf(\"failed to convert the given HPA to %s: %v\", autoscalingv2.SchemeGroupVersion.String(), err) } hpa := hpaRaw.(*autoscalingv2.HorizontalPodAutoscaler) ... } 4.1.3. 根据 hpa.Spec.ScaleTargetRef 信息读到需要伸缩的资源 func (a *HorizontalController) reconcileAutoscaler(hpav1Shared *autoscalingv1.HorizontalPodAutoscaler, key string) error { ... // 省略部分代码 hpa := hpaRaw.(*autoscalingv2.HorizontalPodAutoscaler) reference := fmt.Sprintf(\"%s/%s/%s\", hpa.Spec.ScaleTargetRef.Kind, hpa.Namespace, hpa.Spec.ScaleTargetRef.Name) // 解析资源 api version targetGV, err := schema.ParseGroupVersion(hpa.Spec.ScaleTargetRef.APIVersion) if err != nil { a.eventRecorder.Event(hpa, v1.EventTypeWarning, \"FailedGetScale\", err.Error()) setCondition(hpa, autoscalingv2.AbleToScale, v1.ConditionFalse, \"FailedGetScale\", \"the HPA controller was unable to get the target's current scale: %v\", err) a.updateStatusIfNeeded(hpaStatusOriginal, hpa) return fmt.Errorf(\"invalid API version in scale target reference: %v\", err) } // 资源类型 targetGK := schema.GroupKind{ Group: targetGV.Group, Kind: hpa.Spec.ScaleTargetRef.Kind, } // 查询资源对象 mappings, err := a.mapper.RESTMappings(targetGK) if err != nil { a.eventRecorder.Event(hpa, v1.EventTypeWarning, \"FailedGetScale\", err.Error()) setCondition(hpa, autoscalingv2.AbleToScale, v1.ConditionFalse, \"FailedGetScale\", \"the HPA controller was unable to get the target's current scale: %v\", err) a.updateStatusIfNeeded(hpaStatusOriginal, hpa) return fmt.Errorf(\"unable to determine resource for scale target reference: %v\", err) } // 根据 ns 资源类型 资源版本和资源名称 确定最","date":"2022-01-20","objectID":"/posts/hpa-controller/:4:1","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["kubernetes"],"content":"4.2. 计算副本数过程 可通过上面流程看到会有一个计算目标副本数的过程 a.computeReplicasForMetrics，看似简单其实内部相当丰富的一个过程，下面一起看一下如何去计算的。 4.2.1. 遍历 spec.Metrics 计算得出最大值 // computeReplicasForMetrics computes the desired number of replicas for the metric specifications listed in the HPA, // returning the maximum of the computed replica counts, a description of the associated metric, and the statuses of // all metrics computed. func (a *HorizontalController) computeReplicasForMetrics(hpa *autoscalingv2.HorizontalPodAutoscaler, scale *autoscalingv1.Scale, metricSpecs []autoscalingv2.MetricSpec) (replicas int32, metric string, statuses []autoscalingv2.MetricStatus, timestamp time.Time, err error) { /* * 省略了部分无关代码 */ if scale.Status.Selector == \"\" { errMsg := \"selector is required\" return 0, \"\", nil, time.Time{}, fmt.Errorf(errMsg) } selector, err := labels.Parse(scale.Status.Selector) if err != nil { return 0, \"\", nil, time.Time{}, fmt.Errorf(errMsg) } specReplicas := scale.Spec.Replicas statusReplicas := scale.Status.Replicas // 记录每个 metric 的结果 statuses = make([]autoscalingv2.MetricStatus, len(metricSpecs)) invalidMetricsCount := 0 var invalidMetricError error var invalidMetricCondition autoscalingv2.HorizontalPodAutoscalerCondition // 遍历计算 for i, metricSpec := range metricSpecs { // 计算单个 metric 的方法 replicaCountProposal, metricNameProposal, timestampProposal, condition, err := a.computeReplicasForMetric(hpa, metricSpec, specReplicas, statusReplicas, selector, \u0026statuses[i]) if err != nil { if invalidMetricsCount \u003c= 0 { invalidMetricCondition = condition invalidMetricError = err } invalidMetricsCount++ } // 取最大 if err == nil \u0026\u0026 (replicas == 0 || replicaCountProposal \u003e replicas) { timestamp = timestampProposal replicas = replicaCountProposal metric = metricNameProposal } } // If all metrics are invalid or some are invalid and we would scale down, // return an error and set the condition of the hpa based on the first invalid metric. // Otherwise set the condition as scaling active as we're going to scale if invalidMetricsCount \u003e= len(metricSpecs) || (invalidMetricsCount \u003e 0 \u0026\u0026 replicas \u003c specReplicas) { return 0, \"\", statuses, time.Time{}, fmt.Errorf(\"invalid metrics (%v invalid out of %v), first error is: %v\", invalidMetricsCount, len(metricSpecs), invalidMetricError) } return replicas, metric, statuses, timestamp, nil } 4.2.2. 计算单个 metric：根据类型计算 metric 名词解析 hpa 对象的 spac.metrics 中的元素有个 Type 字段,记录 metric 数据源的类型，目前支持的以下几种： 类型 说明 支持的计算类型 不支持的计算类型 Object 由 k8s 本身资源提供的数据，如 ingress 提供命中规则数量 AverageValue Value AverageUtilization Pods 由 pod 提供的除 CPU 内存之外的数据 AverageValue AverageUtilization Value Resource pod 提供的系统资源（CPU 内存） AverageUtilization AverageValue Value External 外部提供的监控指标 AverageValue Value AverageUtilization AverageValue：设定平均值，如qps，tps。计算时读取 metric 总和，与预设平均值✖️副本数进行对比，从而判断是否需要伸缩。 Value：设定固定值，如队列中消息数量，Redis 中 list 长度等。计算时直接拿 metric 和预设值进行对比。 AverageUtilization： 平均利用率，如 CPU 和内存。先计算 pod的基数的总和（totalMetric 和 totalRequest），最终计算利用率 → totalMetric/totalRequest 源码： // Computes the desired number of replicas for a specific hpa and metric specification, // returning the metric status and a proposed condition to be set on the HPA object. func (a *HorizontalController) computeReplicasForMetric(hpa *autoscalingv2.HorizontalPodAutoscaler, spec autoscalingv2.MetricSpec, specReplicas, statusReplicas int32, selector labels.Selector, status *autoscalingv2.MetricStatus) (replicaCountProposal int32, metricNameProposal string, timestampProposal time.Time, condition autoscalingv2.HorizontalPodAutoscalerCondition, err error) { switch spec.Type { case autoscalingv2.ObjectMetricSourceType: metricSelector, err := metav1.LabelSelectorAsSelector(spec.Object.Metric.Selector) if err != nil { condition := a.getUnableComputeReplicaCountCondition(hpa, \"FailedGetObjectMetric\", err) return 0, \"\", time.Time{}, condition, fmt.Errorf(\"failed to get object metric value: %v\", err) } replicaCountProposal, timestampProposal, metricNameProposal, condition, err = a.computeStatusForObjectMetric(specReplicas, statusRepli","date":"2022-01-20","objectID":"/posts/hpa-controller/:4:2","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["kubernetes"],"content":"5. 扩展用法 在实际开发环境只用 cpu, memory 来作为弹性伸缩依据是远远不够的。大多数情况可能会根据 qps, tps, 平均延迟时间, MQ 中的消息数量, Redis 中的数据量 等与业务息息相关的数据量判断伸缩的依据，这些都属于 HPA 的 External 类型的范畴。但是 External 类型的数据源需要对接 Adapter 的方式才能用到 HPA 对象内容(具体请查看: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-metrics-apis) ，也就是说需要额外开发量的。 这里我推荐一个知名度比较高且支持的数据量比较广泛的 Adapter 的实现 – KEDA。基于事件驱动的autoscaler,且支持从 0 到 1 1 到 0 的伸缩，也就是说业务低峰或者无流量时可以降到 0 个副本数(这个在 HPA 被认为是禁用该功能 所以 KEDA 自己实现的 0 到 1 1 到 0 的伸缩的能力，剩余的情况它叫个 HPA 处理)。 目前 KEDA 支持事件类型如下： KEDA 支持的事件\" KEDA 支持的事件 只需要创建 KEDA 的 CRD 资源，就能实现基于事件的弹性伸缩，KEDA 的 controller 会创建对应的 HPA 对象。 下面以 Prometheus 为例： KEDA.ScaledObject: apiVersion:keda.sh/v1alpha1kind:ScaledObjectmetadata:name:prom-scaledobjectnamespace:defaultspec:scaleTargetRef:name:klyn-deploytriggers:- type:prometheusmetadata:serverAddress:http://10.103.255.235:9090# Prometheus 查询接口metricName:http_request_count# 自定义名字query:sum(rate(http_request_count{job=\"klyn-service\"}[2m]))# 查询语句 2m 内的平均 qpsthreshold:'50'maxReplicaCount:5minReplicaCount:1pollingInterval:5 apply 该 yaml 后，会创建一个 ScaledObject 和 HPA 对象。 ➜ kubectl get ScaledObject NAME SCALETARGETKIND SCALETARGETNAME MIN MAX TRIGGERS AUTHENTICATION READY ACTIVE FALLBACK AGE prom-scaledobject apps/v1.Deployment klyn-deploy 1 5 prometheus True False False 9d ## 该 HPA 对象有 KEDA 的 controller 创建的 ➜ kubectl get hpa NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE keda-hpa-prom-scaledobject Deployment/klyn-deploy 0/50 (avg) 1 5 1 9d 这样一来，可以根据很多事件来控制伸缩的能力，这比单一来 cpu,内存利用率来看更灵活且及时。完全可以根据事件在服务的副本数不够用或者有一堆事件准备处理时，尽可能快速扩容，确保处理能力不会受损。 ","date":"2022-01-20","objectID":"/posts/hpa-controller/:5:0","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["kubernetes"],"content":"6. 总结 这篇文章主要讲 HPA controller 的源码和如何使用 HPA 相关内容 HPA/VPA 的解释 如何使用 HPA HPA Controller 如何处理一次伸缩事件的 HPA Controller 如何计算目标实例数的 认识和使用 KEDA – 一个基于事件驱动的 autoscaler ","date":"2022-01-20","objectID":"/posts/hpa-controller/:6:0","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["kubernetes"],"content":"7. 链接🔗 horizontal-pod-autoscale pvertical-pod-autoscaler metrics server KEDA ","date":"2022-01-20","objectID":"/posts/hpa-controller/:7:0","tags":["go","k8s","源码解读"],"title":"HPA controller 源码解读","uri":"/posts/hpa-controller/"},{"categories":["代码技巧"],"content":" 本篇分享一个分片式的 map 结构，在一些场景下该结构比原生 syncMap 更有优势，本文会对该结构的实现，原理以及时候的场景进行详细的介绍。 ","date":"2022-01-13","objectID":"/posts/shard-map/:0:0","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":["代码技巧"],"content":"1. 背景 map 作为一个基础的数据结构，在编程过程中可以说是无处不在，应用场景十分广泛。在大部分场景下用原生的 map 就能解决当前的问题。如果是高并发场景可以加入 sync.RWMutex 来控制并发读写或者直接使用 sync.Map 来减少手动写锁的处理逻辑。如果作为一个应用的基础数据结构，性能可以说是非常的高了，绝大部分场景下是完全足够的。但是总有人在优化性能这块想做到极致（包括我自己），即便是原生的数据结构也会有人想优化。既然想优化 map，那首先得了解 map 在什么情况下性能会受损或者性能不够高呢？ 对 map 结构熟悉的同学应该都知道，map 又称之为哈希表，key 是按照哈希值存储的，map 在元素增多/减少的过程在 go 里叫 grow,而这个过程中有个非常关键的步骤 rehash。即会对 map 内的数据进行重新哈希计算和移动位置，在数据量比较大的时候，map 的写性能会有一定的受损的。 如果我有个对性能要求很高的程序（其实如果对性能要求极高其实可以考虑 C 或者 rust 的，这里就不考虑了），想在 map 上做进一步的优化的，应该如何优化，从什么地方入手呢？ 在我之前几篇文章都在讲用 go 语言实现 Redis server 的过程，在实际开发过程中我最开始也是直接用的 syncMap 作为底层的哈希表的，但是最后压测的时候，结果不是很满意。尤其是写入操作数据量大的时候，tps 下降比较厉害，所以就开始搜查相关的优化方案。首先遇到了一个开源库orcaman/concurrent-map,其 README 中的一句话吸引到我了 orcaman/concurrent-map.README Prior to Go 1.9, there was no concurrent map implementation in the stdlib. In Go 1.9, sync.Map was introduced. The new sync.Map has a few key differences from this map. The stdlib sync.Map is designed for append-only scenarios. So if you want to use the map for something more like in-memory db, you might benefit from using our version 这不就是在说我吗？所以马上clone 下来进行 benchmark 测试，与 syncMap 进行对比。仅对基础读写能力进行一个压测对比，结果如下： /* * goos: darwin * goarch: amd64 * pkg: github.com/yusank/godis/datastruct * cpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz * Benchmark_concurrence_map_sAdd * Benchmark_concurrence_map_sAdd-12 2619080 440.8 ns/op * Benchmark_concurrence_map_sIsMember * Benchmark_concurrence_map_sIsMember-12 13764466 77.68 ns/op * Benchmark_concurrence_map_sRem * Benchmark_concurrence_map_sRem-12 16740207 65.18 ns/op * Benchmark_sync_map_sAdd * Benchmark_sync_map_sAdd-12 2101056 765.1 ns/op * Benchmark_sync_map_sIsMember * Benchmark_sync_map_sIsMember-12 15998791 73.47 ns/op * Benchmark_sync_map_sRem * Benchmark_sync_map_sRem-12 15768998 76.62 ns/op * PASS */ 查询元素和删除元素前，提前 insert 50000 条数据进行的压测 对比结果确实让我有些惊讶，我以为这个开源库应该也就大概能达到 sync.Map 80-90% 的性能，没想到写入性能比 sync.Map 高出 60%，我决定用这个开源库替代sync.Map。 但是我在看该库的源码的时候发现让我不是很爽的一个地方，就是读取全量数据的时候会进行一次 buffer，再从 buffer 往外吐出元素，导致全量数据的读取或者遍历变得非常的慢，当然这个作者可能有自己的顾虑，但是对我来说说不可接受。所以我决定对这个库进行一个自定义，下面就把库的实现逻辑和自己自定义的部分一起分享一下。 ","date":"2022-01-13","objectID":"/posts/shard-map/:1:0","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":["代码技巧"],"content":"2. 实现 ","date":"2022-01-13","objectID":"/posts/shard-map/:2:0","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":["代码技巧"],"content":"2.1. 数据结构 我们先从数据结构的定义入手看看这个库为什么能做到这么高的性能。 var SHARD_COUNT = 32 // A \"thread\" safe map of type string:Anything. // To avoid lock bottlenecks this map is dived to several (SHARD_COUNT) map shards. type ConcurrentMap []*ConcurrentMapShared // A \"thread\" safe string to anything map. type ConcurrentMapShared struct { items map[string]interface{} sync.RWMutex // Read Write mutex, guards access to internal map. } // Creates a new concurrent map. func New() ConcurrentMap { m := make(ConcurrentMap, SHARD_COUNT) for i := 0; i \u003c SHARD_COUNT; i++ { m[i] = \u0026ConcurrentMapShared{items: make(map[string]interface{})} } return m } ConcurrentMap 是一个 32 个分片的 map 结构，每个分片内是一个 map-lock 的组合。这个 SHARD_COUNT 可能是为了方便后期可以通过编译过程注入的方式扩展分片大小而定义的变量。我目前没有这个需求，而且其他变量名觉得有点啰嗦，所以稍微改了一下： const shardCount = 32 // Map - // 直接定义32 长度的数组 type Map [shardCount]*Shard // Shard of Map // 分片 type Shard struct { sync.RWMutex items map[string]interface{} } func New() Map { m := Map{} for i := 0; i \u003c shardCount; i++ { m[i] = \u0026Shard{items: make(map[string]interface{})} } return m } ","date":"2022-01-13","objectID":"/posts/shard-map/:2:1","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":["代码技巧"],"content":"2.2. 元素定位 从上述结构可以看出，元素分布于多个 Shard 内的 map 中，那么如何确定某个元素在哪个分片上呢？答案是： 哈希取模的方式定位元素的分片。 // GetShard returns shard under given key func (m Map) GetShard(key string) *Shard { return m[uint(fnv32(key))%uint(shardCount)] } // 哈希算法 func fnv32(key string) uint32 { hash := uint32(2166136261) const prime32 = uint32(16777619) keyLength := len(key) for i := 0; i \u003c keyLength; i++ { hash *= prime32 hash ^= uint32(key[i]) } return hash } ","date":"2022-01-13","objectID":"/posts/shard-map/:2:2","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":["代码技巧"],"content":"2.3. 增改删查 func (m Map) Get(key string) (interface{}, bool) { shard := m.GetShard(key) shard.RLock() defer shard.RUnlock() v, ok := shard.items[key] return v, ok } func (m Map) Set(key string, value interface{}) { shard := m.GetShard(key) shard.Lock() defer shard.Unlock() shard.items[key] = value } func (m Map) Delete(key string) { shard := m.GetShard(key) shard.Lock() defer shard.Unlock() delete(shard.items, key) } // UpsertFunc callback for upsert // if after found oldValue and want to stop the upsert op, you can return result and true for it type UpsertFunc func(exist bool, valueInMap, newValue interface{}) (result interface{}, abort bool) // Upsert - update or insert value and support abort operation after callback func (m Map) Upsert(key string, value interface{}, f UpsertFunc) (res interface{}, abort bool) { shard := m.GetShard(key) shard.Lock() defer shard.Unlock() old, ok := shard.items[key] res, abort = f(ok, old, value) if abort { return } shard.items[key] = res return } 有了基础的方法之后，可以补充一些更方便的方法封装，如 Exists, SetIfNotExists, DeleteAndLoad 等等。 ","date":"2022-01-13","objectID":"/posts/shard-map/:2:3","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":["代码技巧"],"content":"2.4. 高级用法 func (m Map) SetIfAbsent(key string, value interface{}) bool { shard := m.GetShard(key) shard.Lock() defer shard.Unlock() _, ok := shard.items[key] if !ok { shard.items[key] = value return true } return false } func (m Map) DeleteIfExists(key string) bool { shard := m.GetShard(key) shard.Lock() defer shard.Unlock() _, ok := shard.items[key] if !ok { return false } delete(shard.items, key) return true } func (m Map) LoadAndDelete(key string) (v interface{}, loaded bool) { shard := m.GetShard(key) shard.Lock() defer shard.Unlock() v, loaded = shard.items[key] if !loaded { return nil, false } delete(shard.items, key) return v, loaded } func (m Map) Delete(key string) { shard := m.GetShard(key) shard.Lock() defer shard.Unlock() delete(shard.items, key) } func (m Map) Range(f func(key string, value interface{}) bool) { for i := range m { shard := (m)[i] shard.RLock() defer shard.RUnlock() for s, v := range shard.items { if !f(s, v) { return } } } } ","date":"2022-01-13","objectID":"/posts/shard-map/:2:4","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":["代码技巧"],"content":"3. 场景 \u0026 压测 ","date":"2022-01-13","objectID":"/posts/shard-map/:3:0","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":["代码技巧"],"content":"3.1. 使用场景 该结构的特点就是写操作比 sync.Map 高大概 60% 左右，所以使用场景的选择的基础的在于以下两点： 对性能要求比较高，否则 sync.Map 完成足够 数据量大。在数据量比较少的情况下，该结构的优势不够明显 综上述，比较合适的使用场景的应该是 内存数据库。对性能要求高，且数据量会很大，整体性能不会因为数据量高而会下降。 ","date":"2022-01-13","objectID":"/posts/shard-map/:3:1","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":["代码技巧"],"content":"3.2. 压测 压测源码： func BenchmarkShardMap_Set(b *testing.B) { m := New() for i := 0; i \u003c b.N; i++ { k := strconv.Itoa(i) m.Set(k, i) } } func BenchmarkSyncMap_Set(b *testing.B) { m := sync.Map{} for i := 0; i \u003c b.N; i++ { k := strconv.Itoa(i) m.Store(k, i) } } func BenchmarkShardMap_Get(b *testing.B) { m := New() for i := 0; i \u003c 3_000_000; i += 3 { k := strconv.Itoa(i) m.Set(k, i) } for i := 0; i \u003c b.N; i++ { k := strconv.Itoa(i) m.Get(k) } } func BenchmarkSyncMap_Get(b *testing.B) { m := sync.Map{} for i := 0; i \u003c 3_000_000; i += 3 { k := strconv.Itoa(i) m.Store(k, i) } for i := 0; i \u003c b.N; i++ { k := strconv.Itoa(i) m.Load(k) } } func BenchmarkShardMap_Del(b *testing.B) { m := New() for i := 0; i \u003c 3_000_000; i += 3 { k := strconv.Itoa(i) m.Set(k, i) } for i := 0; i \u003c b.N; i++ { k := strconv.Itoa(i) m.Delete(k) } } func BenchmarkSyncMap_Del(b *testing.B) { m := sync.Map{} for i := 0; i \u003c 3_000_000; i += 3 { k := strconv.Itoa(i) m.Store(k, i) } for i := 0; i \u003c b.N; i++ { k := strconv.Itoa(i) m.Delete(k) } } 分别对 sync.Map, ShardMap 进行大量的读写删操作,下面看看压测结果 原始结果 goos: darwin goarch: amd64 pkg: github.com/yusank/godis/lib/shard_map cpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz BenchmarkShardMap_Set BenchmarkShardMap_Set-12 2442687 481.3 ns/op BenchmarkSyncMap_Set BenchmarkSyncMap_Set-12 1442368 736.1 ns/op BenchmarkShardMap_Get BenchmarkShardMap_Get-12 2702954 385.3 ns/op BenchmarkSyncMap_Get BenchmarkSyncMap_Get-12 717051 1409 ns/op BenchmarkShardMap_Del BenchmarkShardMap_Del-12 2704998 384.8 ns/op BenchmarkSyncMap_Del BenchmarkSyncMap_Del-12 480789 2209 ns/op PASS 结果对比 结果如下(单位：ns/op)： 数据结构 Set Get Del ShardMap 481.3 385.3 384.8 sync.Map 736.1 1409 2209 不难发现，在数据量大的情况下（百万级别）sync.Map 的性能会下降很多，这个与 sync.Map 的设计和内部结构有关，感兴趣的朋友可以去阅读一下 sync.Map 的源码。 注意：这里文章最开始时的压测结果差距很大的原因是 数据量不一样，第一个压测结果是基于 50000 个元素之上进行的，所以查询和删除的性能上看上去很高。而这里的压测时基于 3000000 个元素之上进行的。 ","date":"2022-01-13","objectID":"/posts/shard-map/:3:2","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":["代码技巧"],"content":"4. 总结 本篇介绍了一个基于 map 的分片式数据结构 – ShardMap。 该结构可以在数据量比较大的使用替代sync.Map 从而保持比较高的性能。我在自己的 godis 项目内也是用该结构作为基础的哈希表，但是由于godis 单进程处理数据，所以我把其中的读写锁去掉 从而获得更高的性能。 本篇主要内容： 认识 ShardMap 了解到 sync.Map 也存在性能问题 了解到 map 在数据量大的情况下，性能会因为 reshah 机制的存在而有所下降 通过分片的方式，降低单个 map 的数据量，从而减少 rehash 带来的性能的降低 实现和压测 ShardMap ","date":"2022-01-13","objectID":"/posts/shard-map/:4:0","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":["代码技巧"],"content":"5. 链接🔗 orcaman/concurrent-map godis godis/shard_map ","date":"2022-01-13","objectID":"/posts/shard-map/:5:0","tags":["go","map","数据结构"],"title":"go 语言中的分片 map 的实现","uri":"/posts/shard-map/"},{"categories":null,"content":" 感谢各位大佬们的大力支持 杨鼎睿 ","date":"2022-01-07","objectID":"/links/:0:0","tags":null,"title":"友情链接","uri":"/links/"},{"categories":["Redis"],"content":" 本篇讲述 Redis 中的基础数据结构 ZSet(SortedSet) 的底层实现原理和如何通过 go 语言实现一个 ZSet 的过程以及需要注意的问题。 说明 本文章为该系列的有序集合，如果需要阅读其他相关文章， 请点击这里跳转查看 ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:0:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":"1 前言 使用 Redis 过程中集合这个概念出现的比较频繁，常用的 set，zset 都是集合的概念。与普通的集合不同的是，zset 的元素之间是有顺序的，而且这个顺序不是插入的顺序而是使用者插入元素时指定的 score 而定的。 zset 中的任何元素都是有score 值（浮点数）的，而且根据 score 的顺序进行读写甚至可以做到获取范围数据，这些特性给使用者带来了无数种可能性解决方案。 zset 的数据结构 从使用者的角度来说，zset 更像一个 kv 结构,元素不可以重复但是不同元素的 score 值是可以一样的，此时的排序是按元素字典排序。 通过 ZRANGEBYSCORE 命令可以列出指定score范围内的元素以及对应的 key， 其顺序为 score 的升序。 \u003e ZRANGEBYSCORE zset1 0 100 withscores 1) \"a\" 2) \"5\" 3) \"b\" 4) \"5\" 5) \"hello\" 6) \"20\" ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:1:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":"2 zset 支持的能力 zset 作为一个有序集合，即拥有普通集合的特性，同时又基于其有序特性衍生出更多别的特性。主要特性如下： 元素不重复 集合之间交集并集差集的操作 批量读写元素 根据 score 操作（增删改查）元素 获取score最大最小的元素 根据集合内rank（或 index）操作（增删改查）元素 ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:2:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":"3 zset 底层原理 注意 本篇中所有引用的 Redis 源码均基于 Redis6.2 版本。 Redis 实现的 zset 底层是跳跃表和哈希表的组合。跳跃表 用于记录和操作所有基于 score 的操作，而哈希表存的是元素值和 score 的kv关系，用于快速定位元素存不存在的情况。 typedef struct zset { dict *dict; // 哈希表，存储 元素-\u003escore zskiplist *zsl; // 跳跃表 } zset; 除了跳跃表和哈希表之外，其实还有一个不怎么出场的数据结构 – ziplist（压缩列表）。在满足以下两个条件的情况下，Redis 会使用 ziplist来替代跳跃表。 保存的元素少于128个 保存的所有元素大小都小于64字节 在了解跳跃表之前先了简单解一下 ziplist 这个数据结构的实现以及解答为什么要用 ziplist 来替代跳跃表。 ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:3:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":"3.1 压缩列表-ziplist ziplist 编码的有序集合对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个节点保存元素的分值。并且压缩列表内的集合元素按分值从小到大的顺序进行排列。 从上述的两个条件可以看出，在数据量少且单个元素也比较小的情况下，使用 ziplist 是为了节省内存，因为在数据量少的情况下发挥不出来 skiplist 的优势且占的内存比 ziplist 大。 想更深入了解 ziplist 的实现细节，请点击这里查看 结构分布 ziplist 结构分布 area |\u003c---- ziplist header ----\u003e|\u003c----------- entries -------------\u003e|\u003c-end-\u003e| size 4 bytes 4 bytes 2 bytes ? ? ? ? 1 byte +---------+--------+-------+--------+--------+--------+--------+-------+ component | zlbytes | zltail | zllen | entry1 | entry2 | ... | entryN | zlend | +---------+--------+-------+--------+--------+--------+--------+-------+ ^ ^ ^ address | | | ZIPLIST_ENTRY_HEAD | ZIPLIST_ENTRY_END | ZIPLIST_ENTRY_TAIL ziplist 节点结构分布 area |\u003c------------------- entry --------------------\u003e| +------------------+----------+--------+---------+ component | pre_entry_length | encoding | length | content | +------------------+----------+--------+---------+ ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:3:1","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":"3.2 跳跃表-skiplist 3.2.1 定义 跳跃表是一个随机化的数据结构，实质就是一种可以进行二分查找的有序链表。跳跃表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。跳跃表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能。 它采用随机技术决定链表中哪些节点应增加向前指针以及在该节点中应增加多少个指针。跳跃表结构的头节点需有足够的指针域，以满足可能构造最大级数的需要，而尾节点不需要指针域。 采用这种随机技术，跳跃表中的搜索、插入、删除操作的时间均为O(logn)，然而，最坏情况下时间复杂性却变成O(n)。相比之下，在一个有序数组或链表中进行插入/删除操作的时间为O(n)，最坏情况下为O(n)。 3.2.2 原理 跳跃表原理非常简单，在链表的基础上每个元素加上一个层(level)的概念，层高则是随机的, 所以每个元素的高度不一样。每一层都会指向下一个同一层的元素，查询元素时由高层向后向下的方式二级检索从而达到更高的查询效率，下面用图解的方式解析如何读写跳跃表元素的。在看图之前可以先看一下源码，尝试理解一下。 // 跳跃表结构 typedef struct zskiplist { struct zskiplistNode *header, *tail; // 记录 head 和 tail 两个节点 unsigned long length; // 记录长度 int level; // 记录当前最高 level，如果有新元素插入且其 level 大于当前最高则更新该值 } zskiplist; // 跳跃表节点 typedef struct zskiplistNode { sds ele; // 元素值 double score; // score struct zskiplistNode *backward; // 向前指向指针，用于往回跳 struct zskiplistLevel { struct zskiplistNode *forward; // 每一层都指向下一个同高度元素 unsigned long span; // 到下一个同高度元素的跨度 } level[]; // 该元素的 level 数组，index 从 0 到 N 表示从最低到最高，默认最高支持 32 层 } zskiplistNode; 如果看完源码还是没有看到 ，请看下图： 跳跃表结构\" 跳跃表结构 从图中可以看到， 跳跃表主要由以下部分构成： 表头（head）：负责维护跳跃表的节点指针。 跳跃表节点：保存着元素值，以及多个层。 层：保存着指向其他元素的指针。高层的指针越过的元素数量大于等于低层的指针，为了提高查找的效率，程序总是从高层先开始访问，然后随着元素值范围的缩小，慢慢降低层次。 表尾：全部由 NULL 组成，表示跳跃表的末尾。 注意 图中没有表示出来 zskiplistNode.backward 指针的指向，实际上图中每个元素都会指向前一个元素 3.2.3 查询元素 在跳跃表查询元素，总是从 head 的顶层 level 向后向下的方式取查询，以上面的示例图为例，下面讲解如何查询 score 值为 7 的元素: 初始条件： p 为初始指针，指向 head 的顶层 level 查询步骤： 判断指针 p 的 forward 元素的值 当满足条件：forward.score \u003c score 或 forward.score == score \u0026\u0026 forward.ele \u003c targetEle 时，p 向前移动，level 不变 当 p 的 forward 为 null 或者forward 元素的值大于 score 时，level 减一，但是 p 不往前移动 步骤 1，2 一直循环，指到 p 移动到 null 或者移动到目标元素为止。 跳跃表查询元素过程\" 跳跃表查询元素过程 源码： /* 下面就是非常常规的一个遍历查找过程 */ x = zsl-\u003eheader; // 从head 顶层level开始向下遍历 for (i = zsl-\u003elevel-1; i \u003e= 0; i--) { // 每一层判断forward元素不为空的时候是否与目标score和ele while (x-\u003elevel[i].forward \u0026\u0026 (x-\u003elevel[i].forward-\u003escore \u003c curscore || (x-\u003elevel[i].forward-\u003escore == curscore \u0026\u0026 // 这里的 sdccmp 是Redis内实现的对其 String 结构的字符串进行对比(即字典排序的对比) sdscmp(x-\u003elevel[i].forward-\u003eele,ele) \u003c 0))) { x = x-\u003elevel[i].forward; } } 然后再真正实现 zset 的时候，不会根据 value 值去遍历查询跳跃表, 而是直接从哈希表查是否存在 3.2.4 添加元素 添加元素核心有以下几点： 找到需要插入的位置，这块用上上一个小节的查询元素相关知识 在查找位置的过程中需要记录牵连到需要更新的元素 如何得到新元素的层高，真的是 [0,32) 之间随机一个数嘛？ 如果新元素的层高大于当前 skiplist 的高度，需要做哪些调整工作？ 对以上几点有了明确的认知和回答后，了解插入元素的过程就变得很简单。 添加元素过程： 定义一个 zskiplistNode *update[ZSKIPLIST_MAXLEVEL] 数组记录每次变更 level 时的节点（后期更新受影响的节点用） 定义 unsigned int rank[ZSKIPLIST_MAXLEVEL] 数组记录两次向下遍历的节点直接的跨度 与查询元素一样，从 head 的顶层开始向下向前遍历，找到插入的位置，这个位置满足 score 值介于前后的元素 在遍历的过程中，每往下移动一次(level - 1 )的时候记录当前元素update[cur_level] = cur_node 在遍历的过程中，每往前移动一次(注：每次移动只会单向 不会同时向前向下)的前记录同一个 level 内的跨度 rank[cur_level] += cur_node.level[cur_level].span (这里之所以累加是因为，同一个 level 上可能会向前移动 n 次，如上面示例图中的从 1 到 6 的过程都是在同一个 level 上进行的) // 定义变量 zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned int rank[ZSKIPLIST_MAXLEVEL]; int i, level; // 从 header 开始遍历 x = zsl-\u003eheader; // 初始位置 header 的顶层 level for (i = zsl-\u003elevel-1; i \u003e= 0; i--) { /* store rank that is crossed to reach the insert position */ // 如果当前level 为最高一层的 level 则 rank 记录 0 rank[i] = i == (zsl-\u003elevel-1) ? 0 : rank[i+1]; while (x-\u003elevel[i].forward \u0026\u0026 (x-\u003elevel[i].forward-\u003escore \u003c score || (x-\u003elevel[i].forward-\u003escore == score \u0026\u0026 sdscmp(x-\u003elevel[i].forward-\u003eele,ele) \u003c 0))) { // 向前移动时记录当前 level 移动的跨度 rank[i] += x-\u003elevel[i].span; x = x-\u003elevel[i].forward; } // level - 1 时 记录当前元素 update[i] = x; } 随机一个 level， Redis 是有一套简单的算法去生成随机的 level 跳转查看。 如果随机的 level 大于 skiplist 当前最高 level，则在 update 数组记录从当前最高到新的最高之间的level 对应的节点为 head 节点 /* we assume the element is not already inside, since we allow duplicated * scores, reinserting the same element should never happen since the * caller of zslInsert() should test in the hash table if the element is * already inside or not. */ level = zslRandomLevel(); if (level \u003e zsl-\u003elevel) { // 在 zsl-\u003elevel 到 level 之间区域补缺原来的空缺 // 原来高于 zsl-\u003elevel 的 level 均指向 null，现在需要指向到新的元素对应的 level 了 for (i = zsl-\u003elevel; i \u003c level; i++) { rank[i] = 0; // 因为最高的 level 了所以在该层不会指向下一个元素 所以对应的 rank == 0 update[i] = zsl-\u003eheader; // header 需要更新 update[i]-\u003elevel[i].span = ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:3:2","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":"4 zset 实现 上面关于zset的原理和实现都理解的比较透彻了，如果还有不明白的建议看源码，结合源码上下文更好理解。现在我用 go 语言实现跳跃表。关于压缩表我在这里不会涉及到只实现跳跃表相关代码。 ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:4:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":"4.1 数据结构定义 数据结构定义基本与 Redis 一致，跳跃表 + map 的组合。其中 map 部分为了提高读写性能，自己实现了一个 map 结构。 // zSet is object contain skip list and map which store key-value pair type zSet struct { // smap.Map 为自己实现的原生 map 的封装，之后单独讲一下，之所以自己实现是为了提高性能 m smap.Map // store key and value // 在元素少于 100 \u0026 每个元素大小小于 64 的时候,Redis 实际上用的是 zipList 这里作为知识点提了一下 // 除非遇到性能问题,否则不准备同时支持 zipList 和 skipList zsl *zSkipList // skip list } type zSkipList struct { head, tail *zSkipListNode length int // 总长度 level int // 最大高度 } type zSkipListNode struct { value string score float64 backward *zSkipListNode levels []*zSkipListLeve } type zSkipListLeve struct { forward *zSkipListNode span uint // 当前 level 到下一个节点的跨度 } ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:4:1","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":"4.2 初始化 因为存在一个 header 的虚拟节点，所以初始化的时候需要把跳跃表的 header 以及其每一层都初始化。 // new skiplist func newZSkipList() *zSkipList { zsl := \u0026zSkipList{ level: 1, // 每一层为空的 ZSkipListMaxLevel 层的 head head: newZslNode(ZSkipListMaxLevel, 0, \"\"), } return zsl } // new node func newZslNode(level int, score float64, value string) *zSkipListNode { node := \u0026zSkipListNode{ value: value, score: score, levels: make([]*zSkipListLeve, level), } // 初始化每一层 for i := 0; i \u003c level; i++ { node.levels[i] = \u0026zSkipListLeve{} } return node } ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:4:2","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":"4.3 其他功能 增删改查的代码与上面源码解析的逻辑大致相同，我在这里给出go 语言实现的源码，可以点击查看。在这里不再讲述这些基础功能的实现， 而是给出一些特殊的方法的实现。 4.3.1 根据排名查找元素 在上面的实现里会看到到处飞的 span 这个属性，但是好像一直没有实际用上，其实在遍历过程中尤其是跟排名相关的操作里这个 span 属性是非常的有用，下面看一下实际用处： func (zsl *zSkipList) findElementByRank(rank uint) *zSkipListNode { var ( x = zsl.head // 已遍历的距离 traversed uint ) // 从 head 的顶层开始遍历 for i := zsl.level - 1; i \u003e= 0; i-- { // 如果当前level 的下一个元素的距离 + 已经走过的距离 小于 目标排名 -\u003e 向前移动 // 否则 level - 1 for x.levels[i].forward != nil \u0026\u0026 traversed+x.levels[i].span \u003c= rank { traversed += x.levels[i].span x = x.levels[i].forward } // level -1 前判断是否达到目标 rank if traversed == rank { return x } } return nil } 因为记录了与下一个元素的距离，根据排名找元素变得很简单高效，只要跳跃对应的距离即可（距离代表的就是跨越多少个元素也就是多少个排名位置） 4.3.2 zrange 实现 zrange 这个命令是使用 zset 时最常用的命令之一, 那底层是怎么实现的呢？ // start stop 支持负数 负数时表示倒数第几个 func (zsl *zSkipList) zRange(start, stop int, withScores bool) []string { if start \u003c 0 { start = start + zsl.length if start \u003c 0 { start = 0 } } if stop \u003c 0 { stop = stop + zsl.length } if start \u003e stop || start \u003e= zsl.length { return nil } if stop \u003e= zsl.length { stop = zsl.length - 1 } // 到目前为止是为了处理 start 和 stop 越界问题，并把负数换算成正数 方便下面处理 // 先用上面的方法找到遍历的第一个元素 node := zsl.findElementByRank(uint(start) + 1) var ( rangeLen = stop - start + 1 result []string ) // 从 start 元素开始遍历 for rangeLen \u003e 0 { result = append(result, node.value) if withScores { result = append(result, strconv.FormatFloat(node.score, 'g', -1, 64)) } // 跳跃表的第 0 层可以看做做是一个链表，这样遍历读取多个元素就很方便了 node = node.levels[0].forward rangeLen-- } return result } 如何逆向遍历 如果需要逆向遍历 直接把 node = node.levels[0].forward 改成 node = node.levels[0].backward 即可。 ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:4:3","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":"5 总结 写到这里，Redis 如何实现 zset 的原理和源码以及如何用 go 语言自己写一遍都讲完了，下面做个简单的总结。 zset 底层是两种数据结构组成（ziplist， skiplist + dict），根据存储的数据量不同从决定使用哪个 跳跃表是一个树状结构，读写时间复杂度 O(logN) 跳跃表的level 是随机算法算出来的，确保每一层是上一次的 P 倍，level 越低数据分布越密集 如果对 Redis 的源码或者跳跃表比较熟悉的话，go 语言的实现基本没有任何难度，是把理解转换成代码过程 实现过程需要注意的是一些特殊情况，包括边界问题，head 和 tail 的问题以及操作某个元素其牵连到的附近的元素 ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:5:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":"6 参考链接🔗 压缩列表-ziplist 跳跃表-skiplist go 语言实现 Redis ","date":"2022-01-07","objectID":"/posts/redis-server-zset/:6:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·有序集合篇","uri":"/posts/redis-server-zset/"},{"categories":["Redis"],"content":" 本篇讲述 Redis 中的基础数据结构 List 的底层实现原理和如何通过 go 语言实现一个 List 的过程以及需要注意的问题。 说明 本文章为该系列的链表，如果需要阅读其他相关文章， 请点击这里跳转查看 ","date":"2021-12-24","objectID":"/posts/redeis-server-list/:0:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·链表篇","uri":"/posts/redeis-server-list/"},{"categories":["Redis"],"content":"1 前言 众所周知，Redis 中有五大数据结构，在各种面试中也会经常遇到相关的问题，从这一篇开始，我把这个五大数据结构（string, list, set, sorted_set, hash_map）的底层原理和如何用 go 语言实现讲明白。 ","date":"2021-12-24","objectID":"/posts/redeis-server-list/:1:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·链表篇","uri":"/posts/redeis-server-list/"},{"categories":["Redis"],"content":"2 list能力 list 是一个我们常用的一个 Redis 特性，特定就是先进后出 FILO 。并且支持双端的读写，所以也可以在使用过程中也能实现基于 list 的 先进先出 FIFO 模型。 总结一下，Redis 支持的能力： 双端读写 批量读写 list 内部元素的增删改 阻塞读取 ","date":"2021-12-24","objectID":"/posts/redeis-server-list/:2:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·链表篇","uri":"/posts/redeis-server-list/"},{"categories":["Redis"],"content":"3 list 底层原理 Redis 实现 list 的是双向链表(linked-list)。这个数据结构大家应该非常的熟悉，且经常拿链表和数组进行对比。相对于数组，链表最大的优势在于写入元素时不需要考虑数组一样 grow 过程，只需要将新元素连接到链表最后即可，而数组是需要考虑扩容缩容时数组 grow 问题的。 数据结构： type List struct { // 记录头和尾 head, tail *listNode } type listNode struct { // 双向链表 // 相对于单向链表 多记录一个 prev 指向前一个元素 next, prev *listNode value string } 从数据结构来看，其实一点都不复杂，只需要记录第一个和最后一个元素，元素内部记录前一个和后一个元素的指针即可。读写都是基于修改元素内指向的指针来完成。 配合下面图看代码就更好理解了： ","date":"2021-12-24","objectID":"/posts/redeis-server-list/:3:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·链表篇","uri":"/posts/redeis-server-list/"},{"categories":["Redis"],"content":"4 list的实现 下面我们开始用 go 语言来实现 Redis 中的 list 数据结构的特性。 ","date":"2021-12-24","objectID":"/posts/redeis-server-list/:4:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·链表篇","uri":"/posts/redeis-server-list/"},{"categories":["Redis"],"content":"4.1 定义和初始化 list 定义： type List struct { length int // 记录总长度 head, tail *listNode } type listNode struct { next, prev *listNode value string } 初始化： func newList() *List{ return new(List) } func newListNode(val string) *listNode { return \u0026listNode{ value: val, } } ","date":"2021-12-24","objectID":"/posts/redeis-server-list/:4:1","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·链表篇","uri":"/posts/redeis-server-list/"},{"categories":["Redis"],"content":"4.2 增查元素 4.2.1 增加元素 // n 为 head 时调用 // 即新增一个元素并把该元素置位 head func (n *listNode) addToHead(val string) *listNode { node := newListNode(val) n.prev = node node.next = n return node } // n 为 tail 时调用 // 即新增一个元素并把该元素置位 tail func (n *listNode) addToTail(val string) *listNode { node := newListNode(val) n.next = node node.prev = n return node } 以上两个方法配合下面两个 LPush和 RPush 方法使用： func (l *List) LPush(val string) { l.length++ // 如果list 内已经有元素，则把新增元素置位 head if l.head != nil { l.head = l.head.addToHead(val) return } // 当前 list 为空，则将新元素置位 head 和 tail node := newListNode(val) l.head = node l.tail = node } // 逻辑与上面一致 sssss func (l *List) RPush(val string) { l.length++ if l.tail != nil { l.tail = l.tail.addToTail(val) return } node := newListNode(val) l.head = node l.tail = node } 4.2.2 pop元素 基础方法： // pop head 元素 并返回下一个元素 // pop current node and return next node func (n *listNode) popAndNext() *listNode { var next = n.next // 将当前节点的 next 置位空 n.next = nil if next != nil { next.prev = nil } return next } // pop tail 元素 并返回下一个元素 // pop current node and return prev node func (n *listNode) popAndPrev() *listNode { var prev = n.prev n.prev = nil if prev != nil { prev.next = nil } return prev } 下面是真正实现 LPop, RPop 方法： // left pop 从左边 pop 一个元素 func (l *List) LPop() (val string, ok bool) { if l.head == nil { return \"\", false } l.length-- val = l.head.value l.head = l.head.popAndNext() if l.head == nil { l.tail = nil } return val, true } // right pop 从右边 pop 一个元素 func (l *List) RPop() (val string, ok bool) { if l.tail == nil { return \"\", false } l.length-- val = l.tail.value l.tail = l.tail.popAndPrev() if l.tail == nil { l.head = nil } return val, true } 4.2.3 查询元素 根据 value 查询第一个元素（list 内元素值是可以重复的，所以查询第一个值相同的元素） func (l *List) findNode(val string) *listNode { var cur = l.head for cur != nil { if cur.value == val { return cur } cur = cur.next } return nil } 根绝 index 查询元素 func (l *List) lIndexNode(i int) *listNode { if l.head == nil { return nil } // 支持反向查，即如果 i 小于 0 则认为是倒数第 i 个元素，把 i 该为正数第 i 个 if i \u003c 0 { i += l.length } if i \u003e= l.length || i \u003c 0 { return nil } var ( idx int cur = l.head reverse = i \u003e l.length/2+1 ) // 为了查询效率，做一个小小的优化 // 如果 i 在前半段则从头到尾的遍历，反之从尾到头 if reverse { idx = l.length - 1 cur = l.tail } for i != idx { if reverse { idx-- cur = cur.prev } else { idx++ cur = cur.next } } return cur } 4.2.4 删除元素 已经支持通过 value/index 查询元素了，就可以删除 list 内元素了，下面以从尾部开始删除 n 个元素为例： // i 表示 index 删除第 i 个元素 func (l *List) Rem(i int) int { node := l.lIndexNode(i) if node == nil { return 0 } p := node.prev n := node.next if p != nil { p.next = nil } else { // node 是 head 所以没有 prev l.head = n } if n != nil { n.prev = nil } else { // node 是 tail 所以没有 next l.tail = p } if l.head == nil || l.tail == nil { // 删除了最后一个元素了 l.head = nil l.tail = nil } l.length-- return 1 } ","date":"2021-12-24","objectID":"/posts/redeis-server-list/:4:2","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·链表篇","uri":"/posts/redeis-server-list/"},{"categories":["Redis"],"content":"4.3 高级特性 配合上面的一些基础方法以及链表的特性，可以写出不少花样玩法. 4.3.1 某个元素前后插入新元素 场景 1 Q: 假如我想在 list 内已知的元素的前面或后面新增一个元素，仅通过增删改查是做不到，有什么好的方法呢？ A: 其实还是通过遍历链表找到插入的位置 修改前后指向指针即可。 实现源码如下： // flag 大于 0 插入到 target 后面 小于 0 插入前面 func (l *List) LInsert(target, newValue string, flag int) bool { if l.head == nil { return false } // 找到元素 node := l.findNode(target) if node == nil { return false } if flag == 0 { node.value = newValue return true } newNode := \u0026listNode{value: newValue} l.length++ // insert after if flag \u003e 0 { next := node.next node.next = newNode newNode.prev = node if next == nil { l.tail = newNode } else { newNode.next = next next.prev = newNode } return true } // insert before prev := node.prev node.prev = newNode newNode.next = node if prev == nil { l.head = newNode } else { newNode.prev = prev prev.next = newNode } return true } 4.3.2 批量删除元素 从某个元素开始往后删除 N 个或删除所有元素。 // 从head 开始遍历删除 n 个值等于 value 的元素 func (l *List) LRemCountFromHead(value string, n int) (cnt int) { var ( dumbHead = \u0026listNode{ next: l.head, } // 引入虚拟 head 是为了 防止从第一个元素删除，然后需要频繁修改 l.head 的值 // 同时为了减少过多的特殊判断 prev = dumbHead cur = l.head next = l.head.next ) // 开始遍历 for cur != nil \u0026\u0026 n \u003e 0 { // 找打元素 if cur.value == value { // cur 前后的元素连接起来 prev.next = next if next != nil { next.prev = prev } // cur 指向前后的指针置位空 cur.prev, cur.next = nil, nil cnt++ n-- } else { // 只有在没有被删除元素时才移动 prev // *注意：prev 不能每次都移动，因为不确定下一个元素是不是也是要被删除的， // 只有确保 cur 不是我们要找的元素时候 才会同时移动三个指针* prev = prev.next } // dumHead 1 2 2 4 5 // ^ ^ ^ -\u003e\u003e // prev cur next // cur 和 next 往后移动 cur = next if next != nil { next = next.next } } // remove last element if prev.next == nil { l.tail = prev } l.head = dumbHead.next if l.head != nil { // if remove first element from, dumbHead.next.prev will be point to dumbHead // // In other words, l.head.tail will be not nil l.head.prev = nil } l.length -= cnt return } 4.3.3 局部遍历 场景 2 Q: 需要读取前几个或者后几个或者从第 N 个到第 M 个元素，但是不想 pop 出来怎么办？ 局部遍历的实现： func (l *List) LRange(start, stop int) (values []string) { if l.head == nil { return nil } // 这里需要支持负数，因为 Redis lrange 是支持负数 // 负数代表倒数第 N 个 if start \u003c 0 { start = start + l.length if start \u003c 0 { start = 0 } } // 需要处理一下负数 虽然客户端表达式倒数第 N 个 但是实现的时候都是统一从头遍历到尾 // 全部转换为正数 if stop \u003c 0 { stop = stop + l.length } // start already \u003e=0 , so if stop \u003c 0 then this case is true if start \u003e stop || start \u003e l.length { return nil } if stop \u003e= l.length { stop = l.length - 1 } var ( head = l.head idx int ) for head != nil \u0026\u0026 idx \u003c= stop { if idx \u003e= start { values = append(values, head.value) } idx++ head = head.next } return } ","date":"2021-12-24","objectID":"/posts/redeis-server-list/:4:3","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·链表篇","uri":"/posts/redeis-server-list/"},{"categories":["Redis"],"content":"5 总结 目前位置除了阻塞读取外，其他数据结构特性都以全部实现或者实现了底层方法 ，上面封装即可，完整代码请看 GitHub 项目。关于阻塞这块，由于服务端和客户端是长链接，所以实现其实比较简单，而且也属于数据结构的范畴，所以不再这里细讲，下面给出思路。 起一个 goroutine, 监听对应 key 的数据 有数据之前这次请求时不响应，知道返回正确结果或者客户端主动断开连接 拿到数据后，停止 goroutine, 响应客户端。 整体下来因为数据处理都是单进程，不需要考虑进程间资源竞争问题，代码相对简洁很多，注意增删元素时前后关系以及极限情况（边界的元素的修改）。 ","date":"2021-12-24","objectID":"/posts/redeis-server-list/:5:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·链表篇","uri":"/posts/redeis-server-list/"},{"categories":["Redis"],"content":"6 项目链接🔗 https://github.com/yusank/godis ","date":"2021-12-24","objectID":"/posts/redeis-server-list/:6:0","tags":["redis","系列篇","数据结构"],"title":"[系列]Redis Server 实现·链表篇","uri":"/posts/redeis-server-list/"},{"categories":["Go"],"content":" Go 已经确实在 1.18 版本支持泛型了，预计 2022 年 2 月份发布 1.18 正式版，到目前为止泛型相关规范已确定且可以在开发分支的 go 版本中尝试使用了，这篇文章带你领略 go 的泛型. ","date":"2021-12-09","objectID":"/posts/go-generic/:0:0","tags":["go1.18","泛型"],"title":"Go 泛型提前尝试","uri":"/posts/go-generic/"},{"categories":["Go"],"content":"安装 go 开发版 没有发版我怎么提前尝试呢？ 在这里分享一个小技巧，学会了之后以后每个新版本发布前都可以提前尝试新版的特性，提前学习好。 可以通过下面的命令安装最新的 master 分支： go install golang.org/dl/gotip gotip download 现在可以把 gotip 这个命令当做 go 命令来使用了， gotip version go version devel go1.18-d6c4583 Wed Dec 8 23:38:20 2021 +0000 linux/amd64 灵活使用 bash alias gotip 敲起来麻烦，总是习惯性打 go build/run , 我就在 .bashrc 添加了一行配置 alias go18=\"gotip\" # 如果你有单独的 workspace 直接用 go=\"gotip\" 也可以 ","date":"2021-12-09","objectID":"/posts/go-generic/:1:0","tags":["go1.18","泛型"],"title":"Go 泛型提前尝试","uri":"/posts/go-generic/"},{"categories":["Go"],"content":"泛型 ","date":"2021-12-09","objectID":"/posts/go-generic/:2:0","tags":["go1.18","泛型"],"title":"Go 泛型提前尝试","uri":"/posts/go-generic/"},{"categories":["Go"],"content":"基础用法 终于可以不用为 int/uint/int8/int16/int32/int64 写一堆代码类似的代码了！ type Integer interface{ ~uint|~uint8|~uint16|~uint32|~uint64|~int|~int8|~int16|~int32|~int64 } func Max[T Integer](a, b T) T { if a \u003e b { return a } return b } func main() { fmt.Println(Max(1, 2)) // 2 fmt.Println(Max(uint(1), uint(2))) // uint(2) fmt.Println(Max(int64(1), int64(2))) // 2 } 定义支持的类型 Integer, | 表示并集， ~ 表示底层是该类型也可以(type CustomInt int 这种情况)。这个就是最基础的基于泛型的代码了，是不是看着都不太像 go 代码了，哈哈。 其实， Integer 类型不需要我们定义了，go 官方新增了 constraints 包，放了一些常用的泛型类型，后期应该也会扩展。 // Copyright 2021 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. // Package constraints defines a set of useful constraints to be used // with type parameters. package constraints // Signed is a constraint that permits any signed integer type. // If future releases of Go add new predeclared signed integer types, // this constraint will be modified to include them. type Signed interface { ~int | ~int8 | ~int16 | ~int32 | ~int64 } // Unsigned is a constraint that permits any unsigned integer type. // If future releases of Go add new predeclared unsigned integer types, // this constraint will be modified to include them. type Unsigned interface { ~uint | ~uint8 | ~uint16 | ~uint32 | ~uint64 | ~uintptr } // Integer is a constraint that permits any integer type. // If future releases of Go add new predeclared integer types, // this constraint will be modified to include them. type Integer interface { Signed | Unsigned } // Float is a constraint that permits any floating-point type. // If future releases of Go add new predeclared floating-point types, // this constraint will be modified to include them. type Float interface { ~float32 | ~float64 } // Complex is a constraint that permits any complex numeric type. // If future releases of Go add new predeclared complex numeric types, // this constraint will be modified to include them. type Complex interface { ~complex64 | ~complex128 } // Ordered is a constraint that permits any ordered type: any type // that supports the operators \u003c \u003c= \u003e= \u003e. // If future releases of Go add new ordered types, // this constraint will be modified to include them. type Ordered interface { Integer | Float | ~string } 上面的代码可以简化为如下： import ( \"constraints\" ) func Max[T constraints.Integer](a, b T) T { if a \u003e b { return a } return b } func main() { fmt.Println(Max(1, 2)) // 2 fmt.Println(Max(uint(1), uint(2))) // uint(2) fmt.Println(Max(int64(1), int64(2))) // 2 } 当然如果想扩展也是完全可以，比如上面的 Max 方法要支持 float 类型的话，自己定义一个新的 interface 即可。 type Number interface{ constraints.Integer | constraints.Float } ","date":"2021-12-09","objectID":"/posts/go-generic/:2:1","tags":["go1.18","泛型"],"title":"Go 泛型提前尝试","uri":"/posts/go-generic/"},{"categories":["Go"],"content":"花式玩法 slice 如果你写 go 的时间长的话， 应该经历过写很多长得很像排序算法，也应该羡慕过python/js的直接 string.sort()这种写法的，现在用泛型也可以玩出同样的姿势了。废话不多说直接上货： type Slice[T constraints.Ordered] []T func (s Slice[T]) Sort() { sort.Slice(s,func (i,j int) bool { return s[i] \u003c s[j] }) } func main() { // 随时定义随时调用，没有过多的方法调用或者额外的条件判断了 ss := Slice[string]{\"b\",\"d\",\"c\",\"a\"} ss.Sort() fmt.Println(ss) is := Slice[int]{2,4,1,3} is.Sort() fmt.Println(is) } 这块代码运行成功后，我反正是很爽的，以后起码少些很多长得像功能还一样的代码了，等正式发版后可以搞一波支持泛型的基础库了。 map map 的 key-value 均可以指定泛型，从而灵活的做一些处理，下面以返回某个 map 的 key 作为数组的例子： // 定义一个 key 可以做对比的类型 value 作为任意类型 // 注： any == interface{} type Map[K constraints.Ordered, V any] map[K]V func (m Map[K,V]) Keys() []K { var result []K for k := range m { result = append(result, k) } return result } func main() { sm := Map[string,int]{\"a\":1,\"b\":2} fmt.Println(sm.Keys()) // [a, b] im := Map[int,string]{1:\"a\",2:\"b\"} fmt.Println(im.Keys()) // [1, 2] } 这样减少了很多类型判断类型转换的过程了，只要初始化的时候声明好了后返回的就是对应类型的数组而不是 []interface{} . chan chan 作为在高并发异步编程中非常常用的特性，之前也面领着同样类型转换类型判断的困扰，设想一个场景，如果我有个需求，将数组转换成 channel，异步的去处理这组数据，如果数组类型是单个还好 如果我又有 string 的又有 int 的未来可能还会有别的类型，那只能一个类型一个方法或者统一 interface 然后使用时类型转换。如果用泛型实现呢？ // 类型也可以按需求限制在 Ordered 或 comparable 等范围 func convertChan[T any](slice []T) chan T { ch := make(chan T, 1) go func() { defer close(ch) for _, v := range slice { ch \u003c- v } }() return ch } func main() { s1 := []string{\"a\", \"b\", \"c\"} // s2 := []float64{1.1, 1.2, 1.3} ch := convertChan(s1) // ch =\u003e chan string for v := range ch { fmt.Println(v) } // a, b, c } ","date":"2021-12-09","objectID":"/posts/go-generic/:2:2","tags":["go1.18","泛型"],"title":"Go 泛型提前尝试","uri":"/posts/go-generic/"},{"categories":["Go"],"content":"总结 总结 整体而言，新增的泛型我觉得利大于弊的，看起来是语法复杂了很多其实并没有，定义的时候限制一些可用的基础类型或者直接用 any 来表示接受任何类型的参数即可。 对于开发者来说绝对会减少一部分重复代码的，也可以做一些更好的抽象，从长远来说对开发者还是好处很多的。 1.18是第一个支持泛型的版本，肯定会谨慎一些，之后的版本该功能说不定会得到更多的扩展和支持，所以还是很期待的。 最后 如果你对泛型有自己不一样的看法或者用法，也可以来讨论讨论。 ","date":"2021-12-09","objectID":"/posts/go-generic/:3:0","tags":["go1.18","泛型"],"title":"Go 泛型提前尝试","uri":"/posts/go-generic/"},{"categories":["Go"],"content":"参考文档 https://bitfieldconsulting.com/golang/generics https://colobu.com/2021/10/24/go-generic-eliding-interface/ ","date":"2021-12-09","objectID":"/posts/go-generic/:4:0","tags":["go1.18","泛型"],"title":"Go 泛型提前尝试","uri":"/posts/go-generic/"},{"categories":["Redis"],"content":" 这一篇主要是将如何定义一个比较完善的服务入口以及如何管理服务的生命周期、如何处理 tcp 的连接管理和请求处理等相关内容。 说明 本文章为该系列的服务管理篇，如果需要阅读其他相关文章， 请点击这里跳转查看 ","date":"2021-12-06","objectID":"/posts/redis-server-network/:0:0","tags":["redis","系列篇","网络"],"title":"[系列]Redis Server 实现·服务管理篇","uri":"/posts/redis-server-network/"},{"categories":["Redis"],"content":"定义服务 该项目作为 Redis Server, 需要定义一个 Server 对象 作为服务启动关闭及请求处理的的入口。 type Server struct { addr string // 监听 ip:port handler api.Handler // 请求处理方法 listener net.Listener // 监听入口 } func NewServer(addr string, h api.Handler) *Server { return \u0026Server{ addr: addr, handler: h, } } ","date":"2021-12-06","objectID":"/posts/redis-server-network/:1:0","tags":["redis","系列篇","网络"],"title":"[系列]Redis Server 实现·服务管理篇","uri":"/posts/redis-server-network/"},{"categories":["Redis"],"content":"启动服务 正常监听 tcp 服务，并处理连接即可。 func (s *Server) Start() error { l, err := net.Listen(\"tcp\", s.addr) if err != nil { log.Println(\"listen err:\", err) return err } log.Println(\"listen: \", l.Addr()) s.listener = l // 阻塞处理 s.handleListener() return nil } ","date":"2021-12-06","objectID":"/posts/redis-server-network/:2:0","tags":["redis","系列篇","网络"],"title":"[系列]Redis Server 实现·服务管理篇","uri":"/posts/redis-server-network/"},{"categories":["Redis"],"content":"处理连接 之后便可以 accept 连接请求，处理请求。在每建立一个新的连接的时候，启动一个 goroutine 来处理该连接，从而支持高并发的请求。 // Server 内保存 net.Listener 等服务必要参数 func (s *Server) handleListener() { for { conn, err := s.listener.Accept() if err != nil { // 如果 listener 已被关闭则退出 if errors.Is(err, net.ErrClosed) { log.Println(\"closed\") break } log.Println(\"accept err:\", err) continue } log.Println(\"new conn from:\", conn.RemoteAddr().String()) // 处理该请求 go s.handleConn(conn) } } 处理逻辑如下： // handle by a new goroutine func (s *Server) handleConn(conn net.Conn) { defer func() { _ = conn.Close() }() // 初始化 Server 时，将 handler 也注册进来 // Handle 方法的核心逻辑时，读取请求内容，根据到 Redis 协议解析内容 // 并对这次请求做出响应并返回 reply reply, err := s.handler.Handle(reader) if err == io.EOF { return } if err != nil { log.Println(\"handle err:\", err) return } if len(reply) == 0 { return } _, err = conn.Write(reply) if err != nil { log.Println(\"write err:\", err) return } } ","date":"2021-12-06","objectID":"/posts/redis-server-network/:3:0","tags":["redis","系列篇","网络"],"title":"[系列]Redis Server 实现·服务管理篇","uri":"/posts/redis-server-network/"},{"categories":["Redis"],"content":"处理请求 上述处理逻辑中比较重要的一个逻辑是 handler.Handle(reader), 这里面是如何读取请求内容并解析协议的，下面将会以简化的代码逻辑 讲述处理逻辑： func (TCPHandler) Handle(r api.Reader) ([]byte, error) { // io data to protocol msg rec, err := protocol.DecodeFromReader(r) if err != nil { return nil, err } log.Println(rec) rsp := redis.NewCommandFromReceive(rec).Execute(context.Background()) log.Println(\"rsp:\", debug.Escape(string(rsp.Encode()))) return rsp.Encode(), err } // 1. 读取内容decode协议 type Receive []string func DecodeFromReader(r api.Reader) (rec Receive, err error) { rec = make([]string, 0) // read first line b, err := r.ReadBytes('\\n') if err != nil { log.Println(\"readBytes err:\", err) return nil, err } // decode line content str, length, desc, err := decodeSingleLine(b) if err != nil { log.Println(\"init message err:\", err) return nil, err } // 如果是 bulk 或者 array 则需要往下读取 length 行 // length 从第一行内容中解析出来 if desc == DescriptionBulkStrings { temp, err1 := readBulkStrings(r, length) if err1 != nil { log.Println(\"read bulk str err:\", err1) return nil, err1 } rec = append(rec, string(temp)) return } if desc == descriptionArrays { // won't sava array element items, err1 := readArray(r, length) if err1 != nil { log.Println(\"read bulk str err:\", err1) return nil, err1 } rec = append(rec, items...) return } rec = append(rec, str) return } // 2. 处理请求（处理 Redis 命令） rsp := redis.NewCommandFromReceive(rec).Execute(context.Background()) // 3. 处理结果 encode 成 Redis 协议 return rsp.Encode(), err 小结总结 至此，一个简单的 server 端的能力基本都有了，从服务启动到监听端口、处理连接、处理请求以及响应。 但是问题也很多： 请求处理完连接会断开，需要支持长链接 服务启动后直接阻塞主线程，且没有优雅退出逻辑，导致服务关闭时可能存在请求未处理完的情况 goroutine 无限开启并不能更好的处理和管理 下面针对以上问题进行一步步优化。 ","date":"2021-12-06","objectID":"/posts/redis-server-network/:4:0","tags":["redis","系列篇","网络"],"title":"[系列]Redis Server 实现·服务管理篇","uri":"/posts/redis-server-network/"},{"categories":["Redis"],"content":"更完善的服务定义 type Server struct { addr string // 新增支持 context 从而更好的控制上下文和下游 goroutine ctx context.Context cancel context.CancelFunc handler api.Handler listener net.Listener // 新增 WaitGroup 更好控制并发和退出逻辑 wg *sync.WaitGroup } Question 单从服务定义看不出来太多的变化，即便新增几个字段又能如何解决上面的问题呢？ ","date":"2021-12-06","objectID":"/posts/redis-server-network/:5:0","tags":["redis","系列篇","网络"],"title":"[系列]Redis Server 实现·服务管理篇","uri":"/posts/redis-server-network/"},{"categories":["Redis"],"content":"更优雅的服务启停 服务启动和运行过程中感知到服务以外的一些数据才能在一些特殊情况下更从容的 handle 住问题。这个服务以外的数据一般就是系统的信号量(Signal) .除此之外还需要关心下游的 goroutine 的情况，在下游服务遇到不可控的 Fatel 事件时，上游服务需要做判断是否要关闭服务。在主 server 需要关停时，需要让下游服务感知到且给下游 goroutine 处理的时间但又得有一定的时间控制 不能无限期等待，这些都是需要考虑的问题。 ","date":"2021-12-06","objectID":"/posts/redis-server-network/:6:0","tags":["redis","系列篇","网络"],"title":"[系列]Redis Server 实现·服务管理篇","uri":"/posts/redis-server-network/"},{"categories":["Redis"],"content":"主 server 的启停 func (s *Server) Start() error { // 监听信号量 sigChan := make(chan os.Signal, 1) signal.Notify(sigChan, syscall.SIGTERM, syscall.SIGINT, syscall.SIGQUIT) l, err := net.Listen(\"tcp\", s.addr) if err != nil { log.Println(\"listen err:\", err) return err } log.Println(\"listen: \", l.Addr()) s.listener = l // 起一个 goroutine 去等待信号量或 ctx 的结束 go func() { select { case \u003c-s.ctx.Done(): log.Println(\"kill by ctx\") return case sig := \u003c-sigChan: s.Stop() log.Printf(\"kill by signal:%s\", sig.String()) return } }() //阻塞处理连接 s.handleListener() return nil } // Stop 可以被 Start 方法调用也可以被 main 的其他协程调用 func (s *Server) Stop() { s.cancel() _ = s.listener.Close() } ","date":"2021-12-06","objectID":"/posts/redis-server-network/:6:1","tags":["redis","系列篇","网络"],"title":"[系列]Redis Server 实现·服务管理篇","uri":"/posts/redis-server-network/"},{"categories":["Redis"],"content":"下游 handler 的启停 处理连接时，由sync.WaitGroup 控制 goroutine，这样可以在某个连接还未处理完成时，可以继续阻塞， 从而做到服务关闭时等待未处理的请求。 func (s *Server) handleListener() { for { conn, err := s.listener.Accept() if err != nil { if errors.Is(err, net.ErrClosed) { log.Println(\"closed\") break } log.Println(\"accept err:\", err) continue } log.Println(\"new conn from:\", conn.RemoteAddr().String()) s.wg.Add(1) go s.handleConn(conn) } // wait for unDone connections s.wg.Wait() } 在处理连接上的请求时，通过 for 循环一直读取连接上的内容，如果客户端没有写入消息则会阻塞，如何客户端主动关闭连接则会读取 EOF 错误。没处理完一次请求先判断服务是否已关闭，因为上次很有可能已经关闭且停止监听端口，等待下游剩下请求处理完成。 // handle by a new goroutine func (s *Server) handleConn(conn net.Conn) { reader := bufio.NewReader(conn) // ReceiveDataAsync 返回一个结构体包含两个 channel，实际读取数据是异步的 ar := protocol.ReceiveDataAsync(reader) loop: for { select { // ctx // 处理完上一个请求后 如果 ctx 已经被 cancel 了 则退出循环结束这个 connection case \u003c-s.ctx.Done(): break loop case \u003c-ar.ErrorChan: log.Println(\"handle err:\", err) break loop case rec := \u003c-ar.ReceiveChan: rsp := handleRequest(rec) reply := rsp.Encode() if len(reply) == 0 { continue } _, err := conn.Write(reply) if err != nil { log.Println(\"write err:\", err) break loop } } } _ = conn.Close() s.wg.Done() } func ReceiveDataAsync(r Reader) *AsyncReceive { var ar = \u0026AsyncReceive{ ReceiveChan: make(chan Receive, 1), ErrorChan: make(chan error, 1), } go func() { defer func() { close(ar.ReceiveChan) close(ar.ErrorChan) }() for { rec, err := DecodeFromReader(r) if err != nil { ar.ErrorChan \u003c- err if errors.Is(err, io.EOF) || errors.Is(err, net.ErrClosed) { return } log.Println(err) continue } ar.ReceiveChan \u003c- rec } }() return ar } 总结 到这里本篇内容结束了，总结一下讲述的内容： 作为一个 server 端，在定义和提供服务时需要注意哪些方面？ 在处理连接和请求时需要注意哪些问题？ 如何管理一个服务的生命周期，如从从上到下都能确保统一的启停，相互作用彼此感知？ 项目地址 ❤️ https://github.com/yusank/godis ","date":"2021-12-06","objectID":"/posts/redis-server-network/:6:2","tags":["redis","系列篇","网络"],"title":"[系列]Redis Server 实现·服务管理篇","uri":"/posts/redis-server-network/"},{"categories":["Markdown"],"content":" 这里我会记录一些 Markdown 和 Shortcut 的使用技巧以及常用的模块，方便后期写文章时查看和使用。 ","date":"2021-11-23","objectID":"/posts/blog_example/:0:0","tags":["技巧"],"title":"好用且实用的写文章技巧","uri":"/posts/blog_example/"},{"categories":["Markdown"],"content":"shortcuts ","date":"2021-11-23","objectID":"/posts/blog_example/:1:0","tags":["技巧"],"title":"好用且实用的写文章技巧","uri":"/posts/blog_example/"},{"categories":["Markdown"],"content":"admonition Note This is Note . Abstract This is Abstract . Info This is Info . Tip This is Tip . Success This is Success . Question This is Question . Warning This is Warning . Failure This is Failure . Danger This is Danger . Bug This is Bug . Example This is Example . Quote This is Quete . ","date":"2021-11-23","objectID":"/posts/blog_example/:1:1","tags":["技巧"],"title":"好用且实用的写文章技巧","uri":"/posts/blog_example/"},{"categories":["Markdown"],"content":"typeit markdown code Bug 这块目前发现是有 bug 的，不会换行，所以暂时不可用。 graph ","date":"2021-11-23","objectID":"/posts/blog_example/:1:2","tags":["技巧"],"title":"好用且实用的写文章技巧","uri":"/posts/blog_example/"},{"categories":["Redis"],"content":"说明 本文章为该系列的协议篇，如果需要阅读其他相关文章， 请点击这里跳转查看 ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:0:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"前言 Redis 作为一个当下最流行的 NoSQL 或 KV 数据库，几乎嵌入到大部对性能、时效性高的项目内，变成了每个程序员尤其是后端程序必需了解的一个知识点。 我是无形在 GitHub 上发现一个 Godis 项目，是实现了大部分 Redis 服务器的功能。 然后瞬间激发了我的兴趣，既然用了 Redis 这些年了而且对核心逻辑和数据结构也是有所了解的，那我为什么不也写一个基于 Go 的 Redis 服务器代码，实现我能实现的核心功能逻辑。目的无外乎以下几点： 更全面且系统的了解Redis 核心逻辑并把自己的了解通过代码输出出来 提高自己的代码水平 提高自己的算法水平（涉及到实现 Redis 核心五大数据结构） 所以我也起了一个项目叫 Godis,一步步将 Redis 的逻辑通过Go 代码写出来，并且在性能上尽可能的追赶 Redis 的性能。 前期我更专注于最核心的 请求处理, 协议处理, 数据结构处理, 命令处理 等这些基础核心的模块一个个攻破，至于数据持久化，分布式部署，主从模式等这些高级特性，我在确保之前的功能都达到预期后再考虑，目前计划是数据持久化可能优先考虑。 ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:1:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"协议 想实现 Redis 服务器首先想到的问题是，如何通信？其实都知道是 tcp 连接，所以更准确的问题是，客户端和服务端用的什么协议去传输数据？答案是 RESP (REdis Serialization Protocol）。 该协议从内容来说还是比较简单的，对于服务端去解析也是相对友好且消耗性能很低。官方给出的优点为以下三点： 容易实现 解析快 可读性高 RESP 协议为一个 request-response 模型的协议，客户端发出请求并等待服务器响应，服务器按同样的协议返回数据。下面我们来看一下协议具体内容。 ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:2:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"基础说明 在 RESP 协议中，所有的数据的第一字符都是以下五种类型之一： + : 简单字符串. - : 错误. : : 整数. $ : 复杂字符串或大块字符串(bulk string). * : 数组. 数据结尾 任何一个类型的数据都是以 \"\\r\\n\"(CRLF)作为结束符. 本文中的大部分示例均来自官方文档。 ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:3:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"简单字符串(Simple Strings) 简单字符串以 + 符号开始，然后字符内容（不能包含 CR 或 LF，即不能有换行符），以 CRLF(\"\\r\\n\") 结尾。简单字符不适合传输数据(non binary safa)，在 Redis 内基本用于响应 \"OK\" 或成功标识。 简单字符串 “+OK\\r\\n” 为了安全起见，Redis 内传输数据会用 Bulk Strings . ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:4:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"错误(Errors) RESP 预留专门的错误类型。其实错误类型与简单字符串几乎没区别，只是第一个字符是 -, 除此之外在处理和编码过程均无区别，更多的区别在于客户端处理上。 Errors “-Error Message\\r\\n” Errors 类型只用于在处理请求遇到错误时，响应到客户端，比如命令不存在或命令与 key 的类型不符合等。客户端应该针对错误做一层处理，方便使用者感知到错误。 另一个 Errors 的例子 -ERR unknown command ‘foobar’ -WRONGTYPE Operation against a key holding the wrong kind of value 从 - 到第一个空格或新一行的单词代表返回的错误的类型。这个是 Redis 的一个响应习惯(convention)，将错误分类型，方便客户端更灵活的处理。 以上面的例子为例， ERR 是一个通用的错误，而 WRONGTYPE 是一个具体的错误类型，代表命令和 key 的类型不匹配,这个叫错误前缀Error Prefix。站在客户端角度来说，相对于一串错误字符串，拿到一个具体的错误类型无异于拿到一个 error code 一样，可以做一个具体的操作来消化这个错误。 当然如果分的错误类型很细 那客户端就得写的更复杂反而可能会导致得不偿失，抛开 Redis 的习惯从协议的角度来说，可以在非常简单的返回一个 false 来说明一个错误或者就一行错误内容，返回给用户，这个更多的取决于客户端实现的时候的取舍。 ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:5:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"整数(Integers) 该类型与上述两个类型也没有很大的区别，是为了专门传输整数而定的，以: 字符为开头，内容为整数且以\\r\\n 结尾，如 \":100\\r\\n\" 。 数字范围 有符号 64 位整数 Redis 中像 INCR, LLEN 和 LASTSAVE 等命令都返回整数。当然返回整数没有别的意义，只是这些命令的结果是数字。 除了命令结果是整数时返回 Integer 类型外，一些命令用整数 0 or 1 来表示 true or false,如 EXISTS, SISMEMBER。 还有一些命令是返回 1 表示操作真正执行(这么说是因为，一些操作因为数据已存在或已被操作所以不会再次操作数据而直接返回),否则返回 0 ，像 SADD, SREM, SETNX 等。 ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:6:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"复杂字符串(Bulk Strings) 复杂字符串为 RESP 中二进制安全的字符串类型，最大容量为 512MB。bulk string 编码方式如下： 以 $为开头写入实际字符串长度并以 CRLF 结尾 实际字符串 CRLF 结束 以 Hello 为例 “$5\\r\\nHello\\r\\n” 空字符 “$0\\r\\n\\r\\n” 前面说到简单字符串 不能包好换行符，然而 Bulk String是允许包含这类特殊字符的，因为读取 Bulk String 是根据其定义的长度来读取的，而不是根据换行符。 包含换行符的例子 “$4\\r\\nOK\\r\\n\\r\\n” 这是一个有效的复杂字符串其内容是 OK\\r\\n包含四个字符。 注意：$4\\r\\nOK\\r\\n\\r\\n, 下划线才是字符串内容 Bulk String 支持 Null 值（注意不是空字符）以此来区分数据不存在的情况。Null 的情况下不存在数据，所以长度为-1（-1 是协议定的，具体为什么是-1 I hava no idea .), 没有数据部分也没有数据最后的 CRLF（空字符是有的，这个需要注意的） Null 响应 “$-1\\r\\n” 官方原文： This is called a Null Bulk String. ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:7:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"数组(Arrays) 客户端的所有请求都是以数组的方式传到服务端的，而服务端的响应如果是多个值也都是以数组的方式响应。比如 ZRANGE, LRANGE, MGET 等。 数组(Arrays) 是以下方式编码的： 以 * 作为第一个字符，然后写入数组的长度，最后以 CRLF 结尾. 一组 RESP 类型的数据作为数组的元素. 空数组 “*0\\r\\n” 包含 foo 和 bar 两个 bulk string 作为元素的数组 “*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n” 为了阅读方便加上换行符： *2\\r\\n $3\\r\\n foo\\r\\n $3\\r\\n bar\\r\\n 不难发现，数组只需要声明长度即可，后面拼接元素就可以，元素之前无需有任何分隔符，元素可以是简单字符串, Errors, 整型,复杂字符串。下面例子更明显体现如何使用包含不用元素的数组： 混合元素例子 *5\\r\\n :1\\r\\n :2\\r\\n +SimpleString\\r\\n -Err Message\\r\\n $6\\r\\n foobar\\r\\n ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:8:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"Null数组 与复杂字符串一样，数组也支持表示 Null 值，在 BLPOP 命令中，如果操作超时，则返回一个 Null 数组表示结果： Null Array “*-1\\r\\n” 实现客户端时，应该考虑并区分开空数组和 Null 数组（如无数据或操作超时）应该有不同的处理方式。 ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:8:1","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"嵌套 数组是支持其元素也是数组的，如下面是一个包含两个数组作为元素的数组： 嵌套数组 *2\\r\\n *3\\r\\n :1\\r\\n :2\\r\\n :3\\r\\n *2\\r\\n +Foo\\r\\n -Bar\\r\\n 把 RESP 协议转换成可读性更高的数据后： 解码后 [[1, 2, 3], [\"Foo\", Error(\"Bar\")]] ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:8:2","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"包含 Null 元素的数组 在与 Redis 交互时, 一部分命令是操作多个 key，返回多个值的，这个时候就有个问题，其中一些操作不成功或数据不存在， 该不该影响这次请求的整体结果呢？ 以 MGET 这个命令为例，如果获取多个 key 的值，而其中有一部分 key 是不存在时，Redis 在响应中留 null 值从而不影响其他 key 的读取，协议如下： 包含 Null 元素 *3\\r\\n $3\\r\\n foo\\r\\n $-1\\r\\n $3\\r\\n bar\\r\\n 客户端针对该响应解析出来的结果应该如下： 解码后 [\"foo\", nil, \"bar\"] ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:8:3","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"客户端服务端交互 到目前为止，RESP 协议的内容全部说完了，发现其实蛮简单的。其实现在去实现一个客户端的代码比实现服务端的简单很多，因为只需要编码解码协议内容即可。 服务端和客户单交互最核心就是以下两点： 客户端向服务端发起请求均为以 Bulk Strings 作为元素的数组. 服务端向客户端响应任意合法的 RESP 数据类型. 以 LLEN mylist 为例： 一次交互过程 C: *2\\r\\n C: $4\\r\\n C: LLEN\\r\\n C: $6\\r\\n C: mylist\\r\\n S: :48293\\r\\n C: client， S:server ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:9:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"高效解析协议 该协议可读性相对高，与此同时解析效率也很高，下面给出如何解析该协议. import ( \"bytes\" \"log\" \"io\" ) func main() { var p = []byte(\"$5\\r\\nHello\\r\\n\") buf := bytes.NewBuffer(p) // read first line b, err := buf.ReadBytes('\\n') if err != nil { panic(err) } // read length ln := readBulkOrArrayLength(b) log.Println(\"string len: \",ln) // string len: 5 // read value value,err := readBulkStrings(buf, ln) if err != nil { panic(err) } log.Println(\"value: \", string(value)) // value: Hello } // 解析长度 func readBulkOrArrayLength(line []byte) int { var ( ln int ) for i := 1; line[i] != '\\r'; i++ { ln = (ln * 10) + int(line[i]-'0') } return ln } // 读取内容 func readBulkStrings(r io.Reader, ln int) (val []byte, err error) { if ln \u003c= 0 { return } // 读取时 将 \\r\\n 也读出来，保证 offset 在新的一行第一个字符 val = make([]byte, ln+2) _, err = r.Read(val) // trim last \\r\\n val = val[:ln] return } ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:10:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":"参考文献 https://redis.io/topics/protocol ","date":"2021-11-23","objectID":"/posts/redis-server-protocol/:11:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·协议篇","uri":"/posts/redis-server-protocol/"},{"categories":["Redis"],"content":" 本文系列篇Redis Server 实现的开篇文章，将列出本系列篇讲述的内容和实现的功能做简单的描述。 ","date":"2021-11-22","objectID":"/posts/redeis-server-introduction/:0:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·前言","uri":"/posts/redeis-server-introduction/"},{"categories":["Redis"],"content":"核心内容 系列篇将会分步骤讲述如何通过 Go 语言实现一个 Redis Server 并能达到可使用的地步的过程，到目前为止的想法是分 以下几个步骤实现并写出对应的总结文章： 协议篇·Redis 协议的介绍和如何解析 网络篇·如何提供一个高性能的 TCP 服务 数据结构篇·如何实现 Redis 五大数据结构（这个可能根据篇幅大小分几篇文章） 代码结构篇·如何实现和优化从请求进来到数据处理和响应过程 测试篇·如何做一个性能测试和测试结果对比 完结篇·总结开发和设计过程中遇到的问题和新的、 除以上的计划写的文章外 可能会写一些开发过程中遇到的问题结果过程或一些心得也会不定时更新 ","date":"2021-11-22","objectID":"/posts/redeis-server-introduction/:1:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·前言","uri":"/posts/redeis-server-introduction/"},{"categories":["Redis"],"content":"文章传送门 协议篇 服务管理篇 网络篇(网络模型，未发布) 数据结构·链表篇 数据结构·跳表篇 数据结构·哈希表篇 日志篇(未发布) 项目经验总结(未发布) 待补充 ","date":"2021-11-22","objectID":"/posts/redeis-server-introduction/:2:0","tags":["redis","系列篇"],"title":"[系列]Redis Server 实现·前言","uri":"/posts/redeis-server-introduction/"},{"categories":["网关"],"content":" 分享如何在 docker 环境部署 apisix 和如何开发 lua 和 go 语言的插件以及如何使用这些自定义插件的过程，希望能帮助到你。 ","date":"2021-11-03","objectID":"/posts/apisix_plugins/:0:0","tags":["lua","go","apisix"],"title":"apisix 开发自定义插件","uri":"/posts/apisix_plugins/"},{"categories":["网关"],"content":"如何部署 # 1. 下载官方 docker compose 项目 $ git clone https://github.com/apache/apisix-docker.git $ cd apisix-docker/example # 2. run docker compose $ docker-compose -p docker-apisix up -d # check docker ps $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 629eb9d85656 627d00c649fc \"sh -c '/usr/bin/api…\" 24 seconds ago Up 20 seconds 0.0.0.0:9080-\u003e9080/tcp, :::9080-\u003e9080/tcp, 0.0.0.0:9091-9092-\u003e9091-9092/tcp, :::9091-9092-\u003e9091-9092/tcp, 0.0.0.0:9443-\u003e9443/tcp, :::9443-\u003e9443/tcp docker-apisix_apisix_1 c3cbca636e65 13afb861111c \"/run.sh\" 24 seconds ago Up 22 seconds 0.0.0.0:3000-\u003e3000/tcp, :::3000-\u003e3000/tcp docker-apisix_grafana_1 4a5cb9ad6239 5b0292a5e821 \"/usr/local/apisix-d…\" 24 seconds ago Up 22 seconds 0.0.0.0:9000-\u003e9000/tcp, :::9000-\u003e9000/tcp docker-apisix_apisix-dashboard_1 6430826c4095 8c7e00e786b8 \"/opt/bitnami/script…\" 24 seconds ago Up 21 seconds 0.0.0.0:2379-\u003e2379/tcp, :::2379-\u003e2379/tcp, 2380/tcp docker-apisix_etcd_1 c086d6e4fbd9 a618f5685492 \"/bin/prometheus --c…\" 24 seconds ago Up 22 seconds 0.0.0.0:9090-\u003e9090/tcp, :::9090-\u003e9090/tcp docker-apisix_prometheus_1 1e6ea10c008f 7d0cdcc60a96 \"/docker-entrypoint.…\" 24 seconds ago Up 21 seconds 0.0.0.0:9082-\u003e80/tcp, :::9082-\u003e80/tcp docker-apisix_web2_1 d4891bd0744e 7d0cdcc60a96 \"/docker-entrypoint.…\" 24 seconds ago Up 22 seconds 0.0.0.0:9081-\u003e80/tcp, :::9081-\u003e80/tcp docker-apisix_web1_1 部署完成，可以通过 localhost:9000 访问 dashboard。 ","date":"2021-11-03","objectID":"/posts/apisix_plugins/:1:0","tags":["lua","go","apisix"],"title":"apisix 开发自定义插件","uri":"/posts/apisix_plugins/"},{"categories":["网关"],"content":"配置 默认配置文件在 apisix-docker/example/apisix_conf 目录下。 apisix:node_listen:9080# APISIX listening portenable_ipv6:falseallow_admin:# http://nginx.org/en/docs/http/ngx_http_access_module.html#allow- 0.0.0.0/0 # We need to restrict ip access rules for security. 0.0.0.0/0 is for test.admin_key:- name:\"admin\"key:edd1c9f034335f136f87ad84b625c8f1# 这个值需要改的否则有安全隐患role: admin # admin:manage all configuration data# viewer: only can view configuration data- name:\"viewer\"key:4054f7cf07e344346cd3f287985e76a2role:viewerenable_control:truecontrol:ip:\"0.0.0.0\"port:9092etcd:host:# it's possible to define multiple etcd hosts addresses of the same etcd cluster.- \"http://etcd:2379\"# multiple etcd addressprefix:\"/apisix\"# apisix configurations prefixtimeout:30# 30 secondsplugin_attr:prometheus:export_addr:ip:\"0.0.0.0\"port:9091 ","date":"2021-11-03","objectID":"/posts/apisix_plugins/:2:0","tags":["lua","go","apisix"],"title":"apisix 开发自定义插件","uri":"/posts/apisix_plugins/"},{"categories":["网关"],"content":"插件 ","date":"2021-11-03","objectID":"/posts/apisix_plugins/:3:0","tags":["lua","go","apisix"],"title":"apisix 开发自定义插件","uri":"/posts/apisix_plugins/"},{"categories":["网关"],"content":"lua 官方开发教程 示例插件： local ngx = ngx local core = require(\"apisix.core\") local plugin = require(\"apisix.plugin\") local upstream = require(\"apisix.upstream\") -- 定义配置，即使用插件时 配置一些自定义字段，如鉴权的 key，需要校验的 header 之类的 local schema = { type = \"object\", properties = { value = {type = \"array\", minItems = 1} }, required = {\"value\"} } -- 这个需要了解一下干什么的 local metadata_schema = { type = \"object\", properties = { ikey = {type = \"number\", minimum = 0}, skey = {type = \"string\"} }, required = {\"ikey\", \"skey\"} } local plugin_name = \"block_by_lua\" local _M = { version = 0.1, priority = 0, name = plugin_name, schema = schema, metadata_schema = metadata_schema } function _M.check_schema(conf, schema_type) if schema_type == core.schema.TYPE_METADATA then return core.schema.check(metadata_schema, conf) end return core.schema.check(schema, conf) end function _M.init() -- call this function when plugin is loaded core.log.info(plugin_name, \"loaded!\") end function _M.destroy() -- call this function when plugin is unloaded end -- uri 重写阶段 如果不需要就不用定义这个方法 --[[ function _M.rewrite(conf, ctx) core.log.warn(\"plugin rewrite phase, conf: \", core.json.encode(conf)) core.log.warn(\"conf_type: \", ctx.conf_type) core.log.warn(\"conf_id: \", ctx.conf_id) core.log.warn(\"conf_version: \", ctx.conf_version) end --]] --命中服务 \u0026 调服务前 function _M.access(conf, ctx) core.log.warn(\"plugin access phase, conf: \", core.json.encode(conf)) core.log.warn(\"plugin access phase, ctx: \", core.json.encode(ctx, true)) -- return 200, {message = \"hit example plugin\"} -- 1. extract from header local pass = core.request.header(ctx, \"X-Block-Pass\") if not pass then core.response.set_header(\"X-Block-Flag\", \"Block By Lua Ext\") -- 返回 http 状态码 则这次请求截止到当前插件，不会往下走 return 403, {message = \"Missing pass value in header\"} end for _, val in pairs(conf.value) do if val == pass then -- return 空表示通过 return end end core.response.set_header(\"X-Block-Flag\", \"Block By Lua Ext\") return 403, {message = \"Invalid pass value in header.\"} end local function hello() local args = ngx.req.get_uri_args() if args[\"json\"] then return 200, {msg = \"world\"} else return 200, \"world\\n\" end end function _M.control_api() return { { -- 注册 controller api 用于探测插件是否插入成功，也可以用于内部一些返回 token 之类的用处 methods = {\"GET\"}, uris = {\"/v1/plugin/example-plugin/hello\"}, handler = hello } } end return _M 如何安装： 创建目录 ├── example │ └── apisix │ ├── plugins │ │ └── 3rd-party.lua │ └── stream │ └── plugins │ └── 3rd-party.lua 配置文件(config.yaml)添加插件目录 apisix:...extra_lua_path:\"/path/to/example/?.lua\" 开启插件(config.yaml) apisix:...plugins:# 从 config-default.yaml 文件复制出来，然后加上自己的插件...- your-plugin Q:如何在dashboard 看到自己的插件？ A: 目前自定义插件不支持自动同步到 dashboard，需要手动添加，步骤如下： 在 apisix 机器上执行如下命令获取最新 json scheme： $ curl 127.0.0.1:9092/v1/schema \u003e scheme.json 2. 将 `scheme.json` 复制到 dashboard 机器上 `conf` 目录下与原有的文件替换，重启 dashboard 服务。 ","date":"2021-11-03","objectID":"/posts/apisix_plugins/:3:1","tags":["lua","go","apisix"],"title":"apisix 开发自定义插件","uri":"/posts/apisix_plugins/"},{"categories":["网关"],"content":"go 官方开发教程 示例代码： package plugins import ( \"encoding/json\" \"net/http\" pkgHTTP \"github.com/apache/apisix-go-plugin-runner/pkg/http\" \"github.com/apache/apisix-go-plugin-runner/pkg/log\" \"github.com/apache/apisix-go-plugin-runner/pkg/plugin\" ) // 初始化 func init() { // 注册插件 err := plugin.RegisterPlugin(\u0026BlockReq{}) if err != nil { log.Fatalf(\"failed to register plugin block-req: %s\", err) } } // LimitReq is a demo for a real world plugin type BlockReq struct { } // 与 lua 插件内 scheme 一样 type BlockReqConf struct { Key string `json:\"key\"` Value []string `json:\"value\"` } func (p *BlockReq) Name() string { return \"blcok-req\" } // ParseConf is called when the configuration is changed. And its output is unique per route. func (p *BlockReq) ParseConf(in []byte) (interface{}, error) { conf := BlockReqConf{} err := json.Unmarshal(in, \u0026conf) return conf, err } // Filter is called when a request hits the route func (p *BlockReq) Filter(conf interface{}, w http.ResponseWriter, r pkgHTTP.Request) { b := conf.(BlockReqConf) val := r.Header().Get(b.Key) for _, v := range b.Value { if val == v { r.Header().Set(\"X-Block-Value\", v) return } } // block request // 只要写 response 的 header 或body，请求将停在这里不会往下传递，直接响应回去 w.Header().Add(\"X-Block-Req\", \"Block by Go ext.\") w.WriteHeader(http.StatusForbidden) } 编译部署 用官方提供的 Makefile 进行 build（注意编译环境和apisix 运行的环境，指定对应的 GOOS，GOARCH） 将编译好的二进制文件打包到 apisix 的容器内 修改配置文件 ext-plugin:cmd:[\"/path/to/apisix-go-plugin-runner/go-runner\",\"run\"] 注意：一个 go-runner 内可以注册多个插件，所以不需要拥有多个 go-runner ,所有的插件在一个项目里 然后统一编译部署即可 使用 非 lua 插件都运行在各自的 runner 内，所以使用的时候不能直接在 dashboard 中使用自定义的插件（lua 的自定义插件是可以的），需要在 ext-plugin-pre-req, ext-plugin-post-req 两个插件内配置使用，这两插件只有运行时间不一样，一个在所有插件之前 一个在所有插件之后。使用时配置如下: \"plugins\": { \"ext-plugin-pre-req\": { \"conf\": [ { \"name\": \"blcok-req\", // 注册的 go 插件名字 \"value\": \"{\\\"key\\\":\\\"pass\\\", \\\"value\\\":[\\\"word\\\",\\\"port\\\"]}\" // 该插件的 conf，这里需要将 json 进行转义 } ], \"disable\": false } } ","date":"2021-11-03","objectID":"/posts/apisix_plugins/:3:2","tags":["lua","go","apisix"],"title":"apisix 开发自定义插件","uri":"/posts/apisix_plugins/"},{"categories":["网关"],"content":"wasm apisix 开始支持 wasm 插件，但是官方给出的示例和文档还不够完善，这块还在研究中，之后会补齐。 ","date":"2021-11-03","objectID":"/posts/apisix_plugins/:3:3","tags":["lua","go","apisix"],"title":"apisix 开发自定义插件","uri":"/posts/apisix_plugins/"},{"categories":["网关"],"content":" 本文简单介绍如何通过 lua 脚本和 ngx_shared_dict 在 nginx 中动态加载后端服务配置以及动态更新服务配置. ","date":"2021-09-17","objectID":"/posts/nginx-lua-plugins/:0:0","tags":["nginx","lua"],"title":"nginx 中使用 lua 动态加载服务配置","uri":"/posts/nginx-lua-plugins/"},{"categories":["网关"],"content":"nginx ","date":"2021-09-17","objectID":"/posts/nginx-lua-plugins/:1:0","tags":["nginx","lua"],"title":"nginx 中使用 lua 动态加载服务配置","uri":"/posts/nginx-lua-plugins/"},{"categories":["网关"],"content":"加载 lua 脚本 在 Nginx 中需要引入和加载 lua 脚本，从而在路由转发时运行 lua 脚本进行我们的逻辑。初始化代码如下： http { lua_shared_dict endpoints_data 5m; #定义upstream共享内存空间 lua_shared_dict cache 1m; #定义计数共享空间 access_log nginx_access.log; lua_package_path \"/etc/nginx/lua/?.lua;;\"; init_by_lua_block { collectgarbage(\"collect\") local ok, res # 加载脚本 configuration.lua ok, res = pcall(require, \"configuration\") if not ok then error(\"require failed: \" .. tostring(res)) else configuration = res end } # 执行脚本内初始化方法，这里为可选项，如果没有可初始化的代码部分 这里可以不要 init_worker_by_lua_block { configuration.prepare() }} ","date":"2021-09-17","objectID":"/posts/nginx-lua-plugins/:1:1","tags":["nginx","lua"],"title":"nginx 中使用 lua 动态加载服务配置","uri":"/posts/nginx-lua-plugins/"},{"categories":["网关"],"content":"执行 lua 脚本 如何在 Nginx 配置中执行 lua 脚本，从而实现一些特殊逻辑？这里给出一个简单的示例: server { # 执行最简单的 lua 脚本 location /hello { default_type 'text/plain'; content_by_lua 'ngx.say(\"hello, lua\")'; } # 配置接口 # 这里是执行加载的 lua 脚本中方法 location /configuration { client_max_body_size 5m; client_body_buffer_size 1m; proxy_buffering off; content_by_lua_block { configuration.call() # 调用 call() 方法 } } # 执行较为复杂的 lua 逻辑 location /lua { default_type 'text/plain'; # 读取请求中的 path 参数 并从共享 dict 中查询这个值， # 返回查询到的结果 content_by_lua ' local path = ngx.req.get_uri_args()[\"path\"] if path == nil then ngx.say(\"path not found\") return end local data = ngx.shared.endpoints_data:get(\"/\"..path) if not data then ngx.say(\"unkonw path\") return end ngx.say(\"paths: \"..data) '; }} lua 的语法相对简单好上手，实现一些简单的逻辑也很方便，非常值得学习。 ","date":"2021-09-17","objectID":"/posts/nginx-lua-plugins/:1:2","tags":["nginx","lua"],"title":"nginx 中使用 lua 动态加载服务配置","uri":"/posts/nginx-lua-plugins/"},{"categories":["网关"],"content":"完整配置 先给出 Nginx 的完整配置，里面包括动态配置后端服务列表和动态加载服务转发的逻辑，然后再给出 lua 部分详细实现的代码。 user nginx;worker_processes 1;pid /var/run/nginx.pid;error_log nginx_error.log;events { worker_connections 1024;}http { lua_shared_dict endpoints_data 5m; #定义upstream共享内存空间 lua_shared_dict cache 1m; #定义计数共享空间 access_log nginx_access.log; lua_package_path \"/etc/nginx/lua/?.lua;;\"; init_by_lua_block { collectgarbage(\"collect\") local ok, res ok, res = pcall(require, \"configuration\") if not ok then error(\"require failed: \" .. tostring(res)) else configuration = res end } # 执行脚本内初始化方法，这里为可选项，如果没有可初始化的代码部分 这里可以不要 init_worker_by_lua_block { configuration.prepare() } include /etc/nginx/mime.types; default_type application/octet-stream; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; server { # 执行最简单的 lua 脚本 location /hello { default_type 'text/plain'; content_by_lua 'ngx.say(\"hello, lua\")'; } # 配置接口 # 这里是执行加载的 lua 脚本中方法 location /configuration { client_max_body_size 5m; client_body_buffer_size 1m; proxy_buffering off; content_by_lua_block { configuration.call() # 调用 call() 方法 } } # 执行较为复杂的 lua 逻辑 location /lua { default_type 'text/plain'; # 读取请求中的 path 参数 并从共享 dict 中查询这个值， # 返回查询到的结果 content_by_lua ' local path = ngx.req.get_uri_args()[\"path\"] if path == nil then ngx.say(\"path not found\") return end local data = ngx.shared.endpoints_data:get(\"/\"..path) if not data then ngx.say(\"unkonw path\") return end ngx.say(\"paths: \"..data) '; } # other path location / { set $load_ups \"\"; # 动态设置当前 upstream, 未找到返回404 rewrite_by_lua ' local ups = configuration.getEndpoints() if ups ~= nil then ngx.log(ngx.ERR,\"got upstream\", ups) ngx.var.load_ups = ups return end ngx.status = ngx.HTTP_NOT_FOUND ngx.exit(ngx.status) '; proxy_pass http://$load_ups$uri; add_header X-Upstream $upstream_addr always; # 添加 backend ip } }} ","date":"2021-09-17","objectID":"/posts/nginx-lua-plugins/:1:3","tags":["nginx","lua"],"title":"nginx 中使用 lua 动态加载服务配置","uri":"/posts/nginx-lua-plugins/"},{"categories":["网关"],"content":"lua ","date":"2021-09-17","objectID":"/posts/nginx-lua-plugins/:2:0","tags":["nginx","lua"],"title":"nginx 中使用 lua 动态加载服务配置","uri":"/posts/nginx-lua-plugins/"},{"categories":["网关"],"content":"定义变量 因为需要用到 shared_dict 特性，在 lua 和 Nginx 之间公用内存块 从而实现数据的同步共享，所以需要预定义一些变量。 -- 引入变量 local io = io local ngx = ngx local table = table -- 当前包的对象，类似 go 语言的定义结构体 让给这个结构体实现方法 local _M = {} -- 与 Nginx 共享的空间 可读写 local Endpoints = ngx.shared.endpoints_data ","date":"2021-09-17","objectID":"/posts/nginx-lua-plugins/:2:1","tags":["nginx","lua"],"title":"nginx 中使用 lua 动态加载服务配置","uri":"/posts/nginx-lua-plugins/"},{"categories":["网关"],"content":"动态更新服务列表 服务列表是通过被调接口实现，即有别的服务区监听服务节点(endpoint)的变化,然后调用/configuration/backends 接口，被 Nginx 配置的 /configuration 规则命中后调用 configuration.call() 方法，我们看一下这个 call 方法的实现。 -- call called by ngx function _M.call() -- 只处理 GET 和 POST if ngx.var.request_method ~= \"POST\" and ngx.var.request_method ~= \"GET\" then ngx.status = ngx.HTTP_BAD_REQUEST ngx.print(\"Only POST and GET requests are allowed!\") return end -- 目前只处理后端服务的配置 所以判断路由 if ngx.var.request_uri == \"/configuration/backends\" then -- 调用内部方法 handle_backends() return end -- 非法请求 返回 404 ngx.status = ngx.HTTP_NOT_FOUND ngx.print(\"Not found!\") end 多说一句，调用 /configuration/backends 时传参是在请求 body 里，格式为 json 所以需要引入第三方的 json 解析包。handle_backends 方法的实现： -- handle_backends . local function handle_backends() if ngx.var.request_method == \"GET\" then ngx.status = ngx.HTTP_OK -- 返回查询的服务列表 local path = ngx.req.get_uri_args()[\"path\"] ngx.print(Endpoints:get(\"path\")) return end -- 读取请求 body local obj = fetch_request_body() if not obj then ngx.log(ngx.ERR, \"dynamic-configuration: unable to read valid request body\") ngx.status = ngx.HTTP_BAD_REQUEST return end -- 通过 第三方包 json 解析 body到 lua table local rule, err = json.decode(obj) if not rule then ngx.log(ngx.ERR, \"could not parse backends data: \", err) return end ngx.log(ngx.ERR, \"decoed rule\", obj) -- 清空共享空间 Endpoints:flush_all() -- 遍历并写入 for _, new_rule in ipairs(rule.rules) do -- 更新 -- 将数组合并 local succ, err1, forcible = Endpoints:set(new_rule.path, table.concat(new_rule.upstreams, \",\")) ngx.log(ngx.ERR, \"set result\", succ, err1,forcible) end ngx.status = ngx.HTTP_CREATED ngx.say(\"ok\") end -- 读取请求 body 部分 local function fetch_request_body() ngx.req.read_body() local body = ngx.req.get_body_data() if not body then -- request body might've been written to tmp file if body \u003e client_body_buffer_size local file_name = ngx.req.get_body_file() local file = io.open(file_name, \"rb\") if not file then return nil end body = file:read(\"*all\") file:close() end return body end 请求 body 的 json 结构如下： type NginxRuleConf struct { Rules []struct{ Path string `json:\"path\"` ServiceName string `json:\"serviceName\"` Port int32 `json:\"-\"` Upstreams []string `json:\"upstreams\"` } `json:\"rules\"` } ","date":"2021-09-17","objectID":"/posts/nginx-lua-plugins/:2:2","tags":["nginx","lua"],"title":"nginx 中使用 lua 动态加载服务配置","uri":"/posts/nginx-lua-plugins/"},{"categories":["网关"],"content":"动态读取后端服务 上面已经通过接口的方式动态更新服务节点列表并写入到共享空间 endpoints_data 内，我们现在实现读取服务列表并选择其中一个节点进行接口转发。 代码如下： -- 轮顺的方式取节点 function _M.getEndpoints() local cache = ngx.shared.cache local path = ngx.var.request_uri local eps = Endpoints:get(path) if not eps then return nil end local tab = split(eps,\",\") local index = cache:get(path) if index == nil or index \u003e #tab then index = 1 end -- 加一 cache:set(path,index+1) return tab[index] end ","date":"2021-09-17","objectID":"/posts/nginx-lua-plugins/:2:3","tags":["nginx","lua"],"title":"nginx 中使用 lua 动态加载服务配置","uri":"/posts/nginx-lua-plugins/"},{"categories":["网关"],"content":"结论 至此实现的效果是，可以动态配置多个后端服务和后端服务节点列表，外部服务请求 Nginx 时，会尝试从已有的服务中匹配转发，如果服务有多个节点则轮顺的方法去转发。如有服务信息发生变化，则通过调用 Nginx 中配置的 configuration 接口更新即可，无需修改 Nginx 配置。 ","date":"2021-09-17","objectID":"/posts/nginx-lua-plugins/:3:0","tags":["nginx","lua"],"title":"nginx 中使用 lua 动态加载服务配置","uri":"/posts/nginx-lua-plugins/"},{"categories":["kubernetes"],"content":"本文介绍本地或服务器上搭建单节点的 k8s 集群和 webUI 以及启用ingress，可以用作开发和测试环境。 ","date":"2021-09-07","objectID":"/posts/deploy-k8s-cluster/:0:0","tags":["k8s","docker"],"title":"部署单机 k8s 集群","uri":"/posts/deploy-k8s-cluster/"},{"categories":["kubernetes"],"content":"准备工作 所需工具： docker minkube kubectl 如何安装 docker 就不再这里撰述。 ","date":"2021-09-07","objectID":"/posts/deploy-k8s-cluster/:1:0","tags":["k8s","docker"],"title":"部署单机 k8s 集群","uri":"/posts/deploy-k8s-cluster/"},{"categories":["kubernetes"],"content":"安装 minikube 官方文档 Mac $ brew install minkube linux $ curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\ \u0026\u0026 chmod +x minikube 将 Minikube 可执行文件添加至 PATH： sudo mkdir -p /usr/local/bin/ sudo install minikube /usr/local/bin/ 也可以在 GitHub 上下载系统对应的二级制文件 ","date":"2021-09-07","objectID":"/posts/deploy-k8s-cluster/:1:1","tags":["k8s","docker"],"title":"部署单机 k8s 集群","uri":"/posts/deploy-k8s-cluster/"},{"categories":["kubernetes"],"content":"安装 kubectl 官方文档 Mac $ brew install kubernetes-cli Linux $ sudo apt-get update \u0026\u0026 sudo apt-get install -y apt-transport-https $ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - $ echo \"deb https://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee -a /etc/apt/sources.list.d/kubernetes.list $ sudo apt-get update $ sudo apt-get install -y kubectl ","date":"2021-09-07","objectID":"/posts/deploy-k8s-cluster/:1:2","tags":["k8s","docker"],"title":"部署单机 k8s 集群","uri":"/posts/deploy-k8s-cluster/"},{"categories":["kubernetes"],"content":"启动\u0026检查 启动 $ minikube start --vm-driver=docker 检查 $ minikube status minikube type: Control Plane host: Running kubelet: Running apiserver: Running kubeconfig: Configured 至此集群已经部署成功，可以通过 kubectl 命令查看状态 $ kubectl cluster-info Kubernetes control plane is running at https://xxx.xxx.xx.xx:8443 CoreDNS is running at https://xxx.xxx.xx.xx:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy ","date":"2021-09-07","objectID":"/posts/deploy-k8s-cluster/:2:0","tags":["k8s","docker"],"title":"部署单机 k8s 集群","uri":"/posts/deploy-k8s-cluster/"},{"categories":["kubernetes"],"content":"停止\u0026清理 停止 $ minkube stop 清理 $ minikube delete ","date":"2021-09-07","objectID":"/posts/deploy-k8s-cluster/:3:0","tags":["k8s","docker"],"title":"部署单机 k8s 集群","uri":"/posts/deploy-k8s-cluster/"},{"categories":["kubernetes"],"content":"webUI 安装 k8s 管理 dashboard。 $ minikube dashboard --url 🤔 Verifying dashboard health ... 🚀 Launching proxy ... 🤔 Verifying proxy health ... http://127.0.0.1:35983/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ minikube 会安装 dashboard 并返回可访问的 url, 如果是本地则直接访问即可。 如果是服务器上，则需要执行以下命令： $ kubectl proxy --address='0.0.0.0' --disable-filter=true W0907 17:47:12.246841 591818 proxy.go:162] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious Starting to serve on [::]:8001 并通过http://serverIP:8001/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/访问 dashboard 。 ","date":"2021-09-07","objectID":"/posts/deploy-k8s-cluster/:4:0","tags":["k8s","docker"],"title":"部署单机 k8s 集群","uri":"/posts/deploy-k8s-cluster/"},{"categories":["kubernetes"],"content":"Ingress 启动 ingress 也是需要通过 minikube 命令执行。 $ minikube addons enable ingress minikube 会开启 ingress 并安装 ingress-nginx, 我们只需要写 ingress 规则即可。然后通过 kubectl 命令查看可访问的虚拟 ip。 $ kubectl get ingress NAME CLASS HOSTS ADDRESS PORTS AGE goapp-ingress \u003cnone\u003e * 192.168.49.2 80 2d $ curl 192.168.49.2/ping \"pong\" 可以访问的通的。 相关连接: https://v1-18.docs.kubernetes.io/zh/docs/tasks/tools/install-minikube/ https://kubernetes.io/zh/docs/tasks/access-application-cluster/ingress-minikube/ https://stackoverflow.com/questions/47173463/how-to-access-local-kubernetes-minikube-dashboard-remotely ","date":"2021-09-07","objectID":"/posts/deploy-k8s-cluster/:5:0","tags":["k8s","docker"],"title":"部署单机 k8s 集群","uri":"/posts/deploy-k8s-cluster/"},{"categories":["代码调试"],"content":"dlv 作为程序调试工具功能非常强大，日常开发和测试中几乎离不开 debug 调试。但是有的时候由于本地环境与线上环境不一致或有些问题在本地无法复现的时候，我们需要在线上/测试环境做 debug，同时希望 debug 体验能与本地 debug 体验一致。dlv 其实是支持这种需求的，线上运行线本地 debug。以下是基于 docker 环境的远程调试步骤，希望能对遇到这种情况的码友们友帮助。 所需工具： docker goland dlv ","date":"2021-09-06","objectID":"/posts/docker-dlv-debugging/:0:0","tags":["go","docker"],"title":"如何在 docker 环境下进行远程 dlv 调试","uri":"/posts/docker-dlv-debugging/"},{"categories":["代码调试"],"content":"docker file # Compile stageFROMgolang:1.13.8 AS build-env# Build DelveRUN go get github.com/go-delve/delve/cmd/dlvADD . /dockerdevWORKDIR/dockerdev# 编译需要 debug 的程序RUN go build -gcflags=\"all=-N -l\" -o /server# Final stageFROMdebian:buster# 分别暴露 server 和 dlv 端口EXPOSE8000 40000WORKDIR/COPY --from=build-env /go/bin/dlv /COPY --from=build-env /server /CMD [\"/dlv\", \"--listen=:40000\", \"--headless=true\", \"--api-version=2\", \"--accept-multiclient\", \"exec\", \"/server\"] ","date":"2021-09-06","objectID":"/posts/docker-dlv-debugging/:1:0","tags":["go","docker"],"title":"如何在 docker 环境下进行远程 dlv 调试","uri":"/posts/docker-dlv-debugging/"},{"categories":["代码调试"],"content":"启动 docker 镜像 $ docker run -d -p 8000:8000 -p 40000:40000 --privileged --name=dlv-debug $(ImageName):$(ImageVersion) ","date":"2021-09-06","objectID":"/posts/docker-dlv-debugging/:2:0","tags":["go","docker"],"title":"如何在 docker 环境下进行远程 dlv 调试","uri":"/posts/docker-dlv-debugging/"},{"categories":["代码调试"],"content":"goland 配置 在 Goland -\u003e Run -\u003e Edit Configuration 添加 Go Remote 配置 docker 镜像的 ip:port, 本地的 docker 环境则 localhost:40000 即可。 现在就可以在本地 Goland 环境下启动配置 debug 就可以，本地 debug 远程程序，与本地 debug 毫无区别。 这种方式在一些特定环境（test 环境、远程办公等）非常方便。 参考文献： https://blog.jetbrains.com/go/2020/05/06/debugging-a-go-application-inside-a-docker-container/ ","date":"2021-09-06","objectID":"/posts/docker-dlv-debugging/:3:0","tags":["go","docker"],"title":"如何在 docker 环境下进行远程 dlv 调试","uri":"/posts/docker-dlv-debugging/"},{"categories":["proto"],"content":"前言 如果大家接触过 grpc 和 protobuf ，那对 protoc 这个命令应该不陌生。 protoc 为基于 proto buffer 文件生成不同语言代码的工具，在日常业务开发中能经常用到。那先抛出一个问题，你有没有基于 pb 文件生成满足自己特殊要求的需求？比如生成对应的 http 代码或校验参数等。 我个人需求为，除了生成正常的 grpc 代码外，需要生成一套对应的 http 代码，而且最好是能直接在 gin/iris 这种主流 web 框架内注册使用。 其实 golang/protobuf 包支持自定义插件的，而且还提供很多好用的方法，方便我们读写 pb 文件。我们写好自己的插件安装到 $GOPATH/bin 下，然后在调用 protoc 命令时，指定我们自己的插件名和输出位置即可。 关于这个插件：我现有的需求然后一直找不到比较好的解决方案，直到看到 kratos 项目的 http 代码生成插件后豁然开朗，基于 kratos 的逻辑实现的自己需求，感谢 kratos 作者们。 ","date":"2021-07-08","objectID":"/posts/go-protoc-http/:1:0","tags":["go","grpc","protoc"],"title":"如何自定义 protoc 插件","uri":"/posts/go-protoc-http/"},{"categories":["proto"],"content":"效果 先看原始 pb 文件。 test.proto syntax = \"proto3\";package hello.service.v1;option go_package = \"api/hello/service/v1;v1\";// 下载 `github.com/googleapis/googleapis` 至`GOPATH`, 生成 http 代码需要。 import \"google/api/annotations.proto\";service Hello { rpc Add(AddRequest) returns (AddResponse) { option (google.api.http) = { post: \"/api/hello/service/v1/add\" body: \"*\" }; } rpc Get(GetRequest) returns (GetResponse) { option (google.api.http) = { get: \"/api/hello/service/v1/get\" }; }}message AddRequest { uint32 id = 1; string name = 2;}message AddResponse { uint32 id = 1; string name = 2;}message GetRequest { uint32 id = 1;}message GetResponse { uint32 id = 1; string name = 2; float score = 3; bytes bs = 4; map\u003cstring, string\u003e m = 5;} 因为我需要生成 http 代码，所以定义 rpc 时，http 路由和method 需要在 pb 文件指定。 我实现的插件起码叫 protoc-gen-go-http, 必须以 protoc-gen 开头否则 protoc 不认。 执行命令： # --go-http 为我自己的插件 # 其中参数是 key=v,key2=v2 方式传，最后冒号后面写输出目录 protoc -I$GOPATH/src/github.com/googleapis/googleapis --proto_path=$GOPATH/src:. --go_out=. --go-http_out=router=gin:. --micro_out=. test.proto 执行完命令后，会生成三个文件分别为 test.pb.go,test.pb.micro.go和test.http.pb.go， 生成的文件名是可以自定义的。 test.pb.micro.go 文件是由 go-micro 提供的工具生成 grpc 代码文件。 看一下 test.http.pb.go 文件 // Code generated by protoc-gen-go-http. DO NOT EDIT. // versions: // protoc-gen-go-http v0.0.9 package v1 import ( context \"context\" gin \"github.com/gin-gonic/gin\" ) // This is a compile-time assertion to ensure that this generated file // is compatible with the galaxy package it is being compiled against. var _ context.Context const _ = gin.Version type HelloHTTPHandler interface { Add(context.Context, *AddRequest, *AddResponse) error Get(context.Context, *GetRequest, *GetResponse) error } // RegisterHelloHTTPHandler define http router handle by gin. func RegisterHelloHTTPHandler(g *gin.RouterGroup, srv HelloHTTPHandler) { g.POST(\"/api/hello/service/v1/add\", _Hello_Add0_HTTP_Handler(srv)) g.GET(\"/api/hello/service/v1/get\", _Hello_Get0_HTTP_Handler(srv)) } func _Hello_Add0_HTTP_Handler(srv HelloHTTPHandler) func(c *gin.Context) { return func(c *gin.Context) { var ( in AddRequest out AddResponse ) if err := c.ShouldBind(\u0026in); err != nil { c.AbortWithStatusJSON(400, gin.H{\"err\": err.Error()}) return } err := srv.Add(context.Background(), \u0026in, \u0026out) if err != nil { c.AbortWithStatusJSON(500, gin.H{\"err\": err.Error()}) return } c.JSON(200, \u0026out) } } func _Hello_Get0_HTTP_Handler(srv HelloHTTPHandler) func(c *gin.Context) { return func(c *gin.Context) { var ( in GetRequest out GetResponse ) if err := c.ShouldBind(\u0026in); err != nil { c.AbortWithStatusJSON(400, gin.H{\"err\": err.Error()}) return } err := srv.Get(context.Background(), \u0026in, \u0026out) if err != nil { c.AbortWithStatusJSON(500, gin.H{\"err\": err.Error()}) return } c.JSON(200, \u0026out) } } 重点是 RegisterHelloHTTPHandler 方法，这样我就注册一个 gin.RouterGroup 和 HelloHTTPHandler 就可以直接提供一个 http 服务 HelloHTTPHandler 接口里方法的签名与go-micro生成的 grpc 方法保持了一致， 这样我只需要实现 grpc 的代码里对应的 Interface{} 接口，就可以服用，完全不会产生多余代码。 go-micro 生成的 pb 代码片段： type HelloHandler interface { Add(context.Context, *AddRequest, *AddResponse) error Get(context.Context, *GetRequest, *GetResponse) error } func RegisterHelloHandler(s server.Server, hdlr HelloHandler, opts ...server.HandlerOption) error {} 我在 main 函数注册的时候也只需要多注册一次 http handler 即可， main.go // 它实现了 HelloHandler type implHello struct{} RegisterHelloHandler(micro.Server, \u0026implHello) g := gin.New() // implHello 实现HelloHandler 那就是实现了HelloHTTPHandler RegisterHelloHTTPHandler(g.Group(\"/\"), \u0026implHello) 所以我就很容易通过 http 接口调试 grpc 方法，甚至可以对外提供服务，一举两得。 ","date":"2021-07-08","objectID":"/posts/go-protoc-http/:2:0","tags":["go","grpc","protoc"],"title":"如何自定义 protoc 插件","uri":"/posts/go-protoc-http/"},{"categories":["proto"],"content":"如何实现 ","date":"2021-07-08","objectID":"/posts/go-protoc-http/:3:0","tags":["go","grpc","protoc"],"title":"如何自定义 protoc 插件","uri":"/posts/go-protoc-http/"},{"categories":["proto"],"content":"程序入口 main.go package main import ( \"flag\" \"google.golang.org/protobuf/compiler/protogen\" \"google.golang.org/protobuf/types/pluginpb\" ) // protoc-gen-go-http 工具版本 // 与 GalaxyMicroVersion 保持一致 const version = \"v0.0.12\" func main() { // 1. 传参定义 // 即 插件是支持自定义参数的，这样我们可以更加灵活，针对不同的场景生成不同的代码 var flags flag.FlagSet // 是否忽略没有指定 google.api 的方法 omitempty := flags.Bool(\"omitempty\", true, \"omit if google.api is empty\") // 我这里同时支持了 gin 和 iris 可以通过参数指定生成 routerEngine := flags.String(\"router\", \"gin\", \"http router engine, choose between gin and iris\") // 是否生校验代码块 // 发现了一个很有用的插件 github.com/envoyproxy/protoc-gen-validate // 可以在 pb 的 message 中设置参数规则，然后会生成一个 validate.go 的文件 针对每个 message 生成一个 Validate() 方法 // 我在每个 handler 处理业务前做了一次参数校验判断，通过这个 flag 控制是否生成这段校验代码 genValidateCode := flags.Bool(\"validate\", false, \"add validate request params in handler\") // 生成代码时参数 这么传：--go-http_out=router=iris,validate=true:. gp := \u0026GenParam{ Omitempty: omitempty, RouterEngine: routerEngine, GenValidateCode: genValidateCode, } // 这里就是入口，指定 option 后执行 Run 方法 ，我们的主逻辑就是在 Run 方法 protogen.Options{ ParamFunc: flags.Set, }.Run(func(gen *protogen.Plugin) error { gen.SupportedFeatures = uint64(pluginpb.CodeGeneratorResponse_FEATURE_PROTO3_OPTIONAL) for _, f := range gen.Files { if !f.Generate { continue } // 这里是我们的生成代码方法 generateFile(gen, f, gp) } return nil }) } type GenParam struct { Omitempty *bool RouterEngine *string GenValidateCode *bool } ","date":"2021-07-08","objectID":"/posts/go-protoc-http/:3:1","tags":["go","grpc","protoc"],"title":"如何自定义 protoc 插件","uri":"/posts/go-protoc-http/"},{"categories":["proto"],"content":"读取 pb 文件定义 http.go import ( \"fmt\" \"strings\" \"google.golang.org/genproto/googleapis/api/annotations\" \"google.golang.org/protobuf/compiler/protogen\" \"google.golang.org/protobuf/proto\" \"google.golang.org/protobuf/types/descriptorpb\" ) const ( contextPackage = protogen.GoImportPath(\"context\") ginPackage = protogen.GoImportPath(\"github.com/gin-gonic/gin\") irisPackage = protogen.GoImportPath(\"github.com/kataras/iris/v12\") ) var methodSets = make(map[string]int) // generateFile generates a _http.pb.go file containing gin/iris handler. func generateFile(gen *protogen.Plugin, file *protogen.File, gp *GenParam) *protogen.GeneratedFile { if len(file.Services) == 0 || (*gp.Omitempty \u0026\u0026 !hasHTTPRule(file.Services)) { return nil } // 这里我们可以自定义文件名 filename := file.GeneratedFilenamePrefix + \".pb.http.go\" g := gen.NewGeneratedFile(filename, file.GoImportPath) // 写入一些警告之类的 告诉用户不要修改 g.P(\"// Code generated by protoc-gen-go-http. DO NOT EDIT.\") g.P(\"// versions:\") g.P(fmt.Sprintf(\"// protoc-gen-go-http %s\", version)) g.P() g.P(\"package \", file.GoPackageName) g.P() generateFileContent(gen, file, g, gp) return g } // generateFileContent generates the _http.pb.go file content, excluding the package statement. func generateFileContent(gen *protogen.Plugin, file *protogen.File, g *protogen.GeneratedFile, gp *GenParam) { if len(file.Services) == 0 { return } // import // 这里有个插曲：其实 import 相关的代码我们这么不需要特殊指定，protogen 包会帮我们处理， // 但是import 的 path 前的别名默认取 path 最后一个 `/` 之后的字符， // 比如：github.com/kataras/iris/v12 被处理成 v12 \"github.com/kataras/iris/v12\" // 这个我不太愿意接受 所以自己写入 import g.P(\"// This imports are custom by galaxy micro framework.\") g.P(\"import (\") switch *gp.RouterEngine { case \"gin\": g.P(\"gin\", \" \", ginPackage) case \"iris\": g.P(\"iris\", \" \", irisPackage) } g.P(\")\") // 注： 我们难免有一些 _ \"my/package\" 这种需求，这其实不用自己写 直接调 g.Import(\"my/package\") 就可以 // 这里定义一堆变量是为了程序编译的时候确保这些包是正确的，如果包不存在或者这些定义的包变量不存在都会编译失败 g.P(\"// This is a compile-time assertion to ensure that this generated file\") g.P(\"// is compatible with the galaxy package it is being compiled against.\") // 只要调用这个 Ident 方法 就会自动写入到 import 中 ，所以如果对 import 的包名没有特殊要求，那就直接使用 Ident g.P(\"var _ \", contextPackage.Ident(\"Context\")) // 像我自己自定义 import 的包就不要使用 Ident 方法，否则生成的代码文件里有两个同一个包的引入导致语法错误 switch *gp.RouterEngine { case \"gin\": g.P(\"const _ = \", \"gin.\", \"Version\") case \"iris\": g.P(\"const _ = \", \"iris.\", \"Version\") } g.P() // 到这里我们就把包名 import 和变量写入成功了，剩下的就是针对 rpc service 生成对应的 handler for _, service := range file.Services { genService(gen, file, g, service, gp) } } // rpc service 信息 type serviceDesc struct { ServiceType string // Greeter ServiceName string // helloworld.Greeter Metadata string // api/helloworld/helloworld.proto GenValidate bool Methods []*methodDesc MethodSets map[string]*methodDesc } // rpc 方法信息 type methodDesc struct { // method Name string Num int Request string Reply string // http_rule Path string Method string CamelCaseMethod string HasVars bool HasBody bool Body string ResponseBody string } // 生成 service 相关代码 func genService(gen *protogen.Plugin, file *protogen.File, g *protogen.GeneratedFile, service *protogen.Service, gp *GenParam) { if service.Desc.Options().(*descriptorpb.ServiceOptions).GetDeprecated() { g.P(\"//\") g.P(deprecationComment) } // HTTP Server. // 服务的主要变量，比如服务名 服务类型等 sd := \u0026serviceDesc{ ServiceType: service.GoName, ServiceName: string(service.Desc.FullName()), Metadata: file.Desc.Path(), GenValidate: *gp.GenValidateCode, } // 开始遍历服务的方法 for _, method := range service.Methods { // 不处理 if method.Desc.IsStreamingClient() || method.Desc.IsStreamingServer() { continue } // annotations 这个就是我们在 rpc 方法里 option 里定义的 http 路由 rule, ok := proto.GetExtension(method.Desc.Options(), annotations.E_Http).(*annotations.HttpRule) if rule != nil \u0026\u0026 ok { for _, bind := range rule.AdditionalBindings { // 拿到 option里定义的路由， http method等信息 sd.Methods = append(sd.Methods, buildHTTPRule(g, method, bind)) } sd.Methods = append(sd.Methods, buildHTTPRule(g, method, rule)) } else if !*gp.Omitempty { path := fmt.Sprint","date":"2021-07-08","objectID":"/posts/go-protoc-http/:3:2","tags":["go","grpc","protoc"],"title":"如何自定义 protoc 插件","uri":"/posts/go-protoc-http/"},{"categories":["proto"],"content":"模板渲染 // execute 方法实现也其实不复杂，总起来就是 go 的 temple 包的使用 // 提前写好模板文件，然后拿到所有需要的变量，进行模板渲染，写入文件 func (s *serviceDesc) execute(routerEngine string) string { var ( name = routerEngine tmp string ) switch routerEngine { case \"gin\": tmp = ginTemplate case \"iris\": tmp = irisTemplate default: panic(\"unknown http engine\") } s.MethodSets = make(map[string]*methodDesc) for _, m := range s.Methods { s.MethodSets[m.Name] = m } buf := new(bytes.Buffer) tmpl, err := template.New(name).Parse(strings.TrimSpace(tmp)) if err != nil { panic(err) } if err = tmpl.Execute(buf, s); err != nil { panic(err) } return strings.Trim(buf.String(), \"\\r\\n\") } ","date":"2021-07-08","objectID":"/posts/go-protoc-http/:3:3","tags":["go","grpc","protoc"],"title":"如何自定义 protoc 插件","uri":"/posts/go-protoc-http/"},{"categories":["proto"],"content":"模板内容 var ginTemplate = ` {{$svrType:=.ServiceType}}{{$svrName:=.ServiceName}}{{$validate:=.GenValidate}}// 这里定义 handler interface type {{.ServiceType}}HTTPHandler interface { {{-range.MethodSets}}{{.Name}}(context.Context, *{{.Request}}, *{{.Reply}}) error {{-end}}} // Register{{.ServiceType}}HTTPHandler define http router handle by gin. // 注册路由 handler func Register{{.ServiceType}}HTTPHandler(g *gin.RouterGroup, srv {{.ServiceType}}HTTPHandler) { {{-range.Methods}}g.{{.Method}}(\"{{.Path}}\", _{{$svrType}}_{{.Name}}{{.Num}}_HTTP_Handler(srv)) {{-end}}} // 定义 handler // 遍历之前解析到所有 rpc 方法信息 {{range.Methods}}func _{{$svrType}}_{{.Name}}{{.Num}}_HTTP_Handler(srv {{$svrType}}HTTPHandler) func(c *gin.Context) { return func(c *gin.Context) { var ( in = new({{.Request}}) out = new({{.Reply}}) ctx = middleware.GetContextFromGinCtx(c) ) if err := c.ShouldBind(in{{.Body}}); err != nil { c.AbortWithStatusJSON(400, gin.H{\"err\": err.Error()}) return } // 这里就是最开始提到的判断是否启用 validate // 其中这个 api.Validator 接口只有一个方法 Validate() error // 所以需要在一个统一的地方定义好引入使用，建议不要在生成的时候写入，因为这个是通用的 interface{} {{if$validate-}}// check param if v, ok := interface{}(in).(api.Validator);ok { if err := v.Validate();err != nil { c.AbortWithStatusJSON(400, gin.H{\"err\": err.Error()}) return } } {{end-}}// 执行方法 err := srv.{{.Name}}(ctx, in, out) if err != nil { c.AbortWithStatusJSON(500, gin.H{\"err\": err.Error()}) return } c.JSON(200, out) } } {{end}}` iris 的模板基本类似。 到这里代码部分完全结束，做一个简单的总结： 构思需求，即我需要什么样的插件，它需要给我生成什么的代码块？ 根据需求先自己写一个预期代码，然后把这份代码拆解成一个模板，提取里面的可以渲染的变量。 模板里可以有逻辑，也就是可以做一些参数校验的方式，生成不同的代码，比如针对不同的 http 方法，做不同的处理，针对不同的插件参数生成不同的代码块。 程序入口到渲染文件前这段代码，基本都用 protogen 包提供的方法，可以对这个包做一些调研阅读文档，看看它都提供什么能力, 说不定可以少走很多弯路。 基本就这些了，我也是各种琢磨琢磨出来的，建议大家多动手，只要不写永远学不到精髓。 ","date":"2021-07-08","objectID":"/posts/go-protoc-http/:3:4","tags":["go","grpc","protoc"],"title":"如何自定义 protoc 插件","uri":"/posts/go-protoc-http/"},{"categories":["工具开发"],"content":"关于如何用 go 语言编写一个命令行工具。这里会基于 cobra 开源库进行开发。cobra 作为一个非常有名的命令行工具库，被很多开源项目引入使用，很多命令行工具都能看到 cobra 的身影。cobra 提供一个完整的命令行的工具的所需的功能，包括命令定义、命令扩展、读取参数等。下面我们以开发一个命令行工具的流程一步步学习如何使用 cobra 开发一个自己的命令行工具。 ","date":"2021-06-30","objectID":"/posts/go-cobra/:0:0","tags":["go","cobra"],"title":"如何编写自己的第一个命令行工具","uri":"/posts/go-cobra/"},{"categories":["工具开发"],"content":"创建根命令 我们项目暂且就叫 myCmd, 我们本地创建一个go项目就叫 myCmd。 $ mkdir myCmd $ cd myCmd $ touch main.go $ go mod init myCmd main.go package main import ( \"log\" \"github.com/spf13/cobra\" ) var ( // 定义主命令 rootCmd = \u0026cobra.Command{ Use: \"myCmd\", Short: \"这里是对命令的简短介绍\", Long: `这里可以放对命令的详细介绍。 可以多行`, Example: \"myCmd help\", // 使用示例 Version: \"v0.0.1\", // 定义版本 } dirPath string ) func init() { // 定义参数，即从命令行读取的参数变量 // 除了 PersistentFlags 外，也可以用 Flags()，区别是 前一个可以在其子命令也可以用，后一个不能。即PersistentFlags是一个全局的flag注册。 rootCmd.PersistentFlags().StringVarP(\u0026dirPath, \"dir\", \"d\", \".\", \"文件路径\") } func main() { if err := rootCmd.Execute(); err != nil { log.Fatal(err) } } 这样我们就创建了一个属于的自己的命令，执行看一下效果。 # 直接执行,会打印 字段Long的值， ➜./myCmd 这里可以放对命令的详细介绍。 可以多行 # 打印版本 ➜./myCmd -v myCmd version v0.0.1 # 输入未知 flag ➜./myCmd -x Error: unknown shorthand flag: 'x' in -x Usage: Examples: myCmd help Flags: -d, --dir string 文件路径 (default \".\") -h, --help help for myCmd -v, --version version for myCmd 2021/07/04 15:18:59 unknown shorthand flag: 'x' in -x 不难发现，版本处理，未知参数处理等情况 cobra已经做了相对完善的处理，我们不需要做太多的错误处理。 目前未知，我们的的命令只是定义了命令，并没有执行任何指令，下面我们添加一个简单的执行函数。cobra.Command 有很多参数可以定义执行函数的，我们以最常用的的 Run，RunE 为例，分别是不返回错误和返回错误的函数定义。 假如我们的主命令执行一个打印 d 参数传值的目录的信息。 // rootCmd RunE: printDirInfo, /* ... */ func printDirInfo(cmd *cobra.Command, args []string) error { info, err := os.Stat(dirPath) if err != nil { return err } fmt.Printf(\"name:%s, size:%d modTime:%v \\n\", info.Name(), info.Size(), info.ModTime()) return nil } 执行一下命令： # 查看一下 main 文件的信息 ➜./myCmd -d main.go name:main.go, size:759 modTime:2021-07-04 15:26:43.311399368 +0800 CST # 查看一个不存在的文件 ➜./myCmd -d main.go1 Error: stat main.go1: no such file or directory Usage: myCmd [flags] Examples: myCmd help Flags: -d, --dir string 命令执行目录 (default \".\") -h, --help help for myCmd -v, --version version for myCmd 2021/07/04 15:30:01 stat main.go1: no such file or directory # 不仅打印出错误，如何使用命令也会同时打印出来 下面我们就添加我们的子命令。 ","date":"2021-06-30","objectID":"/posts/go-cobra/:1:0","tags":["go","cobra"],"title":"如何编写自己的第一个命令行工具","uri":"/posts/go-cobra/"},{"categories":["工具开发"],"content":"添加子命令 我们现在添加一个子命令，这个子命令的功能是统计当前目录下的所有文件信息，我们就起名叫 stat。同时，为了方便全局变量的在不同包内读取，创建一个 variable 的目录，里面存放全局的一些变量，包内变量就放到各自包内。 ➜ mkdir stat ➜ mkdir variable ➜ touch stat/stat.go ➜ touch variable/variable.go 下面是stat文件的内容。 stat.go package stat import ( \"fmt\" \"myCmd/variable\" \"os\" \"path/filepath\" \"github.com/spf13/cobra\" ) var ( StatCmd = \u0026cobra.Command{ Use: \"stat\", Short: \"统计目录\", RunE: statDir, } isStatDir bool ) func init() { // 这里使用 Flags 只在我这个命令内解析和读取 StatCmd.Flags().BoolVarP(\u0026isStatDir, \"stat_dir\", \"s\", false, \"是否统计目录信息\") } func statDir(cmd *cobra.Command, args []string) error { return filepath.Walk(variable.DirPath, func(path string, info os.FileInfo, err error) error { if err != nil { return err } if info.IsDir() \u0026\u0026 !isStatDir { // 不统计 return nil } fmt.Printf(\"path:%s, size:%d, modTime:%v\", path, info.Size(), info.ModTime()) return nil }) } 然后将该子命令注册的主命令下。 main.go package main import ( \"fmt\" \"log\" \"myCmd/stat\" \"myCmd/variable\" \"os\" \"github.com/spf13/cobra\" ) var ( rootCmd = \u0026cobra.Command{ Use: \"myCmd\", Short: \"这里是对命令的简短介绍\", Long: `这里可以放对命令的详细介绍。 可以多行`, Example: \"myCmd help\", // 使用示例 Version: variable.Version, // 全局变量常量都移到 variable 目录下 RunE: printDirInfo, } ) func init() { rootCmd.PersistentFlags().StringVarP(\u0026variable.DirPath, \"dir\", \"d\", \".\", \"文件路径\") // 注册命令 rootCmd.AddCommand(stat.StatCmd) } func printDirInfo(cmd *cobra.Command, args []string) error { info, err := os.Stat(variable.DirPath) if err != nil { return err } fmt.Printf(\"name:%s, size:%d modTime:%v \\n\", info.Name(), info.Size(), info.ModTime()) return nil } func main() { if err := rootCmd.Execute(); err != nil { log.Fatal(err) } } 再次执行 help 查看我们的命令。 ➜./myCmd -h 这里可以放对命令的详细介绍。 可以多行 Usage: myCmd [flags] myCmd [command] Examples: myCmd help Available Commands: help Help about any command stat 统计目录 Flags: -d, --dir string 文件路径 (default \".\") -h, --help help for myCmd -v, --version version for myCmd Use \"myCmd [command] --help\" for more information about a command. # 查看子命令help ➜./myCmd stat -h 统计目录 Usage: myCmd stat [flags] Flags: -h, --help help for stat -s, --stat_dir 是否统计目录信息 Global Flags: -d, --dir string 文件路径 (default \".\") # 统计 ➜./myCmd stat -d . path:go.mod, size:61, modTime:2021-07-04 15:03:33.339495852 +0800 CST path:go.sum, size:56568, modTime:2021-07-04 15:03:33.339185898 +0800 CST path:main.go, size:929, modTime:2021-07-04 15:55:07.206300444 +0800 CST path:myCmd, size:4344056, modTime:2021-07-04 16:01:12.930132286 +0800 CST path:stat/stat.go, size:691, modTime:2021-07-04 16:01:09.353487727 +0800 CST path:variable/variable.go, size:73, modTime:2021-07-04 15:48:18.345134258 +0800 CST 不难发现，这个子命令可以无限嵌套，我们可以拥有二级三级子命令，能满足我们各种各样奇葩的需求，子命令可以复用其上级目录的 flag参数。 ","date":"2021-06-30","objectID":"/posts/go-cobra/:2:0","tags":["go","cobra"],"title":"如何编写自己的第一个命令行工具","uri":"/posts/go-cobra/"},{"categories":["工具开发"],"content":"自主更新 假如我们开发命令，已经发布到 GitHub 上，别人可以简单的 go get 命令就能安装使用我们的命令。但是我要是发布一个新版本，希望使用的人能知道我的命令工具有新版了而且要是能方便的更新到最新的版本是不是一个非常人性化的设计呢？ 其实实现起来也不难，这里抛出个思路。假如我们命令每次执行的时候，我做一次版本检查（但是强烈不建议每次都检查，最好本地做一个上次检查时间的缓存，最多一天检查一次，否则用户体验非常不好），如果有新的版本我就提醒用户，甚至我可以检查的时候拉过来新版本的 feature 展现给用户，，然后提供一个 update 的子命令，自我更新，这体验是不是听起来就很不错呀。 至于 update 这个子命令实现也很简单，尝试执行一次 go get -u \u003cmyCmdRemoteURL\u003e 即可，虽然看起来是对 go get 的一次封装，但是对于用户来说就很简单方便。 ","date":"2021-06-30","objectID":"/posts/go-cobra/:3:0","tags":["go","cobra"],"title":"如何编写自己的第一个命令行工具","uri":"/posts/go-cobra/"},{"categories":["工具开发"],"content":"小彩蛋 到这里我们一个小命令行工具也有模有样了，但是缺一个灵魂，是什么呢？ 当然是 命令的炫酷的logo！！！ 先看效果图： # 普通版本 __ __ __ __ _____ __ __ _____ | \\/ | \\ \\ / / / ____| | \\/ | | __ \\ | \\ / | \\ \\_/ / | | | \\ / | | | | | | |\\/| | \\ / | | | |\\/| | | | | | | | | | | | | |____ | | | | | |__| | |_| |_| |_| \\_____| |_| |_| |_____/ # 斜体 /| //| | \\\\ / / // ) ) /| //| | // ) ) //| // | | \\\\ / / // //| // | | // / / // | // | | \\\\/ / // // | // | | // / / // | // | | / / // // | // | | // / / // |// | | / / ((____/ / // |// | | //____/ / # 夸张版本 _____ _____ _____ _____ _____ /\\ \\ |\\ \\ /\\ \\ /\\ \\ /\\ \\ /::\\____\\ |:\\____\\ /::\\ \\ /::\\____\\ /::\\ \\ /::::| | |::| | /::::\\ \\ /::::| | /::::\\ \\ /:::::| | |::| | /::::::\\ \\ /:::::| | /::::::\\ \\ /::::::| | |::| | /:::/\\:::\\ \\ /::::::| | /:::/\\:::\\ \\ /:::/|::| | |::| | /:::/ \\:::\\ \\ /:::/|::| | /:::/ \\:::\\ \\ /:::/ |::| | |::| | /:::/ \\:::\\ \\ /:::/ |::| | /:::/ \\:::\\ \\ /:::/ |::|___|______ |::|___|______ /:::/ / \\:::\\ \\ /:::/ |::|___|______ /:::/ / \\:::\\ \\ /:::/ |::::::::\\ \\ /::::::::\\ \\ /:::/ / \\:::\\ \\ /:::/ |::::::::\\ \\ /:::/ / \\:::\\ ___\\ /:::/ |:::::::::\\____\\ /::::::::::\\____\\/:::/____/ \\:::\\____\\/:::/ |:::::::::\\____\\/:::/____/ \\:::| | \\::/ / ~~~~~/:::/ / /:::/~~~~/~~ \\:::\\ \\ \\::/ /\\::/ / ~~~~~/:::/ /\\:::\\ \\ /:::|____| \\/____/ /:::/ / /:::/ / \\:::\\ \\ \\/____/ \\/____/ /:::/ / \\:::\\ \\ /:::/ / /:::/ / /:::/ / \\:::\\ \\ /:::/ / \\:::\\ \\ /:::/ / /:::/ / /:::/ / \\:::\\ \\ /:::/ / \\:::\\ /:::/ / /:::/ / \\::/ / \\:::\\ \\ /:::/ / \\:::\\ /:::/ / /:::/ / \\/____/ \\:::\\ \\ /:::/ / \\:::\\/:::/ / /:::/ / \\:::\\ \\ /:::/ / \\::::::/ / /:::/ / \\:::\\____\\ /:::/ / \\::::/ / \\::/ / \\::/ / \\::/ / \\::/____/ \\/____/ \\/____/ \\/____/ ~~ 我随机选了几个作为演示，点击这里跳转制作自己工具的logo，然后再主命令注册一个 PreRun 的函数，在该函数内打印我们的logo。这样在主逻辑执行前会打印我们的logo，辨识度一下子提高很多。 实际效果： ➜./myCmd -d main.go __ __ __ __ _____ __ __ _____ | \\/ | \\ \\ / / / ____| | \\/ | | __ \\ | \\ / | \\ \\_/ / | | | \\ / | | | | | | |\\/| | \\ / | | | |\\/| | | | | | | | | | | | | |____ | | | | | |__| | |_| |_| |_| \\_____| |_| |_| |_____/ name:main.go, size:1320 modTime:2021-07-04 16:28:51.339520282 +0800 CST 暂且就这么多，感谢 spf13/cobra 的作者，提供这么高质量的开源库。 ","date":"2021-06-30","objectID":"/posts/go-cobra/:4:0","tags":["go","cobra"],"title":"如何编写自己的第一个命令行工具","uri":"/posts/go-cobra/"},{"categories":["microservice"],"content":"go-micro 作为比较流行的微服务框架，其良好的接口设计为后期扩展使用带来了非常好的便利性。本文章主要讲在 go-micro 中用 nacos 作为服务注册中心和配置中心。 ","date":"2021-06-23","objectID":"/posts/use-nacos-with-go-micro/:0:0","tags":["go","go-micro"],"title":"Go-Micro 中使用Nacos","uri":"/posts/use-nacos-with-go-micro/"},{"categories":["microservice"],"content":"注册中心 先看一下 go-micro 定义的服务注册接口。 registry.go // 服务注册接口 type Registry interface { // 初始化 Init(...Option) error // 返回可选参数 Options() Options // 服务注册 Register(*Service, ...RegisterOption) error // 服务注销 Deregister(*Service, ...DeregisterOption) error // 查询服务 GetService(string, ...GetOption) ([]*Service, error) // 列出服务 ListServices(...ListOption) ([]*Service, error) // 监听服务 Watch(...WatchOption) (Watcher, error) String() string } 只要基于任意一个服务注册服务实现以上接口，即可在 go-micro 中作为注册中心使用。假如我用一个 customRegistry 实现接口后，在 go-micro 初始化的时候或服务启动时候通过启动参数指定实现接口的接口的 String() string方法的返回值接口。 如： // 假如该结构体已实现 Registry 接口 type customRegistry struct {} func (c *customRegistry) String() string { return \"custom\" } // 代码中指定 func main() { micro.NewService(micro.Registry(\u0026customRegistry{})) } // 启动参数指定 ./myApp -- registry custom 如此一看，发现非常方便和好扩展，接下来贴出如何使用nacos 实现该 Registry 接口。 直接列出关键代码块： registry.go import ( \"errors\" \"fmt\" \"net\" \"strconv\" \"time\" \"github.com/asim/go-micro/v3/cmd\" \"github.com/asim/go-micro/v3/registry\" \"github.com/nacos-group/nacos-sdk-go/v2/clients\" \"github.com/nacos-group/nacos-sdk-go/v2/clients/naming_client\" \"github.com/nacos-group/nacos-sdk-go/v2/common/constant\" \"github.com/nacos-group/nacos-sdk-go/v2/common/logger\" \"github.com/nacos-group/nacos-sdk-go/v2/vo\" ) type nacosRegistry struct { // nacos sdk 的client client naming_client.INamingClient // 可选参数，初始化的时候可以通过 registry.Option 方法指定配置 opts registry.Options } func init() { // 设置为默认配置 cmd.DefaultRegistries[\"nacos\"] = NewRegistry } // NewRegistry NewRegistry func NewRegistry(opts ...registry.Option) registry.Registry { n := \u0026nacosRegistry{ opts: registry.Options{}, } if err := configure(n, opts...); err != nil { panic(err) } return n } // 这个方法总结下来就是干了一件事：配置初始化 func configure(n *nacosRegistry, opts ...registry.Option) error { // set opts for _, o := range opts { o(\u0026n.opts) } clientConfig := constant.ClientConfig{} serverConfigs := make([]constant.ServerConfig, 0) contextPath := \"/nacos\" cfg, ok := n.opts.Context.Value(configKey{}).(constant.ClientConfig) if ok { clientConfig = cfg } addrs, ok := n.opts.Context.Value(addressKey{}).([]string) if !ok { addrs = []string{\"127.0.0.1:8848\"} // 默认连接本地 } for _, addr := range addrs { // check we have a port host, port, err := net.SplitHostPort(addr) if err != nil { return err } p, err := strconv.ParseUint(port, 10, 64) if err != nil { return err } serverConfigs = append(serverConfigs, constant.ServerConfig{ // Scheme: \"go.micro\", IpAddr: host, Port: p, ContextPath: contextPath, }) } if n.opts.Timeout == 0 { n.opts.Timeout = time.Second * 1 } clientConfig.TimeoutMs = uint64(n.opts.Timeout.Milliseconds()) // 创建客户端 client, err := clients.CreateNamingClient(map[string]interface{}{ constant.KEY_SERVER_CONFIGS: serverConfigs, constant.KEY_CLIENT_CONFIG: clientConfig, }) if err != nil { return err } n.client = client return nil } func (n *nacosRegistry) Init(opts ...registry.Option) error { _ = configure(n, opts...) return nil } func (n *nacosRegistry) Options() registry.Options { return n.opts } func (n *nacosRegistry) Register(s *registry.Service, opts ...registry.RegisterOption) error { var options registry.RegisterOptions for _, o := range opts { o(\u0026options) } withContext := false // 处理参数 param := vo.RegisterInstanceParam{} if options.Context != nil { if p, ok := options.Context.Value(\"register_instance_param\").(vo.RegisterInstanceParam); ok { param = p withContext = ok } } if !withContext { host, port, err := getNodeIPPort(s) if err != nil { return err } s.Nodes[0].Metadata[\"version\"] = s.Version param.Ip = host param.Port = uint64(port) param.Metadata = s.Nodes[0].Metadata param.ServiceName = s.Name param.Enable = true param.Healthy = true param.Weight = 1.0 param.Ephemeral = true } // 注册节点 _, err := n.client.RegisterInstance(param) return err } func (n *nacosRegistry) Deregister(s *registry.Service, opts ...registry.DeregisterOption) error { var options registry.DeregisterOptions for _, o := range opts { o(\u0026options) } withContext := false param := vo.DeregisterInst","date":"2021-06-23","objectID":"/posts/use-nacos-with-go-micro/:1:0","tags":["go","go-micro"],"title":"Go-Micro 中使用Nacos","uri":"/posts/use-nacos-with-go-micro/"},{"categories":["microservice"],"content":"关于如何使用go的微服务框架 go-micro/v3 的使用和其插件的自定义。第一部分将框架的架构大致了解一遍。 ","date":"2021-06-11","objectID":"/posts/go-micro-1/:0:0","tags":["go","go-micro"],"title":"Go-Micro 的架构及其使用（一）","uri":"/posts/go-micro-1/"},{"categories":["microservice"],"content":"架构 以 v3.5.1 分支为例 go-micor 项目的目录结构如下： $ tree -L 2 . ├── LICENSE ├── README.md ├── _config.yml ├── api // api 接口的定义，包括http、grpc、router等 ├── auth // 账号认证接口的定义 ├── broker // 消息队列接口定义及默认实现 ├── client // 客户端相关接口定义和实现 ├── cmd // 可执行命令（包括生成protobuf的命令实现） ├── codec // code encoder ├── config // 动态配置的接口定义 ├── debug // debug 模式 ├── errors // 错误处理 ├── examples // 各个模块的示例代码 ├── logger // 日志模块接口定义 ├── metadata // 原数据 ├── plugins // 各个模块定义的接口的不同实现 ├── registry // 服务注册接口定义 ├── selector // 负载均衡 ├── server // 服务端接口定义 ├── store // 数据存储接口定义 ├── sync ├── transport // 请求转发 └── util // 工具类 下面按目录将 go-micro 的主要核心模块过一遍。 ","date":"2021-06-11","objectID":"/posts/go-micro-1/:1:0","tags":["go","go-micro"],"title":"Go-Micro 的架构及其使用（一）","uri":"/posts/go-micro-1/"},{"categories":["microservice"],"content":"API api 层为定义和实现基于http/gRPC的api service。即http请求处理 路由处理 路由注册等。 接口定义： type Api interface { // Initialise options Init(...Option) error // Get the options Options() Options // Register a http handler Register(*Endpoint) error // Register a route Deregister(*Endpoint) error // Implemenation of api String() string } 目录结构： $ tree . ├── api.go ├── api_test.go ├── handler // 接口处理方法 │ ├── api // 实现 http.ServerHTTP() 方法 │ ├── event // 基于消息队列的实现 │ ├── handler.go // 接口定义 │ ├── http // 基于http的实现 │ ├── options.go │ ├── rpc // 基于rpc的实现 │ └── web // 支持websocket的实现 ├── proto │ ├── api.pb.go │ ├── api.pb.micro.go │ └── api.proto // 数据结构定义 ├── resolver // 解析请求及路由 │ ├── grpc │ ├── host │ ├── options.go │ ├── path │ ├── resolver.go │ └── vpath ├── router // 路由定义和注册 │ ├── options.go │ ├── registry │ ├── router.go │ ├── static │ └── util └── server // 服务定义和启动 ├── acme ├── cors ├── http ├── options.go └── server.go ","date":"2021-06-11","objectID":"/posts/go-micro-1/:1:1","tags":["go","go-micro"],"title":"Go-Micro 的架构及其使用（一）","uri":"/posts/go-micro-1/"},{"categories":["microservice"],"content":"Config config 作为动态配置中心的接口定义和实现。支持动态加载、插件式配置源、配置合并和观察配置变化。 接口定义： // Config is an interface abstraction for dynamic configuration // 配置接口定义 type Config interface { // provide the reader.Values interface // 读取到的配置的reader reader.Values // Init the config Init(opts ...Option) error // Options in the config Options() Options // Stop the config loader/watcher Close() error // Load config sources // 可以加载多个Source Load(source ...source.Source) error // Force a source changeset sync // 同步配置变化 Sync() error // Watch a value for changes // 订阅配置变化 Watch(path ...string) (Watcher, error) } // Watcher is the config watcher type Watcher interface { Next() (reader.Value, error) Stop() error } // Source is the source from which config is loaded // Source 就是配置来源 go-micro 已实现基于consul，etcd，file等多种配置来源，也可以自己实现下面接口来使用 type Source interface { Read() (*ChangeSet, error) Write(*ChangeSet) error Watch() (Watcher, error) String() string } // Reader is an interface for merging changesets // 用于配置合并 // go-micro 实现了基于json的Reader,默认用json作为解析配置内容，并在插件目录内实现了 toml yaml xml等格式的Encoder可以按需求替换 type Reader interface { Merge(...*source.ChangeSet) (*source.ChangeSet, error) Values(*source.ChangeSet) (Values, error) String() string } // Values is returned by the reader // 用于读写配置，读取的配置会返回 Value type Values interface { Bytes() []byte Get(path ...string) Value Set(val interface{}, path ...string) Del(path ...string) Map() map[string]interface{} Scan(v interface{}) error } // Value represents a value of any type // Value 为拿到的配置，可以通过其方法转到基础类型。 type Value interface { Bool(def bool) bool Int(def int) int String(def string) string Float64(def float64) float64 Duration(def time.Duration) time.Duration StringSlice(def []string) []string StringMap(def map[string]string) map[string]string Scan(val interface{}) error Bytes() []byte } 目录结构： $ tree -L 2 . ├── README.md ├── config.go // Config 接口定义 ├── default.go // 默认实现的Config ├── default_test.go ├── encoder // encoder 解析配置内容 │ ├── encoder.go │ └── json // json实现 ├── loader // 加载配置 │ ├── loader.go │ └── memory // 基于内存的加载，即启动时会将配置加载到内存 ├── options.go ├── reader // 定义和实现Reader，内部依赖Encoder │ ├── json │ ├── options.go │ ├── preprocessor.go │ ├── preprocessor_test.go │ └── reader.go ├── secrets // 定义和实现需要加解密的配置 │ ├── box │ ├── secretbox │ └── secrets.go ├── source // 配置来源 │ ├── changeset.go │ ├── cli │ ├── env // 基于环境变量的实现 │ ├── file // 基于本地文件实现 │ ├── flag // 基于启动参数flag实现 │ ├── memory // 基于内存实现 │ ├── noop.go │ ├── options.go │ └── source.go └── value.go plugins/config/encoder 目录: 实现Encoder接口 $ tree plugins/config/encoder ├── cue ├── hcl ├── toml ├── xml └── yaml plugins/config/source 目录： 实现Source接口 $ tree plugins/config/source ├── configmap ├── consul ├── etcd ├── grpc ├── mucp ├── pkger ├── runtimevar ├── url └── vault ","date":"2021-06-11","objectID":"/posts/go-micro-1/:1:2","tags":["go","go-micro"],"title":"Go-Micro 的架构及其使用（一）","uri":"/posts/go-micro-1/"},{"categories":["microservice"],"content":"Logger Logger 包为全局日志库，默认实现了一套，并在plugins 内实现了基于 logrus，zap的个主流的日志的实现。 接口定义： // Logger is a generic logging interface type Logger interface { // Init initialises options Init(options ...Option) error // The Logger options Options() Options // Fields set fields to always be logged Fields(fields map[string]interface{}) Logger // Log writes a log entry Log(level Level, v ...interface{}) // Logf writes a formatted log entry Logf(level Level, format string, v ...interface{}) // String returns the name of logger String() string } 若需要自己定义日志格式和日志库，可以实现上面接口，并初始化的时候指定即可。 ","date":"2021-06-11","objectID":"/posts/go-micro-1/:1:3","tags":["go","go-micro"],"title":"Go-Micro 的架构及其使用（一）","uri":"/posts/go-micro-1/"},{"categories":["microservice"],"content":"plugins 该目录作为插件目录，实现了大部分预定义的接口，方便使用的时候替换成默认实现的模块代码。 该目录下所有子目录均可以作为go mod package 导入使用 在之后讲如何使用是 同时演示如何使用插件 目录结构： $ tree plugins ├── LICENSE ├── README.md ├── auth // 用户认真 │ └── jwt // 实现基于jwt的auth接口 ├── broker // 支持了市面上大部分消息队列 │ ├── gocloud │ ├── googlepubsub │ ├── grpc │ ├── http │ ├── kafka │ ├── memory │ ├── mqtt │ ├── nats │ ├── nsq │ ├── proxy │ ├── rabbitmq │ ├── redis │ ├── segmentio │ ├── snssqs │ ├── sqs │ ├── stan │ └── stomp ├── client // 支持了grpc http 等方式的客户端实现 │ ├── grpc │ ├── http │ ├── mock │ └── mucp ├── codec // 消息的编码解码的实现 │ ├── bsonrpc │ ├── json-iterator │ ├── jsonrpc2 │ ├── msgpackrpc │ └── segmentio ├── config // 配置 │ ├── encoder // 配置编码解码 │ ├── cue │ ├── hcl │ ├── toml │ ├── xml │ └── yaml │ └── source // 配置数据源 │ ├── configmap │ ├── consul │ ├── etcd │ ├── grpc │ ├── mucp │ ├── pkger │ ├── runtimevar │ ├── url │ └── vault ├── logger // 日志库 │ ├── apex │ ├── logrus │ ├── zap │ └── zerolog ├── plugin.go ├── proxy │ └── http ├── registry // 服务发现服务注册 │ ├── cache │ ├── consul │ ├── etcd │ ├── eureka │ ├── gossip │ ├── kubernetes │ ├── mdns │ ├── memory │ ├── multi │ ├── nats │ ├── proxy │ └── zookeeper ├── release.sh ├── selector // 负载均衡 │ ├── dns │ ├── label │ ├── registry │ ├── shard │ └── static ├── server // 后端服务 │ ├── grpc │ ├── http │ └── mucp ├── store // 数据存储的实现 │ ├── cockroach │ ├── consul │ ├── file │ ├── memcached │ ├── memory │ ├── mysql │ └── redis ├── sync // 数据同步 │ ├── etcd │ └── memory ├── template.go ├── transport // 服务之间通讯模块 │ ├── grpc │ ├── http │ ├── memory │ ├── nats │ ├── quic │ ├── rabbitmq │ ├── tcp │ └── utp └── wrapper // 自定义组件 比如监控、限流、熔断、追踪等 ├── README.md ├── breaker // 熔断 ├── endpoint // 指定服务节点 ├── monitoring // 监控 ├── ratelimiter // 限流 ├── select // 负载均衡 ├── service ├── trace // 链路追踪 └── validator // 参数校验（处理请求时 可以统一参数校验等工作） ","date":"2021-06-11","objectID":"/posts/go-micro-1/:1:4","tags":["go","go-micro"],"title":"Go-Micro 的架构及其使用（一）","uri":"/posts/go-micro-1/"},{"categories":["microservice"],"content":"Registry 服务发现/服务注册相关逻辑均在 registry 包内实现。 核心接口定义： // The registry provides an interface for service discovery // and an abstraction over varying implementations // {consul, etcd, zookeeper, ...} type Registry interface { Init(...Option) error Options() Options // 服务注册 Register(*Service, ...RegisterOption) error // 服务注销 Deregister(*Service, ...DeregisterOption) error // 查询服务 GetService(string, ...GetOption) ([]*Service, error) // 列出服务列表 ListServices(...ListOption) ([]*Service, error) // 监控服务 Watch(...WatchOption) (Watcher, error) String() string } // Watcher is an interface that returns updates // about services within the registry. type Watcher interface { // Next is a blocking call Next() (*Result, error) Stop() } ","date":"2021-06-11","objectID":"/posts/go-micro-1/:1:5","tags":["go","go-micro"],"title":"Go-Micro 的架构及其使用（一）","uri":"/posts/go-micro-1/"},{"categories":["microservice"],"content":"Selector 负载均衡逻辑，即客户端请求其他服务时如何选取服务节点都是在该包内实现。可以通过option指定策略，随机，轮询等。 接口定义： // Selector builds on the registry as a mechanism to pick nodes // and mark their status. This allows host pools and other things // to be built using various algorithms. type Selector interface { Init(opts ...Option) error Options() Options // Select returns a function which should return the next node Select(service string, opts ...SelectOption) (Next, error) // Mark sets the success/error against a node Mark(service string, node *registry.Node, err error) // Reset returns state back to zero for a service Reset(service string) // Close renders the selector unusable Close() error // Name of the selector String() string } // Next is a function that returns the next node // based on the selector's strategy type Next func() (*registry.Node, error) ","date":"2021-06-11","objectID":"/posts/go-micro-1/:1:6","tags":["go","go-micro"],"title":"Go-Micro 的架构及其使用（一）","uri":"/posts/go-micro-1/"},{"categories":["microservice"],"content":"Server server 包为定义和实现管理服务相关逻辑。 server的定义： // Server is a simple micro server abstraction type Server interface { // Initialise options Init(...Option) error // Retrieve the options Options() Options // Register a handler Handle(Handler) error // Create a new handler NewHandler(interface{}, ...HandlerOption) Handler // Create a new subscriber NewSubscriber(string, interface{}, ...SubscriberOption) Subscriber // Register a subscriber Subscribe(Subscriber) error // Start the server Start() error // Stop the server Stop() error // Server implementation String() string } // Router handle serving messages type Router interface { // ProcessMessage processes a message // 处理消息队列消息 ProcessMessage(context.Context, Message) error // ServeRequest processes a request to completion // 处理 http/rpc 请求 ServeRequest(context.Context, Request, Response) error } 默认实现了rpc和消息队列，http服务 可以使用plugins/server/http 包。 ","date":"2021-06-11","objectID":"/posts/go-micro-1/:1:7","tags":["go","go-micro"],"title":"Go-Micro 的架构及其使用（一）","uri":"/posts/go-micro-1/"},{"categories":["microservice"],"content":"Store 该包定义了数据存储的接口。 接口定义： // Store is a data storage interface type Store interface { // Init initialises the store. It must perform any required setup on the backing storage implementation and check that it is ready for use, returning any errors. Init(...Option) error // Options allows you to view the current options. Options() Options // Read takes a single key name and optional ReadOptions. It returns matching []*Record or an error. Read(key string, opts ...ReadOption) ([]*Record, error) // Write() writes a record to the store, and returns an error if the record was not written. Write(r *Record, opts ...WriteOption) error // Delete removes the record with the corresponding key from the store. Delete(key string, opts ...DeleteOption) error // List returns any keys that match, or an empty list with no error if none matched. List(opts ...ListOption) ([]string, error) // Close the store Close() error // String returns the name of the implementation. String() string } 具体使用数据库类型，在plugins/store 内初始化对应的实例。 ","date":"2021-06-11","objectID":"/posts/go-micro-1/:1:8","tags":["go","go-micro"],"title":"Go-Micro 的架构及其使用（一）","uri":"/posts/go-micro-1/"},{"categories":["microservice"],"content":"Sync sync 包为定义分布式选举和分布式锁的定义。 接口定义： // Sync is an interface for distributed synchronization type Sync interface { // Initialise options Init(...Option) error // Return the options Options() Options // Elect a leader // 选举 Leader(id string, opts ...LeaderOption) (Leader, error) // Lock acquires a lock // 上锁 Lock(id string, opts ...LockOption) error // Unlock releases a lock // 释放锁 Unlock(id string) error // Sync implementation String() string } // Leader provides leadership election // 提供分布式选举 type Leader interface { // resign leadership // 辞职 即放弃Leader状态 Resign() error // status returns when leadership is lost // 在leader 状态失去时，channel内可读取 Status() chan bool } ","date":"2021-06-11","objectID":"/posts/go-micro-1/:1:9","tags":["go","go-micro"],"title":"Go-Micro 的架构及其使用（一）","uri":"/posts/go-micro-1/"},{"categories":["技术积累"],"content":"经历了2个月的面试折磨，拿到offer总算结束了这段时间。主要是想记录面试中遇到的问题，列出来的问题不一定有答案，有答案也不一定是最佳答案，所以还是看问题为主，答案自行解决。 知识架构 ","date":"2021-05-31","objectID":"/posts/go-interview/:0:0","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"数据库 ","date":"2021-05-31","objectID":"/posts/go-interview/:1:0","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"MySQL 索引 B+tree 索引 数据存储位置-在叶子节点 相邻节点是链表结构 这样可以实现 range 查询 联合索引 最左原则 索引不能是表达式的一部分 否则不走索引 为什么主键是递增的，随机会怎么样？ 如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置，此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。 哈希索引 - 精准查询 聚簇索引和非聚簇索引 事务 事务的四种特性： 原子性：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 致性：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 事务的隔离级别： 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读) 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞 隔离级别 脏读（Dirty Read） 不可重复读（NonRepeatable Read） 幻读（Phantom Read） 未提交读（Read uncommitted） 可能 可能 可能 已提交读（Read committed） 不可能 可能 可能 可重复读（Repeatable read） 不可能 不可能 可能（innodb 不存在） 可串行化（Serializable ） 不可能 不可能 不可能 分库分表 水平： 水平分表 – 表之间结构相同 表之间数据不相同 所有表的数据并集是总数据（单表数据量很大，影响sql性能） 水平分库 – 库之间表结构相同 库之间数据不相同 所有库数据的并集是总数据（并发量很高，cpu 网络扛不住，分库缓解压力） 垂直： 垂直分表 – 表之间结构不相同，数据根据某个字段关联，缓解io性能 垂直分库 – 库之前的表之间结构不相同，服务压力很高 可以考虑拆出去做单独服务了 方案： 方案一（水平扩容库） 采用双倍扩容策略，避免数据迁移。扩容前每个节点的数据，有一半要迁移至一个新增节点中，对应关系比较简单。 具体操作如下(假设已有 2 个节点 A/B，要双倍扩容至 A/A2/B/B2 这 4 个节点)： 无需停止应用服务器； 新增两个数据库 A2/B2 作为从库，设置主从同步关系为：A=\u003eA2、B=\u003eB2，直至主从数据同步完毕(早期数据可手工同步)； 调整分片规则并使之生效： 原 ID%2=0 =\u003e A 改为 ID%4=0 =\u003e A, ID%4=2 =\u003e A2； 原 ID%2=1 =\u003e B 改为 ID%4=1 =\u003e B, ID%4=3 =\u003e B2。 解除数据库实例的主从同步关系，并使之生效； 此时，四个节点的数据都已完整，只是有冗余(多存了和自己配对的节点的那部分数据)，择机清除即可(过后随时进行，不影响业务)。 方案二（水平扩容表-双写） 第一步：（同步双写）修改应用配置和代码，加上双写，部署 第二步：（同步双写）将老库中的老数据复制到新库中 第三步：（同步双写）以老库为准校对新库中的老数据 第四步：（同步双写）修改应用配置和代码，去掉双写，部署； ","date":"2021-05-31","objectID":"/posts/go-interview/:1:1","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"Redis 数据结构 String 简单动态字符串 编码方式不同会有什么影响 Set 底层哈希表 ZSet member存在哈希表中 score 存在跳表里 查询插入时间复杂 logn 为什么用跳表 List 双向链表结构 Hmap 哈希表 性能 为什么这么快 为什么这么快2 数据均存在内存（引发出持久化问题） 高效的数据结构 单线程，省去线程间上下文切换的时间 以及不需要考虑锁 网络io 多路复用 可以让单个线程处理多个请求连接 减少网络io Redis采用自己实现的事件分离器，效率比较高，内部采用非阻塞的执行方式，吞吐能力比较大。 持久化 两种持久化： RDB持久化 即内存数据定时dump到磁盘上。 fork 一个子进程 将数据写入一个临时文件 写入成功后 替换源文件。 快照的数据是截止fork命令执行的那一刻 AOF 将Redis的操作日志以追加的方式写入文件。 将每一个写、删操作记录下来。默认配置时每秒同步一次。 RDB存在哪些优势呢？ 1). 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。 2). 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。 3). 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。 4). 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。 RDB又存在哪些劣势呢？ 1). 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。 2). 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。 AOF的优势有哪些呢？ 1). 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。 2). 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。 3). 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。 4). AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。 AOF的劣势有哪些呢？ 1). 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 2). 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。 二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。 内存模型 内存模型 ","date":"2021-05-31","objectID":"/posts/go-interview/:1:2","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"MongoDB 待补充 ","date":"2021-05-31","objectID":"/posts/go-interview/:1:3","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"缓存 常见缓存策略 一致性哈希 解决某个缓存节点宕机的情况。 缓存穿透 描述：缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。 解决方案： 接口层增加校验，如用户鉴权校验，id做基础校验，id\u003c=0的直接拦截。 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击。 布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 布隆过滤器原理：对key进行多个(n)hash算法 并将其值与 bitArray 长度m 进行取模 并对应的位置置位1，当一个新的key进行查询时 先查询其n个hash算法后的各个位置是否为1 如果都为1 则这个key可能存在 如果有任意一个位置不是1 则这个key 一定不存在。 缓存击穿 描述：缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力 解决方案： 热点数据不做过期 互斥锁。如果数据缓存不存在 则先进行上锁读数据写缓存释放锁 缓存雪崩 描述：缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 解决方案： 过期时间加随机数 热点数据不过期 分布式缓存 将热点数据拆分到不同的实例 ","date":"2021-05-31","objectID":"/posts/go-interview/:1:4","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"语言特性 ","date":"2021-05-31","objectID":"/posts/go-interview/:2:0","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"GMP 调度 调度2 概念 G：代表一个goroutine对象，每次go调用的时候，都会创建一个G对象，它包括栈、指令指针以及对于调用goroutines很重要的其它信息，比如阻塞它的任何channel，其主要数据结构： type g struct { stack stack // 描述了真实的栈内存，包括上下界 m *m // 当前的m sched gobuf // goroutine切换时，用于保存g的上下文 param unsafe.Pointer // 用于传递参数，睡眠时其他goroutine可以设置param，唤醒时该goroutine可以获取 atomicstatus uint32 stackLock uint32 goid int64 // goroutine的ID waitsince int64 // g被阻塞的大体时间 lockedm *m // G被锁定只在这个m上运行 } M: 代表内核线程(Pthread)，它本身就与一个内核线程进行绑定，goroutine 运行在M上。 type m struct { /* 1. 所有调用栈的Goroutine,这是一个比较特殊的Goroutine。 2. 普通的Goroutine栈是在Heap分配的可增长的stack,而g0的stack是M对应的线程栈。 3. 所有调度相关代码,会先切换到该Goroutine的栈再执行。 */ g0 *g curg *g // M当前绑定的结构体G // SP、PC寄存器用于现场保护和现场恢复 vdsoSP uintptr vdsoPC uintptr // 省略…} P：P(Processor)是一个抽象的概念，并不是真正的物理CPU。所以当P有任务时需要创建或者唤醒一个系统线程来执行它队列里的任务。所以P/M需要进行绑定，构成一个执行单元。 P决定了同时可以并发任务的数量，可通过GOMAXPROCS限制同时执行用户级任务的操作系统线程。可以通过runtime.GOMAXPROCS进行指定。在Go1.5之后GOMAXPROCS被默认设置可用的核数，而之前则默认为1。 // 自定义设置GOMAXPROCS数量 func GOMAXPROCS(n int) int { /* 1. GOMAXPROCS设置可执行的CPU的最大数量,同时返回之前的设置。 2. 如果n \u003c 1,则不更改当前的值。 */ ret := int(gomaxprocs) stopTheWorld(\"GOMAXPROCS\") // startTheWorld启动时,使用newprocs。 newprocs = int32(n) startTheWorld() return ret } // 默认P被绑定到所有CPU核上 // P == cpu.cores func getproccount() int32 { const maxCPUs = 64 * 1024 var buf [maxCPUs / 8]byte // 获取CPU Core r := sched_getaffinity(0, unsafe.Sizeof(buf), \u0026buf[0]) n := int32(0) for _, v := range buf[:r] { for v != 0 { n += int32(v \u0026 1) v \u003e\u003e= 1 } } if n == 0 { n = 1 } return n } // 一个进程默认被绑定在所有CPU核上,返回所有CPU core。 // 获取进程的CPU亲和性掩码系统调用 // rax 204 ; 系统调用码 // system_call sys_sched_getaffinity; 系统调用名称 // rid pid ; 进程号 // rsi unsigned int len // rdx unsigned long *user_mask_ptr sys_linux_amd64.s: TEXT runtime·sched_getaffinity(SB),NOSPLIT,$0 MOVQ pid+0(FP), DI MOVQ len+8(FP), SI MOVQ buf+16(FP), DX MOVL $SYS_sched_getaffinity, AX SYSCALL MOVL AX, ret+24(FP) RET 调度过程 首先创建一个G对象，G对象保存到P本地队列或者是全局队列。P此时去唤醒一个M。P继续执行它的执行序。M寻找是否有空闲的P，如果有则将该G对象移动到它本身。接下来M执行一个调度循环(调用G对象-\u003e执行-\u003e清理线程→继续找新的Goroutine执行)。 M执行过程中，随时会发生上下文切换。当发生上线文切换时，需要对执行现场进行保护，以便下次被调度执行时进行现场恢复。Go调度器M的栈保存在G对象上，只需要将M所需要的寄存器(SP、PC等)保存到G对象上就可以实现现场保护。当这些寄存器数据被保护起来，就随时可以做上下文切换了，在中断之前把现场保存起来。如果此时G任务还没有执行完，M可以将任务重新丢到P的任务队列，等待下一次被调度执行。当再次被调度执行时，M通过访问G的vdsoSP、vdsoPC寄存器进行现场恢复(从上次中断位置继续执行)。 多个线程下如何调度 抛出一个问题：每个P里面的G执行时间是不可控的，如果多个P同时在执行，会不会出现有的P里面的G执行不完，有的P里面几乎没有G可执行呢？ 这就要从M的自循环过程中如何获取G、归还G的行为说起了 有两种途径：1.借助全局队列 sched.runq 作为中介，本地P里的G太多的话就放全局里，G太少的话就从全局取。 2.全局列表里没有的话直接从P1里偷取(steal)。(更多M在执行的话，同样的原理，这里就只拿2个来举例) 调度循环中如何让出CPU 正常完成让出CPU 主动让出CPU time.Sleep(),IO阻塞等 抢占让出CPU 抢占式调度 概念：枚举所有的P 如果P在系统调用中(_Psyscall), 且经过了一次sysmon循环(20us~10ms), 则抢占这个P， 调用handoffp解除M和P之间的关联， 如果P在运行中(_Prunning), 且经过了一次sysmon循环并且G运行时间超过forcePreemptNS(10ms), 则抢占这个P 并设置g.preempt = true，g.stackguard0 = stackPreempt。 为什么设置了stackguard就可以实现抢占? 因为这个值用于检查当前栈空间是否足够, go函数的开头会比对这个值判断是否需要扩张栈。 newstack函数判断g.stackguard0等于stackPreempt, 就知道这是抢占触发的, 这时会再检查一遍是否要抢占。 抢占机制保证了不会有一个G长时间的运行导致其他G无法运行的情况发生。 主动让出CPU time.Sleep() timeSleep 函数里通过 addtimerLocked 把定时器加入到 timer 管理器（timer 通过最小堆的数据结构存放每个定时器，在这不做详细说明）后，再通过 goparkunlock 实现把当前G休眠，这里看到了上面提到的 gopark 方法进行调度循环的上下文切换。 在 addtimerLocked 方法的最下面有个逻辑在运行期间开启了’全局时间事件驱动器’timerproc,该方法会全程遍历最小堆，寻找最早进入 timer 管理器的定时器，然后唤醒。他是怎么找到要唤醒哪个G的？回头看下 timeSleep 方法里把当时正在执行的G以及唤醒方法 goroutineReady 带到了每个定时器里，而在 timerproc 则通过找到期的定时器执行f(arg, seq) 即通过 goroutineReady 方法唤醒。方法调用过程: goroutineReady() -\u003e ready() // runtime/time.go func timeSleep(ns int64) { if ns \u003c= 0 { return } t := getg().timer if t == nil { t = new(timer) getg().timer = t } *t = timer{} // 每个定时任务都创建一个timer t.when = nanotime() + ns t.f = goroutineReady // 记录唤醒该G的方法,唤醒时通过该方法执行唤醒 t.arg = getg() // 把timer与当前G关联,时间到了唤醒时通过该参数找到所在的G lock(\u0026timers.lock) addtimerLocked(t) // 把timer添加到最小堆里 goparkunlock(\u0026timers.lock, \"sleep\", traceEvGoSleep, 2) // 切到G0让出CPU,进入休眠 } 总结：time.Sleep 想要进入阻塞(休眠)状态，其实是通过 gopark 方法给自己标记个_Gwaiting 状态，然后把自己所占用的CPU线程资源给释放出来，继续执行调度任务，调度其它的G来运行。而唤醒是通过把G更改回_Grunnable 状态后，然后把G放入到P的待运行队列里等待执行。通过这点还可以看出休眠中的G其实并不占用 CPU 资源，最多是占用内存，是个很轻量级的阻塞。 Mutex Mutex.Lock 方法通过调用 runtime_SemacquireMutex 最终还是调用 goparkunlock 实现把G进入到休眠状态。在进入休眠","date":"2021-05-31","objectID":"/posts/go-interview/:2:1","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"垃圾回收 三色标记 哪些情况下不被垃圾回收？ 强三色和弱三色 写屏障 ","date":"2021-05-31","objectID":"/posts/go-interview/:2:2","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"channel ","date":"2021-05-31","objectID":"/posts/go-interview/:2:3","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"slice ","date":"2021-05-31","objectID":"/posts/go-interview/:2:4","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"map 怎么解决读写并发（除了锁） sync.Map 了解一下 ","date":"2021-05-31","objectID":"/posts/go-interview/:2:5","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"http库 ","date":"2021-05-31","objectID":"/posts/go-interview/:2:6","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"interface iface 有方法的interface{} eface 没有方法的interface{} ","date":"2021-05-31","objectID":"/posts/go-interview/:2:7","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"其他 变量逃逸 ","date":"2021-05-31","objectID":"/posts/go-interview/:2:8","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"项目经验 ","date":"2021-05-31","objectID":"/posts/go-interview/:3:0","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"微服务 ","date":"2021-05-31","objectID":"/posts/go-interview/:3:1","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"服务限流限速熔断 服务熔断 ","date":"2021-05-31","objectID":"/posts/go-interview/:3:2","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"提现个人能力的点 引入 etcd，基于 etcd 开发服务间通信的基础库 解决服务间通信和服务选举问题 引入nsq 修改源码 支持延迟消息持久化，二次开发 SDK 支持连接池 开发项目基础架构，一键生成新项目 开发基础 lib 包，wechat 包 ，common 包， eventbus-lib ，htlog-go 提高开发效率 规范化项目开发+上线流程，规范化架构 开发统一的内部消息服务，规范内服飞书/企业微信消息的发送 后台服务单点登录功能 服务拆解 向微服务方向改进 敏感词 建立词库结构（B-tree）黑白名单的缓存 自我介绍： 部门内的定位：后端开发+基础服务搭建 关注新技术 表现出持续学习 岗位匹配度 ","date":"2021-05-31","objectID":"/posts/go-interview/:3:3","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"系统设计 系统设计 ","date":"2021-05-31","objectID":"/posts/go-interview/:3:4","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"算法 github项目 ","date":"2021-05-31","objectID":"/posts/go-interview/:4:0","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"堆 最小堆/最大堆 topK 算法的实现： hash 加 小顶堆 堆排序 ","date":"2021-05-31","objectID":"/posts/go-interview/:4:1","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"链表 单向链表/双向链表 链表找环（快慢指针） 链表局部/全部旋转（即修改方向） 问题：查找倒数第 K 个节点 ","date":"2021-05-31","objectID":"/posts/go-interview/:4:2","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"二叉树 二叉树的五种遍历 前序 根-左-右 中序 左-根-右 后序 左-右-根 层次遍历 一层一层从左到右 锯齿遍历（s型遍历）每一层换方向 二叉树查找 查找最近路劲 查找共同祖先（最近祖先） 二叉树的转换 左右转换 其他 打印右视图左视图（即打印每一层的最右边或最左边） ","date":"2021-05-31","objectID":"/posts/go-interview/:4:3","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"回溯法递归法 理解回溯递归的每一层堆栈情况，学会什么情况下使用回溯/递归 ","date":"2021-05-31","objectID":"/posts/go-interview/:4:4","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"动态规划（DP） 找路线数量，爬台阶，背包问题 数组等和分组问题 ","date":"2021-05-31","objectID":"/posts/go-interview/:4:5","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"计算机基础 ","date":"2021-05-31","objectID":"/posts/go-interview/:5:0","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"基础概念 问题：查看当前服务器的性能\u0026查看 go 开的线程数？ 问题：进程线程协程的区别？ 问题：select poll epoll 的区别？ select 有大小限制 效率低 对 socket 是线性扫描 同步多路复用 O(n) poll 与 select 类似 但是用的链表结构 所以没有大小限制 同步多路复用 O(n) epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)） 相关链接 ","date":"2021-05-31","objectID":"/posts/go-interview/:5:1","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"tcp/udp tcp必备 问题：tcp time await 发生在哪端？ A: 发生在四次挥手时客户端，最后会等2MSL。 问题：为什么客户端最后还要等待2MSL？ 答：MSL（Maximum Segment Lifetime），TCP允许不同的实现可以设置不同的MSL值。第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失。站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。如果客户端收到服务端的FIN+ACK报文后，发送一个ACK给服务端之后就“自私”地立马进入CLOSED状态，可能会导致服务端无法确认收到最后的ACK指令，也就无法进入CLOSED状态，这是客户端不负责任的表现。第二，防止失效请求。防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。 在TIME_WAIT状态无法真正释放句柄资源，在此期间，Socket中使用的本地端口在默认情况下不能再被使用。该限制对于客户端机器来说是无所谓的，但对于高并发服务器来说，会极大地限制有效连接的创建数量，称为性能瓶颈。所以建议将高并发服务器TIME_WAIT超时时间调小。RFC793中规定MSL为2分钟。但是在当前的高速网络中，2分钟的等待时间会造成资源的极大浪费，在高并发服务器上通常会使用更小的值。 ","date":"2021-05-31","objectID":"/posts/go-interview/:5:2","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"http 谈谈HTTP https 相关 ","date":"2021-05-31","objectID":"/posts/go-interview/:5:3","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"grpc ","date":"2021-05-31","objectID":"/posts/go-interview/:5:4","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["技术积累"],"content":"其他QA Q: 解释graceful 平滑重启？ Q： ","date":"2021-05-31","objectID":"/posts/go-interview/:6:0","tags":["面试"],"title":"Go 面试总结","uri":"/posts/go-interview/"},{"categories":["代码规范"],"content":"语言篇，提出常见的开发上的不好的、不规范的写法，并给出更好的写法。 Uber 是一家美国硅谷的科技公司，也是 Go 语言的早期 adopter。其开源了很多 golang 项目，诸如被 Gopher 圈熟知的 zap、jaeger 等。2018 年年末 Uber 将内部的 Go 风格规范 开源到 GitHub，经过一年的积累和更新，该规范已经初具规模，并受到广大 Gopher 的关注。本文是该规范的中文版本，并加以作者个人的一些看法，非 uber 官方的建议和看法 本人会加以标注。 ","date":"2020-11-25","objectID":"/posts/go-standard/:0:0","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"介绍 样式 (style) 是支配我们代码的惯例。术语样式有点用词不当，因为这些约定涵盖的范围不限于由 gofmt 替我们处理的源文件格式。 本指南的目的是通过详细描述在 Uber 编写 Go 代码的注意事项来管理这种复杂性。这些规则的存在是为了使代码库易于管理，同时仍然允许工程师更有效地使用 Go 语言功能。 该指南最初由 Prashant Varanasi 和 Simon Newton 编写，目的是使一些同事能快速使用 Go。多年来，该指南已根据其他人的反馈进行了修改。 本文档记录了我们在 Uber 遵循的 Go 代码中的惯用约定。其中许多是 Go 的通用准则，而其他扩展准则依赖于下面外部的指南： Effective Go The Go common mistakes guide 所有代码都应该通过golint和go vet的检查并无错误。我们建议您将编辑器设置为： 保存时运行 goimports 运行 golint 和 go vet 检查错误 您可以在以下 Go 编辑器工具支持页面中找到更为详细的信息： https://github.com/golang/go/wiki/IDEsAndTextEditorPlugins ","date":"2020-11-25","objectID":"/posts/go-standard/:1:0","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"指导原则 ","date":"2020-11-25","objectID":"/posts/go-standard/:2:0","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"指向 interface 的指针 您几乎不需要指向接口类型的指针。您应该将接口作为值进行传递，在这样的传递过程中，实质上传递的底层数据仍然可以是指针。 接口实质上在底层用两个字段表示： 一个指向某些特定类型信息的指针。您可以将其视为\"type\"。 数据指针。如果存储的数据是指针，则直接存储。如果存储的数据是一个值，则存储指向该值的指针。 如果希望接口方法修改基础数据，则必须使用指针传递(将对象指针赋值给接口变量)。 type F interface { f() } type S1 struct{} func (s S1) f() {} type S2 struct{} func (s *S2) f() {} // f1.f()无法修改底层数据 // f2.f() 可以修改底层数据,给接口变量f2赋值时使用的是对象指针 var f1 F:= S1{} var f2 F:= \u0026S2{} ","date":"2020-11-25","objectID":"/posts/go-standard/:2:1","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"Interface 合理性验证 在编译时验证接口的符合性。这包括： 将实现特定接口的导出类型作为接口API 的一部分进行检查 实现同一接口的(导出和非导出)类型属于实现类型的集合 任何违反接口合理性检查的场景,都会终止编译,并通知给用户 补充:上面3条是编译器对接口的检查机制, 大体意思是错误使用接口会在编译期报错. 所以可以利用这个机制让部分问题在编译期暴露. Bad Good // 如果Handler没有实现http.Handler,会在运行时报错 type Handler struct { // ... } func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { ... } type Handler struct { // ... } // 用于触发编译期的接口的合理性检查机制 // 如果Handler没有实现http.Handler,会在编译期报错 var _ http.Handler = (*Handler)(nil) func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { // ... } 如果 *Handler 与 http.Handler 的接口不匹配, 那么语句 var _ http.Handler = (*Handler)(nil) 将无法编译通过. 赋值的右边应该是断言类型的零值。 对于指针类型（如 *Handler）、切片和映射，这是 nil； 对于结构类型，这是空结构。 type LogHandler struct { h http.Handler log *zap.Logger } var _ http.Handler = LogHandler{} func (h LogHandler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { // ... } ","date":"2020-11-25","objectID":"/posts/go-standard/:2:2","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"接收器 (receiver) 与接口 使用值接收器的方法既可以通过值调用，也可以通过指针调用。 带指针接收器的方法只能通过指针或 addressable values调用. 例如， type S struct { data string } func (s S) Read() string { return s.data } func (s *S) Write(str string) { s.data = str } sVals := map[int]S{1: {\"A\"}} // 你只能通过值调用 Read sVals[1].Read() // 这不能编译通过： // sVals[1].Write(\"test\") sPtrs := map[int]*S{1: {\"A\"}} // 通过指针既可以调用 Read，也可以调用 Write 方法 sPtrs[1].Read() sPtrs[1].Write(\"test\") 类似的,即使方法有了值接收器,也同样可以用指针接收器来满足接口. type F interface { f() } type S1 struct{} func (s S1) f() {} type S2 struct{} func (s *S2) f() {} s1Val := S1{} s1Ptr := \u0026S1{} s2Val := S2{} s2Ptr := \u0026S2{} var i F i = s1Val i = s1Ptr i = s2Ptr // 下面代码无法通过编译。因为 s2Val 是一个值，而 S2 的 f 方法中没有使用值接收器 // i = s2Val Effective Go 中有一段关于 pointers vs. values 的精彩讲解。 补充: 一个类型可以有值接收器方法集和指针接收器方法集 值接收器方法集是指针接收器方法集的子集,反之不是 规则 值对象只可以使用值接收器方法集 指针对象可以使用 值接收器方法集 + 指针接收器方法集 接口的匹配(或者叫实现) 类型实现了接口的所有方法,叫匹配 具体的讲,要么是类型的值方法集匹配接口,要么是指针方法集匹配接口 具体的匹配分两种: 值方法集和接口匹配 给接口变量赋值的不管是值还是指针对象,都ok,因为都包含值方法集 指针方法集和接口匹配 只能将指针对象赋值给接口变量,因为只有指针方法集和接口匹配 如果将值对象赋值给接口变量,会在编译期报错(会触发接口合理性检查机制) 为啥 i = s2Val 会报错,因为值方法集和接口不匹配. ","date":"2020-11-25","objectID":"/posts/go-standard/:2:3","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"零值 Mutex 是有效的 零值 sync.Mutex 和 sync.RWMutex 是有效的。所以指向 mutex 的指针基本是不必要的。 BadGood mu := new(sync.Mutex) mu.Lock() var mu sync.Mutex mu.Lock() 如果你使用结构体指针，mutex 可以非指针形式作为结构体的组成字段，或者更好的方式是直接嵌入到结构体中。 如果是私有结构体类型或是要实现 Mutex 接口的类型，我们可以使用嵌入 mutex 的方法： type smap struct { sync.Mutex // only for unexported types（仅适用于非导出类型） data map[string]string } func newSMap() *smap { return \u0026smap{ data: make(map[string]string), } } func (m *smap) Get(k string) string { m.Lock() defer m.Unlock() return m.data[k] } type SMap struct { mu sync.Mutex // 对于导出类型，请使用私有锁 data map[string]string } func NewSMap() *SMap { return \u0026SMap{ data: make(map[string]string), } } func (m *SMap) Get(k string) string { m.mu.Lock() defer m.mu.Unlock() return m.data[k] } 为私有类型或需要实现互斥接口的类型嵌入。 对于导出的类型，请使用专用字段。 ","date":"2020-11-25","objectID":"/posts/go-standard/:2:4","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"在边界处拷贝 Slices 和 Maps slices 和 maps 包含了指向底层数据的指针，因此在需要复制它们时要特别注意。 接收 Slices 和 Maps 请记住，当 map 或 slice 作为函数参数传入时，如果您存储了对它们的引用，则用户可以对其进行修改。 Bad Good func (d *Driver) SetTrips(trips []Trip) { d.trips = trips } trips := ... d1.SetTrips(trips) // 你是要修改 d1.trips 吗？ trips[0] = ... func (d *Driver) SetTrips(trips []Trip) { d.trips = make([]Trip, len(trips)) copy(d.trips, trips) } trips := ... d1.SetTrips(trips) // 这里我们修改 trips[0]，但不会影响到 d1.trips trips[0] = ... 返回 slices 或 maps 同样，请注意用户对暴露内部状态的 map 或 slice 的修改。 BadGood type Stats struct { mu sync.Mutex counters map[string]int } // Snapshot 返回当前状态。 func (s *Stats) Snapshot() map[string]int { s.mu.Lock() defer s.mu.Unlock() return s.counters } // snapshot 不再受互斥锁保护 // 因此对 snapshot 的任何访问都将受到数据竞争的影响 // 影响 stats.counters snapshot := stats.Snapshot() type Stats struct { mu sync.Mutex counters map[string]int } func (s *Stats) Snapshot() map[string]int { s.mu.Lock() defer s.mu.Unlock() result := make(map[string]int, len(s.counters)) for k, v := range s.counters { result[k] = v } return result } // snapshot 现在是一个拷贝 snapshot := stats.Snapshot() ","date":"2020-11-25","objectID":"/posts/go-standard/:2:5","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"使用 defer 释放资源 使用 defer 释放资源，诸如文件和锁。 BadGood p.Lock() if p.count \u003c 10 { p.Unlock() return p.count } p.count++ newCount := p.count p.Unlock() return newCount // 当有多个 return 分支时，很容易遗忘 unlock p.Lock() defer p.Unlock() if p.count \u003c 10 { return p.count } p.count++ return p.count // 更可读 Defer 的开销非常小，只有在您可以证明函数执行时间处于纳秒级的程度时，才应避免这样做。使用 defer 提升可读性是值得的，因为使用它们的成本微不足道。尤其适用于那些不仅仅是简单内存访问的较大的方法，在这些方法中其他计算的资源消耗远超过 defer。 ","date":"2020-11-25","objectID":"/posts/go-standard/:2:6","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"Channel 的 size 要么是 1，要么是无缓冲的 channel 通常 size 应为 1 或是无缓冲的。默认情况下，channel 是无缓冲的，其 size 为零。任何其他尺寸都必须经过严格的审查。我们需要考虑如何确定大小，考虑是什么阻止了 channel 在高负载下和阻塞写时的写入，以及当这种情况发生时系统逻辑有哪些变化。(翻译解释：按照原文意思是需要界定通道边界，竞态条件，以及逻辑上下文梳理) BadGood // 应该足以满足任何情况！ c := make(chan int, 64) // 大小：1 c := make(chan int, 1) // 或者 // 无缓冲 channel，大小为 0 c := make(chan int) ","date":"2020-11-25","objectID":"/posts/go-standard/:2:7","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"枚举从 1 开始 在 Go 中引入枚举的标准方法是声明一个自定义类型和一个使用了 iota 的 const 组。由于变量的默认值为 0，因此通常应以非零值开头枚举。 BadGood type Operation int const ( Add Operation = iota Subtract Multiply ) // Add=0, Subtract=1, Multiply=2 type Operation int const ( Add Operation = iota + 1 Subtract Multiply ) // Add=1, Subtract=2, Multiply=3 在某些情况下，使用零值是有意义的（枚举从零开始），例如，当零值是理想的默认行为时。 type LogOutput int const ( LogToStdout LogOutput = iota LogToFile LogToRemote ) // LogToStdout=0, LogToFile=1, LogToRemote=2 ","date":"2020-11-25","objectID":"/posts/go-standard/:2:8","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"使用 time 处理时间 时间处理很复杂。关于时间的错误假设通常包括以下几点。 一天有 24 小时 一小时有 60 分钟 一周有七天 一年 365 天 还有更多 例如，1 表示在一个时间点上加上 24 小时并不总是产生一个新的日历日。 因此，在处理时间时始终使用 \"time\" 包，因为它有助于以更安全、更准确的方式处理这些不正确的假设。 使用 time.Time 表达瞬时时间 在处理时间的瞬间时使用 time.time，在比较、添加或减去时间时使用 time.Time 中的方法。 BadGood func isActive(now, start, stop int) bool { return start \u003c= now \u0026\u0026 now \u003c stop } func isActive(now, start, stop time.Time) bool { return (start.Before(now) || start.Equal(now)) \u0026\u0026 now.Before(stop) } 使用 time.Duration 表达时间段 在处理时间段时使用 time.Duration . BadGood func poll(delay int) { for { // ... time.Sleep(time.Duration(delay) * time.Millisecond) } } poll(10) // 是几秒钟还是几毫秒? func poll(delay time.Duration) { for { // ... time.Sleep(delay) } } poll(10*time.Second) 回到第一个例子，在一个时间瞬间加上 24 小时，我们用于添加时间的方法取决于意图。如果我们想要下一个日历日(当前天的下一天)的同一个时间点，我们应该使用 Time.AddDate。但是，如果我们想保证某一时刻比前一时刻晚 24 小时，我们应该使用 Time.Add。 newDay := t.AddDate(0 /* years */, 0, /* months */, 1 /* days */) maybeNewDay := t.Add(24 * time.Hour) 对外部系统使用 time.Time 和 time.Duration 尽可能在与外部系统的交互中使用 time.Duration 和 time.Time 例如 : Command-line 标志: flag 通过 time.ParseDuration 支持 time.Duration JSON: encoding/json 通过其 UnmarshalJSON method 方法支持将 time.Time 编码为 RFC 3339 字符串 SQL: database/sql 支持将 DATETIME 或 TIMESTAMP 列转换为 time.Time，如果底层驱动程序支持则返回 YAML: gopkg.in/yaml.v2 支持将 time.Time 作为 RFC 3339 字符串，并通过 time.ParseDuration 支持 time.Duration。 当不能在这些交互中使用 time.Duration 时，请使用 int 或 float64，并在字段名称中包含单位。 例如，由于 encoding/json 不支持 time.Duration，因此该单位包含在字段的名称中。 BadGood // {\"interval\": 2} type Config struct { Interval int `json:\"interval\"` } // {\"intervalMillis\": 2000} type Config struct { IntervalMillis int `json:\"intervalMillis\"` } 当在这些交互中不能使用 time.Time 时，除非达成一致，否则使用 string 和 RFC 3339 中定义的格式时间戳。默认情况下，Time.UnmarshalText 使用此格式，并可通过 time.RFC3339 在 Time.Format 和 time.Parse 中使用。 尽管这在实践中并不成问题，但请记住，\"time\" 包不支持解析闰秒时间戳（8728），也不在计算中考虑闰秒（15190）。如果您比较两个时间瞬间，则差异将不包括这两个瞬间之间可能发生的闰秒。 ","date":"2020-11-25","objectID":"/posts/go-standard/:2:9","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"错误类型 Go 中有多种声明错误（Error) 的选项： errors.New 对于简单静态字符串的错误 fmt.Errorf 用于格式化的错误字符串 实现 Error() 方法的自定义类型 用 \"pkg/errors\".Wrap 的 Wrapped errors 返回错误时，请考虑以下因素以确定最佳选择： 这是一个不需要额外信息的简单错误吗？如果是这样，errors.New 足够了。 客户需要检测并处理此错误吗？如果是这样，则应使用自定义类型并实现该 Error() 方法。 您是否正在传播下游函数返回的错误？如果是这样，请查看本文后面有关错误包装 section on error wrapping 部分的内容。 否则 fmt.Errorf 就可以了。 如果客户端需要检测错误，并且您已使用创建了一个简单的错误 errors.New，请使用一个错误变量。 BadGood // package foo func Open() error { return errors.New(\"could not open\") } // package bar func use() { if err := foo.Open(); err != nil { if err.Error() == \"could not open\" { // handle } else { panic(\"unknown error\") } } } // package foo var ErrCouldNotOpen = errors.New(\"could not open\") func Open() error { return ErrCouldNotOpen } // package bar if err := foo.Open(); err != nil { if err == foo.ErrCouldNotOpen { // handle } else { panic(\"unknown error\") } } 如果您有可能需要客户端检测的错误，并且想向其中添加更多信息（例如，它不是静态字符串），则应使用自定义类型。 BadGood func open(file string) error { return fmt.Errorf(\"file %q not found\", file) } func use() { if err := open(\"testfile.txt\"); err != nil { if strings.Contains(err.Error(), \"not found\") { // handle } else { panic(\"unknown error\") } } } type errNotFound struct { file string } func (e errNotFound) Error() string { return fmt.Sprintf(\"file %q not found\", e.file) } func open(file string) error { return errNotFound{file: file} } func use() { if err := open(\"testfile.txt\"); err != nil { if _, ok := err.(errNotFound); ok { // handle } else { panic(\"unknown error\") } } } 直接导出自定义错误类型时要小心，因为它们已成为程序包公共 API 的一部分。最好公开匹配器功能以检查错误。 // package foo type errNotFound struct { file string } func (e errNotFound) Error() string { return fmt.Sprintf(\"file %q not found\", e.file) } func IsNotFoundError(err error) bool { _, ok := err.(errNotFound) return ok } func Open(file string) error { return errNotFound{file: file} } // package bar if err := foo.Open(\"foo\"); err != nil { if foo.IsNotFoundError(err) { // handle } else { panic(\"unknown error\") } } ","date":"2020-11-25","objectID":"/posts/go-standard/:2:10","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"错误包装 (Error Wrapping) 一个（函数/方法）调用失败时，有三种主要的错误传播方式： 如果没有要添加的其他上下文，并且您想要维护原始错误类型，则返回原始错误。 添加上下文，使用 \"pkg/errors\".Wrap 以便错误消息提供更多上下文 ,\"pkg/errors\".Cause 可用于提取原始错误。 如果调用者不需要检测或处理的特定错误情况，使用 fmt.Errorf。 建议在可能的地方添加上下文，以使您获得诸如“调用服务 foo：连接被拒绝”之类的更有用的错误，而不是诸如“连接被拒绝”之类的模糊错误。 在将上下文添加到返回的错误时，请避免使用“failed to”之类的短语以保持上下文简洁，这些短语会陈述明显的内容，并随着错误在堆栈中的渗透而逐渐堆积： BadGood s, err := store.New() if err != nil { return fmt.Errorf( \"failed to create new store: %s\", err) } s, err := store.New() if err != nil { return fmt.Errorf( \"new store: %s\", err) } failed to x: failed to y: failed to create new store: the error x: y: new store: the error 但是，一旦将错误发送到另一个系统，就应该明确消息是错误消息（例如使用err标记，或在日志中以”Failed”为前缀）。 另请参见 Don’t just check errors, handle them gracefully. 不要只是检查错误，要优雅地处理错误 ","date":"2020-11-25","objectID":"/posts/go-standard/:2:11","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"处理类型断言失败 type assertion 的单个返回值形式针对不正确的类型将产生 panic。因此，请始终使用“comma ok”的惯用法。 BadGood t := i.(string) t, ok := i.(string) if !ok { // 优雅地处理错误 } ","date":"2020-11-25","objectID":"/posts/go-standard/:2:12","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"不要 panic 在生产环境中运行的代码必须避免出现 panic。panic 是 cascading failures 级联失败的主要根源 。如果发生错误，该函数必须返回错误，并允许调用方决定如何处理它。 BadGood func run(args []string) { if len(args) == 0 { panic(\"an argument is required\") } // ... } func main() { run(os.Args[1:]) } func run(args []string) error { if len(args) == 0 { return errors.New(\"an argument is required\") } // ... return nil } func main() { if err := run(os.Args[1:]); err != nil { fmt.Fprintln(os.Stderr, err) os.Exit(1) } } panic/recover 不是错误处理策略。仅当发生不可恢复的事情（例如：nil 引用）时，程序才必须 panic。程序初始化是一个例外：程序启动时应使程序中止的不良情况可能会引起 panic。 var _statusTemplate = template.Must(template.New(\"name\").Parse(\"_statusHTML\")) 即使在测试代码中，也优先使用t.Fatal或者t.FailNow而不是 panic 来确保失败被标记。 BadGood // func TestFoo(t *testing.T) f, err := ioutil.TempFile(\"\", \"test\") if err != nil { panic(\"failed to set up test\") } // func TestFoo(t *testing.T) f, err := ioutil.TempFile(\"\", \"test\") if err != nil { t.Fatal(\"failed to set up test\") } ","date":"2020-11-25","objectID":"/posts/go-standard/:2:13","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"使用 go.uber.org/atomic 使用 sync/atomic 包的原子操作对原始类型 (int32, int64等）进行操作，因为很容易忘记使用原子操作来读取或修改变量。 go.uber.org/atomic 通过隐藏基础类型为这些操作增加了类型安全性。此外，它包括一个方便的atomic.Bool类型。 BadGood type foo struct { running int32 // atomic } func (f* foo) start() { if atomic.SwapInt32(\u0026f.running, 1) == 1 { // already running… return } // start the Foo } func (f *foo) isRunning() bool { return f.running == 1 // race! } type foo struct { running atomic.Bool } func (f *foo) start() { if f.running.Swap(true) { // already running… return } // start the Foo } func (f *foo) isRunning() bool { return f.running.Load() } ","date":"2020-11-25","objectID":"/posts/go-standard/:2:14","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"避免可变全局变量 使用选择依赖注入方式避免改变全局变量。 既适用于函数指针又适用于其他值类型 BadGood // sign.go var _timeNow = time.Now func sign(msg string) string { now := _timeNow() return signWithTime(msg, now) } // sign.go type signer struct { now func() time.Time } func newSigner() *signer { return \u0026signer{ now: time.Now, } } func (s *signer) Sign(msg string) string { now := s.now() return signWithTime(msg, now) } // sign_test.go func TestSign(t *testing.T) { oldTimeNow := _timeNow _timeNow = func() time.Time { return someFixedTime } defer func() { _timeNow = oldTimeNow }() assert.Equal(t, want, sign(give)) } // sign_test.go func TestSigner(t *testing.T) { s := newSigner() s.now = func() time.Time { return someFixedTime } assert.Equal(t, want, s.Sign(give)) } ","date":"2020-11-25","objectID":"/posts/go-standard/:2:15","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"避免在公共结构中嵌入类型 这些嵌入的类型泄漏实现细节、禁止类型演化和模糊的文档。 假设您使用共享的 AbstractList 实现了多种列表类型，请避免在具体的列表实现中嵌入 AbstractList。 相反，只需手动将方法写入具体的列表，该列表将委托给抽象列表。 type AbstractList struct {} // 添加将实体添加到列表中。 func (l *AbstractList) Add(e Entity) { // ... } // 移除从列表中移除实体。 func (l *AbstractList) Remove(e Entity) { // ... } BadGood // ConcreteList 是一个实体列表。 type ConcreteList struct { *AbstractList } // ConcreteList 是一个实体列表。 type ConcreteList struct { list *AbstractList } // 添加将实体添加到列表中。 func (l *ConcreteList) Add(e Entity) { return l.list.Add(e) } // 移除从列表中移除实体。 func (l *ConcreteList) Remove(e Entity) { return l.list.Remove(e) } Go 允许 类型嵌入 作为继承和组合之间的折衷。 外部类型获取嵌入类型的方法的隐式副本。 默认情况下，这些方法委托给嵌入实例的同一方法。 结构还获得与类型同名的字段。 所以，如果嵌入的类型是 public，那么字段是 public。为了保持向后兼容性，外部类型的每个未来版本都必须保留嵌入类型。 很少需要嵌入类型。 这是一种方便，可以帮助您避免编写冗长的委托方法。 即使嵌入兼容的抽象列表 interface，而不是结构体，这将为开发人员提供更大的灵活性来改变未来，但仍然泄露了具体列表使用抽象实现的细节。 BadGood // AbstractList 是各种实体列表的通用实现。 type AbstractList interface { Add(Entity) Remove(Entity) } // ConcreteList 是一个实体列表。 type ConcreteList struct { AbstractList } // ConcreteList 是一个实体列表。 type ConcreteList struct { list *AbstractList } // 添加将实体添加到列表中。 func (l *ConcreteList) Add(e Entity) { return l.list.Add(e) } // 移除从列表中移除实体。 func (l *ConcreteList) Remove(e Entity) { return l.list.Remove(e) } 无论是使用嵌入式结构还是使用嵌入式接口，嵌入式类型都会限制类型的演化. 向嵌入式接口添加方法是一个破坏性的改变。 删除嵌入类型是一个破坏性的改变。 即使使用满足相同接口的替代方法替换嵌入类型，也是一个破坏性的改变。 尽管编写这些委托方法是乏味的，但是额外的工作隐藏了实现细节，留下了更多的更改机会，还消除了在文档中发现完整列表接口的间接性操作。 ","date":"2020-11-25","objectID":"/posts/go-standard/:2:16","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"避免使用内置名称 Go语言规范language specification 概述了几个内置的， 不应在Go项目中使用的名称标识predeclared identifiers。 根据上下文的不同，将这些标识符作为名称重复使用， 将在当前作用域（或任何嵌套作用域）中隐藏原始标识符，或者混淆代码。 在最好的情况下，编译器会报错；在最坏的情况下，这样的代码可能会引入潜在的、难以恢复的错误。 BadGood var error string // `error` 作用域隐式覆盖 // or func handleErrorMessage(error string) { // `error` 作用域隐式覆盖 } var errorMessage string // `error` 指向内置的非覆盖 // or func handleErrorMessage(msg string) { // `error` 指向内置的非覆盖 } type Foo struct { // 虽然这些字段在技术上不构成阴影，但`error`或`string`字符串的重映射现在是不明确的。 error error string string } func (f Foo) Error() error { // `error` 和 `f.error` 在视觉上是相似的 return f.error } func (f Foo) String() string { // `string` and `f.string` 在视觉上是相似的 return f.string } type Foo struct { // `error` and `string` 现在是明确的。 err error str string } func (f Foo) Error() error { return f.err } func (f Foo) String() string { return f.str } 注意，编译器在使用预先分隔的标识符时不会生成错误， 但是诸如go vet之类的工具会正确地指出这些和其他情况下的隐式问题。 ","date":"2020-11-25","objectID":"/posts/go-standard/:2:17","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"避免使用 init() 尽可能避免使用init()。当init()是不可避免或可取的，代码应先尝试： 无论程序环境或调用如何，都要完全确定。 避免依赖于其他init()函数的顺序或副作用。虽然init()顺序是明确的，但代码可以更改， 因此init()函数之间的关系可能会使代码变得脆弱和容易出错。 避免访问或操作全局或环境状态，如机器信息、环境变量、工作目录、程序参数/输入等。 避免I/O，包括文件系统、网络和系统调用。 不能满足这些要求的代码可能属于要作为main()调用的一部分（或程序生命周期中的其他地方）， 或者作为main()本身的一部分写入。特别是，打算由其他程序使用的库应该特别注意完全确定性， 而不是执行“init magic” BadGood type Foo struct { // ... } var _defaultFoo Foo func init() { _defaultFoo = Foo{ // ... } } var _defaultFoo = Foo{ // ... } // or, 为了更好的可测试性: var _defaultFoo = defaultFoo() func defaultFoo() Foo { return Foo{ // ... } } type Config struct { // ... } var _config Config func init() { // Bad: 基于当前目录 cwd, _ := os.Getwd() // Bad: I/O raw, _ := ioutil.ReadFile( path.Join(cwd, \"config\", \"config.yaml\"), ) yaml.Unmarshal(raw, \u0026_config) } type Config struct { // ... } func loadConfig() Config { cwd, err := os.Getwd() // handle err raw, err := ioutil.ReadFile( path.Join(cwd, \"config\", \"config.yaml\"), ) // handle err var config Config yaml.Unmarshal(raw, \u0026config) return config } 考虑到上述情况，在某些情况下，init()可能更可取或是必要的，可能包括： 不能表示为单个赋值的复杂表达式。 可插入的钩子，如database/sql、编码类型注册表等。 对Google Cloud Functions和其他形式的确定性预计算的优化。 ","date":"2020-11-25","objectID":"/posts/go-standard/:2:18","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"追加时优先指定切片容量 追加时优先指定切片容量 在尽可能的情况下，在初始化要追加的切片时为make()提供一个容量值。 BadGood for n := 0; n \u003c b.N; n++ { data := make([]int, 0) for k := 0; k \u003c size; k++{ data = append(data, k) } } for n := 0; n \u003c b.N; n++ { data := make([]int, 0, size) for k := 0; k \u003c size; k++{ data = append(data, k) } } BenchmarkBad-4 100000000 2.48s BenchmarkGood-4 100000000 0.21s ","date":"2020-11-25","objectID":"/posts/go-standard/:2:19","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"性能 性能方面的特定准则只适用于高频场景。 ","date":"2020-11-25","objectID":"/posts/go-standard/:3:0","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"优先使用 strconv 而不是 fmt 将原语转换为字符串或从字符串转换时，strconv速度比fmt快。 BadGood for i := 0; i \u003c b.N; i++ { s := fmt.Sprint(rand.Int()) } for i := 0; i \u003c b.N; i++ { s := strconv.Itoa(rand.Int()) } BenchmarkFmtSprint-4 143 ns/op 2 allocs/op BenchmarkStrconv-4 64.2 ns/op 1 allocs/op ","date":"2020-11-25","objectID":"/posts/go-standard/:3:1","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"避免字符串到字节的转换 不要反复从固定字符串创建字节 slice。相反，请执行一次转换并捕获结果。 BadGood for i := 0; i \u003c b.N; i++ { w.Write([]byte(\"Hello world\")) } data := []byte(\"Hello world\") for i := 0; i \u003c b.N; i++ { w.Write(data) } BenchmarkBad-4 50000000 22.2 ns/op BenchmarkGood-4 500000000 3.25 ns/op ","date":"2020-11-25","objectID":"/posts/go-standard/:3:2","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"指定容器容量 尽可能指定容器容量，以便为容器预先分配内存。这将在添加元素时最小化后续分配（通过复制和调整容器大小）。 指定Map容量提示 在尽可能的情况下，在使用 make() 初始化的时候提供容量信息 make(map[T1]T2, hint) 向make()提供容量提示会在初始化时尝试调整map的大小，这将减少在将元素添加到map时为map重新分配内存。 注意，与slices不同。map capacity提示并不保证完全的抢占式分配，而是用于估计所需的hashmap bucket的数量。 因此，在将元素添加到map时，甚至在指定map容量时，仍可能发生分配。 BadGood m := make(map[string]os.FileInfo) files, _ := ioutil.ReadDir(\"./files\") for _, f := range files { m[f.Name()] = f } files, _ := ioutil.ReadDir(\"./files\") m := make(map[string]os.FileInfo, len(files)) for _, f := range files { m[f.Name()] = f } m 是在没有大小提示的情况下创建的； 在运行时可能会有更多分配。 m 是有大小提示创建的；在运行时可能会有更少的分配。 指定切片容量 在尽可能的情况下，在使用make()初始化切片时提供容量信息，特别是在追加切片时。 make([]T, length, capacity) 与maps不同，slice capacity不是一个提示：编译器将为提供给make()的slice的容量分配足够的内存， 这意味着后续的append()`操作将导致零分配（直到slice的长度与容量匹配，在此之后，任何append都可能调整大小以容纳其他元素）。 BadGood for n := 0; n \u003c b.N; n++ { data := make([]int, 0) for k := 0; k \u003c size; k++{ data = append(data, k) } } for n := 0; n \u003c b.N; n++ { data := make([]int, 0, size) for k := 0; k \u003c size; k++{ data = append(data, k) } } BenchmarkBad-4 100000000 2.48s BenchmarkGood-4 100000000 0.21s ","date":"2020-11-25","objectID":"/posts/go-standard/:3:3","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"规范 ","date":"2020-11-25","objectID":"/posts/go-standard/:4:0","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"一致性 本文中概述的一些标准都是客观性的评估，是根据场景、上下文、或者主观性的判断； 但是最重要的是，保持一致. 一致性的代码更容易维护、是更合理的、需要更少的学习成本、并且随着新的约定出现或者出现错误后更容易迁移、更新、修复 bug 相反，在一个代码库中包含多个完全不同或冲突的代码风格会导致维护成本开销、不确定性和认知偏差。所有这些都会直接导致速度降低、代码审查痛苦、而且增加 bug 数量。 将这些标准应用于代码库时，建议在 package（或更大）级别进行更改，子包级别的应用程序通过将多个样式引入到同一代码中，违反了上述关注点。 ","date":"2020-11-25","objectID":"/posts/go-standard/:4:1","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"相似的声明放在一组 Go 语言支持将相似的声明放在一个组内。 BadGood import \"a\" import \"b\" import ( \"a\" \"b\" ) 这同样适用于常量、变量和类型声明： BadGood const a = 1 const b = 2 var a = 1 var b = 2 type Area float64 type Volume float64 const ( a = 1 b = 2 ) var ( a = 1 b = 2 ) type ( Area float64 Volume float64 ) 仅将相关的声明放在一组。不要将不相关的声明放在一组。 BadGood type Operation int const ( Add Operation = iota + 1 Subtract Multiply ENV_VAR = \"MY_ENV\" ) type Operation int const ( Add Operation = iota + 1 Subtract Multiply ) const ENV_VAR = \"MY_ENV\" 分组使用的位置没有限制，例如：你可以在函数内部使用它们： BadGood func f() string { var red = color.New(0xff0000) var green = color.New(0x00ff00) var blue = color.New(0x0000ff) ... } func f() string { var ( red = color.New(0xff0000) green = color.New(0x00ff00) blue = color.New(0x0000ff) ) ... } ","date":"2020-11-25","objectID":"/posts/go-standard/:4:2","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"import 分组 导入应该分为两组： 标准库 当前项目内的引用 第三方库 默认情况下，这是 goimports 应用的分组。 BadGood import ( \"fmt\" \"os\" \"go.uber.org/atomic\" \"golang.org/x/sync/errgroup\" \"currentProject/model\" \"currentProject/handler\" ) import ( \"fmt\" \"os\" \"currentProject/model\" \"currentProject/handler\" \"go.uber.org/atomic\" \"golang.org/x/sync/errgroup\" ) ","date":"2020-11-25","objectID":"/posts/go-standard/:4:3","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"包名 当命名包时，请按下面规则选择一个名称： 全部小写。没有大写或下划线。 大多数使用命名导入的情况下，不需要重命名。 简短而简洁。请记住，在每个使用的地方都完整标识了该名称。 不用复数。例如net/url，而不是net/urls。 不要用“common”，“util”，“shared”或“lib”。这些是不好的，信息量不足的名称。(应该使用更具体的命名方式 如httputil, mathutil 等。) 另请参阅 Package Names 和 Go 包样式指南. ","date":"2020-11-25","objectID":"/posts/go-standard/:4:4","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"函数名 我们遵循 Go 社区关于使用 MixedCaps 作为函数名 的约定。有一个例外，为了对相关的测试用例进行分组，函数名可能包含下划线，如：TestMyFunction_WhatIsBeingTested. ","date":"2020-11-25","objectID":"/posts/go-standard/:4:5","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"导入别名 如果程序包名称与导入路径的最后一个元素不匹配，则必须使用导入别名。 import ( \"net/http\" client \"example.com/client-go\" trace \"example.com/trace/v2\" ) 在所有其他情况下，除非导入之间有直接冲突，否则应避免导入别名。 BadGood import ( \"fmt\" \"os\" nettrace \"golang.net/x/trace\" ) import ( \"fmt\" \"os\" \"runtime/trace\" nettrace \"golang.net/x/trace\" ) ","date":"2020-11-25","objectID":"/posts/go-standard/:4:6","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"函数分组与顺序 函数应按粗略的调用顺序排序。 同一文件中的函数应按接收者分组。 因此，导出的函数应先出现在文件中，放在struct, const, var定义的后面。 在定义类型之后，但在接收者的其余方法之前，可能会出现一个 newXYZ()/NewXYZ() 由于函数是按接收者分组的，因此普通工具函数应在文件末尾出现。 BadGood func (s *something) Cost() { return calcCost(s.weights) } type something struct{ ... } func calcCost(n []int) int {...} func (s *something) Stop() {...} func newSomething() *something { return \u0026something{} } type something struct{ ... } func newSomething() *something { return \u0026something{} } func (s *something) Cost() { return calcCost(s.weights) } func (s *something) Stop() {...} func calcCost(n []int) int {...} ","date":"2020-11-25","objectID":"/posts/go-standard/:4:7","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"减少嵌套 代码应通过尽可能先处理错误情况/特殊情况并尽早返回或继续循环来减少嵌套。减少嵌套多个级别的代码的代码量。 BadGood for _, v := range data { if v.F1 == 1 { v = process(v) if err := v.Call(); err == nil { v.Send() } else { return err } } else { log.Printf(\"Invalid v: %v\", v) } } for _, v := range data { if v.F1 != 1 { log.Printf(\"Invalid v: %v\", v) continue } v = process(v) if err := v.Call(); err != nil { return err } v.Send() } ","date":"2020-11-25","objectID":"/posts/go-standard/:4:8","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"不必要的 else 如果在 if 的两个分支中都设置了变量，则可以将其替换为单个 if。 BadGood var a int if b { a = 100 } else { a = 10 } a := 10 if b { a = 100 } ","date":"2020-11-25","objectID":"/posts/go-standard/:4:9","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"顶层变量声明 在顶层，使用标准var关键字。请勿指定类型，除非它与表达式的类型不同。 BadGood var _s string = F() func F() string { return \"A\" } var _s = F() // 由于 F 已经明确了返回一个字符串类型，因此我们没有必要显式指定_s 的类型 // 还是那种类型 func F() string { return \"A\" } 如果表达式的类型与所需的类型不完全匹配，请指定类型。 type myError struct{} func (myError) Error() string { return \"error\" } func F() myError { return myError{} } var _e error = F() // F 返回一个 myError 类型的实例，但是我们要 error 类型 ","date":"2020-11-25","objectID":"/posts/go-standard/:4:10","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"对于未导出的顶层常量和变量，使用_作为前缀 在未导出的顶级vars和consts， 前面加上前缀_，以使它们在使用时明确表示它们是全局符号。 例外：未导出的错误值，应以err开头。 基本依据：顶级变量和常量具有包范围作用域。使用通用名称可能很容易在其他文件中意外使用错误的值。 BadGood // foo.go const ( defaultPort = 8080 defaultUser = \"user\" ) // bar.go func Bar() { defaultPort := 9090 ... fmt.Println(\"Default port\", defaultPort) // We will not see a compile error if the first line of // Bar() is deleted. } // foo.go const ( _defaultPort = 8080 _defaultUser = \"user\" ) ","date":"2020-11-25","objectID":"/posts/go-standard/:4:11","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"结构体中的嵌入 嵌入式类型（例如 mutex）应位于结构体内的字段列表的顶部，并且必须有一个空行将嵌入式字段与常规字段分隔开。 BadGood type Client struct { version int http.Client } type Client struct { http.Client version int } 内嵌应该提供切实的好处，比如以语义上合适的方式添加或增强功能。 它应该在对用户不利影响的情况下完成这项工作（另请参见：避免在公共结构中嵌入类型Avoid Embedding Types in Public Structs）。 嵌入 不应该: 纯粹是为了美观或方便。 使外部类型更难构造或使用。 影响外部类型的零值。如果外部类型有一个有用的零值，则在嵌入内部类型之后应该仍然有一个有用的零值。 作为嵌入内部类型的副作用，从外部类型公开不相关的函数或字段。 公开未导出的类型。 影响外部类型的复制形式。 更改外部类型的API或类型语义。 嵌入内部类型的非规范形式。 公开外部类型的实现详细信息。 允许用户观察或控制类型内部。 通过包装的方式改变内部函数的一般行为，这种包装方式会给用户带来一些意料之外情况。 简单地说，有意识地和有目的地嵌入。一种很好的测试体验是， “是否所有这些导出的内部方法/字段都将直接添加到外部类型” 如果答案是some或no，不要嵌入内部类型-而是使用字段。 BadGood type A struct { // Bad: A.Lock() and A.Unlock() 现在可用 // 不提供任何功能性好处，并允许用户控制有关A的内部细节。 sync.Mutex } type countingWriteCloser struct { // Good: Write() 在外层提供用于特定目的， // 并且委托工作到内部类型的Write()中。 io.WriteCloser count int } func (w *countingWriteCloser) Write(bs []byte) (int, error) { w.count += len(bs) return w.WriteCloser.Write(bs) } type Book struct { // Bad: 指针更改零值的有用性 io.ReadWriter // other fields } // later var b Book b.Read(...) // panic: nil pointer b.String() // panic: nil pointer b.Write(...) // panic: nil pointer type Book struct { // Good: 有用的零值 bytes.Buffer // other fields } // later var b Book b.Read(...) // ok b.String() // ok b.Write(...) // ok type Client struct { sync.Mutex sync.WaitGroup bytes.Buffer url.URL } type Client struct { mtx sync.Mutex wg sync.WaitGroup buf bytes.Buffer url url.URL } ","date":"2020-11-25","objectID":"/posts/go-standard/:4:12","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"使用字段名初始化结构体 初始化结构体时，应该指定字段名称。现在由 go vet 强制执行。 BadGood k := User{\"John\", \"Doe\", true} k := User{ FirstName: \"John\", LastName: \"Doe\", Admin: true, } 例外：如果有 3 个或更少的字段，则可以在测试表中省略字段名称。 tests := []struct{ op Operation want string }{ {Add, \"add\"}, {Subtract, \"subtract\"}, } ","date":"2020-11-25","objectID":"/posts/go-standard/:4:13","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"本地变量声明 如果将变量明确设置为某个值，则应使用短变量声明形式 (:=)。 BadGood var s = \"foo\" s := \"foo\" 但是，在某些情况下，var 使用关键字时默认值会更清晰。例如，声明空切片。 BadGood func f(list []int) { filtered := []int{} for _, v := range list { if v \u003e 10 { filtered = append(filtered, v) } } } func f(list []int) { var filtered []int for _, v := range list { if v \u003e 10 { filtered = append(filtered, v) } } } ","date":"2020-11-25","objectID":"/posts/go-standard/:4:14","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"nil 是一个有效的 slice nil 是一个有效的长度为 0 的 slice，这意味着， 您不应明确返回长度为零的切片。应该返回nil 来代替。 BadGood if x == \"\" { return []int{} } if x == \"\" { return nil } 要检查切片是否为空，请始终使用len(s) == 0。而非 nil。 BadGood func isEmpty(s []string) bool { return s == nil } func isEmpty(s []string) bool { return len(s) == 0 } 零值切片（用var声明的切片）可立即使用，无需调用make()创建。 BadGood nums := []int{} // or, nums := make([]int) if add1 { nums = append(nums, 1) } if add2 { nums = append(nums, 2) } var nums []int if add1 { nums = append(nums, 1) } if add2 { nums = append(nums, 2) } 记住，虽然nil切片是有效的切片，但它不等于长度为0的切片（一个为nil，另一个不是），并且在不同的情况下（例如序列化），这两个切片的处理方式可能不同。 ","date":"2020-11-25","objectID":"/posts/go-standard/:4:15","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"缩小变量作用域 如果有可能，尽量缩小变量作用范围。除非它与 减少嵌套的规则冲突。 BadGood err := ioutil.WriteFile(name, data, 0644) if err != nil { return err } if err := ioutil.WriteFile(name, data, 0644); err != nil { return err } 如果需要在 if 之外使用函数调用的结果，则不应尝试缩小范围。 BadGood if data, err := ioutil.ReadFile(name); err == nil { err = cfg.Decode(data) if err != nil { return err } fmt.Println(cfg) return nil } else { return err } data, err := ioutil.ReadFile(name) if err != nil { return err } if err := cfg.Decode(data); err != nil { return err } fmt.Println(cfg) return nil ","date":"2020-11-25","objectID":"/posts/go-standard/:4:16","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"避免参数语义不明确(Avoid Naked Parameters) 函数调用中的意义不明确的参数可能会损害可读性。当参数名称的含义不明显时，请为参数添加 C 样式注释 (/* ... */) BadGood // func printInfo(name string, isLocal, done bool) printInfo(\"foo\", true, true) // func printInfo(name string, isLocal, done bool) printInfo(\"foo\", true /* isLocal */, true /* done */) 对于上面的示例代码，还有一种更好的处理方式是将上面的 bool 类型换成自定义类型。将来，该参数可以支持不仅仅局限于两个状态（true/false）。 type Region int const ( UnknownRegion Region = iota Local ) type Status int const ( StatusReady Status= iota + 1 StatusDone // Maybe we will have a StatusInProgress in the future. ) func printInfo(name string, region Region, status Status) ","date":"2020-11-25","objectID":"/posts/go-standard/:4:17","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"使用原始字符串字面值，避免转义 Go 支持使用 原始字符串字面值，也就是 \" ` \" 来表示原生字符串，在需要转义的场景下，我们应该尽量使用这种方案来替换。 可以跨越多行并包含引号。使用这些字符串可以避免更难阅读的手工转义的字符串。 BadGood wantError := \"unknown name:\\\"test\\\"\" wantError := `unknown error:\"test\"` ","date":"2020-11-25","objectID":"/posts/go-standard/:4:18","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"初始化 Struct 引用 在初始化结构引用时，请使用\u0026T{}代替new(T)，以使其与结构体初始化一致。 BadGood sval := T{Name: \"foo\"} // inconsistent sptr := new(T) sptr.Name = \"bar\" sval := T{Name: \"foo\"} sptr := \u0026T{Name: \"bar\"} ","date":"2020-11-25","objectID":"/posts/go-standard/:4:19","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"初始化 Maps 对于空 map 请使用 make(..) 初始化， 并且 map 是通过编程方式填充的。 这使得 map 初始化在表现上不同于声明，并且它还可以方便地在 make 后添加大小提示。 BadGood var ( // m1 读写安全; // m2 在写入时会 panic m1 = map[T1]T2{} m2 map[T1]T2 ) var ( // m1 读写安全; // m2 在写入时会 panic m1 = make(map[T1]T2) m2 map[T1]T2 ) 声明和初始化看起来非常相似的。 声明和初始化看起来差别非常大。 在尽可能的情况下，请在初始化时提供 map 容量大小，详细请看 指定Map容量提示。 另外，如果 map 包含固定的元素列表，则使用 map literals(map 初始化列表) 初始化映射。 BadGood m := make(map[T1]T2, 3) m[k1] = v1 m[k2] = v2 m[k3] = v3 m := map[T1]T2{ k1: v1, k2: v2, k3: v3, } 基本准则是：在初始化时使用 map 初始化列表 来添加一组固定的元素。否则使用 make (如果可以，请尽量指定 map 容量)。 ","date":"2020-11-25","objectID":"/posts/go-standard/:4:20","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"编程模式 ","date":"2020-11-25","objectID":"/posts/go-standard/:5:0","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"表驱动测试 当测试逻辑是重复的时候，通过 subtests 使用 table 驱动的方式编写 case 代码看上去会更简洁。而且目前编译器可以通过快捷键快速生成单元测试方法，可以帮助养成良好习惯。 BadGood // func TestSplitHostPort(t *testing.T) host, port, err := net.SplitHostPort(\"192.0.2.0:8000\") require.NoError(t, err) assert.Equal(t, \"192.0.2.0\", host) assert.Equal(t, \"8000\", port) host, port, err = net.SplitHostPort(\"192.0.2.0:http\") require.NoError(t, err) assert.Equal(t, \"192.0.2.0\", host) assert.Equal(t, \"http\", port) host, port, err = net.SplitHostPort(\":8000\") require.NoError(t, err) assert.Equal(t, \"\", host) assert.Equal(t, \"8000\", port) host, port, err = net.SplitHostPort(\"1:8\") require.NoError(t, err) assert.Equal(t, \"1\", host) assert.Equal(t, \"8\", port) // func TestSplitHostPort(t *testing.T) tests := []struct{ give string wantHost string wantPort string }{ { give: \"192.0.2.0:8000\", wantHost: \"192.0.2.0\", wantPort: \"8000\", }, { give: \"192.0.2.0:http\", wantHost: \"192.0.2.0\", wantPort: \"http\", }, { give: \":8000\", wantHost: \"\", wantPort: \"8000\", }, { give: \"1:8\", wantHost: \"1\", wantPort: \"8\", }, } for _, tt := range tests { t.Run(tt.give, func(t *testing.T) { host, port, err := net.SplitHostPort(tt.give) require.NoError(t, err) assert.Equal(t, tt.wantHost, host) assert.Equal(t, tt.wantPort, port) }) } 很明显，使用 test table 的方式在代码逻辑扩展的时候，比如新增 test case，都会显得更加的清晰。 我们遵循这样的约定：将结构体切片称为tests。 每个测试用例称为tt。此外，我们鼓励使用give和want前缀说明每个测试用例的输入和输出值。 tests := []struct{ give string wantHost string wantPort string }{ // ... } for _, tt := range tests { // ... } ","date":"2020-11-25","objectID":"/posts/go-standard/:5:1","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"功能选项 功能选项是一种模式，您可以在其中声明一个不透明 Option 类型，该类型在某些内部结构中记录信息。您接受这些选项的可变编号，并根据内部结构上的选项记录的全部信息采取行动。 将此模式用于您需要扩展的构造函数和其他公共 API 中的可选参数，尤其是在这些功能上已经具有三个或更多参数的情况下。 BadGood // package db func Open( addr string, cache bool, logger *zap.Logger ) (*Connection, error) { // ... } // package db type Option interface { // ... } func WithCache(c bool) Option { // ... } func WithLogger(log *zap.Logger) Option { // ... } // Open creates a connection. func Open( addr string, opts ...Option, ) (*Connection, error) { // ... } 必须始终提供缓存和记录器参数，即使用户希望使用默认值。 db.Open(addr, db.DefaultCache, zap.NewNop()) db.Open(addr, db.DefaultCache, log) db.Open(addr, false /* cache */, zap.NewNop()) db.Open(addr, false /* cache */, log) 只有在需要时才提供选项。 db.Open(addr) db.Open(addr, db.WithLogger(log)) db.Open(addr, db.WithCache(false)) db.Open( addr, db.WithCache(false), db.WithLogger(log), ) Our suggested way of implementing this pattern is with an Option interface that holds an unexported method, recording options on an unexported options struct. 我们建议实现此模式的方法是使用一个 Option 接口，该接口保存一个未导出的方法，在一个未导出的 options 结构上记录选项。 type options struct { cache bool logger *zap.Logger } type Option interface { apply(*options) } type cacheOption bool func (c cacheOption) apply(opts *options) { opts.cache = bool(c) } func WithCache(c bool) Option { return cacheOption(c) } type loggerOption struct { Log *zap.Logger } func (l loggerOption) apply(opts *options) { opts.logger = l.Log } func WithLogger(log *zap.Logger) Option { return loggerOption{Log: log} } // Open creates a connection. func Open( addr string, opts ...Option, ) (*Connection, error) { options := options{ cache: defaultCache, logger: zap.NewNop(), } for _, o := range opts { o.apply(\u0026options) } // ... } 注意: 还有一种使用闭包实现这个模式的方法，但是我们相信上面的模式为作者提供了更多的灵活性，并且更容易对用户进行调试和测试。特别是，在不可能进行比较的情况下它允许在测试和模拟中对选项进行比较。此外，它还允许选项实现其他接口，包括 fmt.Stringer，允许用户读取选项的字符串表示形式。 还可以参考下面资料： Self-referential functions and the design of options Functional options for friendly APIs ","date":"2020-11-25","objectID":"/posts/go-standard/:5:2","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["代码规范"],"content":"Linting 比任何 “blessed” linter 集更重要的是，lint在一个代码库中始终保持一致。 建议至少使用以下linters，因为我认为它们有助于发现最常见的问题，并在不需要规定的情况下为代码质量建立一个高标准： errcheck 以确保错误得到处理 goimports 格式化代码和管理 imports golint 指出常见的文体错误 govet 分析代码中的常见错误 staticcheck 各种静态分析检查 ","date":"2020-11-25","objectID":"/posts/go-standard/:6:0","tags":["go"],"title":"Go 语言开发及常用库的使用规范(语言篇)","uri":"/posts/go-standard/"},{"categories":["源码解读"],"content":"Go 的 map 作为该语言最常见的基础数据结构之一。 ","date":"2020-06-14","objectID":"/posts/go-map/:0:0","tags":["go"],"title":"Go Map 源码解读","uri":"/posts/go-map/"},{"categories":["源码解读"],"content":"源码解读 Go 语言实现的 map 并非是完全的哈希 map ，是一种类似两层树状的结构，根据 key 的哈希值的低八位 决定第一层的位置，根据高八位决定第二层，如果第二层所在冲突了则会有一个额外的位置 用于存储哈希碰撞的 kv。看图会帮助理解： ","date":"2020-06-14","objectID":"/posts/go-map/:1:0","tags":["go"],"title":"Go Map 源码解读","uri":"/posts/go-map/"},{"categories":["源码解读"],"content":"图解： ","date":"2020-06-14","objectID":"/posts/go-map/:1:1","tags":["go"],"title":"Go Map 源码解读","uri":"/posts/go-map/"},{"categories":["源码解读"],"content":"数据结构 源码在 go/src/runtime/map.go 文件中： // map 的实现 type hmap struct { count int // 已使用位置数（即 len() 方法会返回该值），之所以说已使用的是因为并非所有的位置都存放位置 flags uint8 // map的状态，通过该字段判断当前是否被某个进程进行写操作 B uint8 // 2^B 为桶的数量， B为 3 时 2^3 一共 8 个桶 noverflow uint16 // 溢出的桶数量 hash0 uint32 // hash seed buckets unsafe.Pointer // 桶的数组 oldbuckets unsafe.Pointer // 旧桶的数组。map 扩容时 原 buckets 变成 oldbuckets 并将数据逐步迁移，并非一次性迁移 nevacuate uintptr // 扩容进度记录 extra *mapextra // 额外信息。存储非指针数据（为了优化空间） } type mapextra struct { // 为了优化空间 将非指针数据存储在 mapextra里 overflow *[]*bmap // 对应 hmap.buckets oldoverflow *[]*bmap // 对应 hmap.oldbuckets // 指向下一个空闲的 bucket nextOverflow *bmap } // bucket 即桶 type bmap struct { // tophash 存储每个 key 的 tophash 即 key 的前八位，用于判断读取的 key 是否在当前桶里。 tophash [bucketCnt]uint8 // 之后是 key-value 的格子，每个桶最多只能存 8 个且 以 key1...key8value1...value8 的形式存储。 // 还有一个 overflow 用于指向下一个桶。 } ","date":"2020-06-14","objectID":"/posts/go-map/:1:2","tags":["go"],"title":"Go Map 源码解读","uri":"/posts/go-map/"},{"categories":["源码解读"],"content":"读取 按 key 读取 遍历 ","date":"2020-06-14","objectID":"/posts/go-map/:1:3","tags":["go"],"title":"Go Map 源码解读","uri":"/posts/go-map/"},{"categories":["源码解读"],"content":"写入 ","date":"2020-06-14","objectID":"/posts/go-map/:1:4","tags":["go"],"title":"Go Map 源码解读","uri":"/posts/go-map/"},{"categories":["源码解读"],"content":"删除 coming soon ","date":"2020-06-14","objectID":"/posts/go-map/:1:5","tags":["go"],"title":"Go Map 源码解读","uri":"/posts/go-map/"},{"categories":null,"content":"技术忠实爱好者，喜欢运动，喜欢与大自然近距离接触。 目前主要经历在微服务、服务架构、服务治理方向 工作内容目前偏向于 Kubernetes 组件开发、网关、弹性伸缩等 有过实际高并发场景的经验 喜欢分享愿意分享 关于我： 邮箱：yusankurban@gmail.com 坐标：北京 微信：yusan--- 欢迎各路大神关注公众号，提出宝贵的意见，谢谢~ 公众号二维码\" 公众号二维码 ","date":"2020-03-09","objectID":"/about/:0:0","tags":null,"title":"About me","uri":"/about/"},{"categories":["源码解读"],"content":"Go 的 channel 作为该语言很重要的特性，作为一个 gopher 有必要详细了解其实现原理。 原理解读 Go 语言的 channel 实现源码在go/src/runtime/chan.go 文件里。（go version ：1.13.4） ","date":"2020-03-06","objectID":"/posts/go-channel/:0:0","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"数据结构 首先看一下基础数据结构： // go 语言的 channel 结构以队列的形式实现 type hchan struct { qcount uint // total data in the queue，队列中元素总数 dataqsiz uint // size of the circular queue，循环队列的大小 buf unsafe.Pointer // points to an array of dataqsiz elements， 指向循环队列中元素的指针 elemsize uint16 // 元素 size closed uint32 // channel 是否关闭标志 elemtype *_type // element type // channel 元素类型 sendx uint // send index // 写入 channel 元素的索引 recvx uint // receive index // 从 channel 读取的元素索引 recvq waitq // list of recv waiters // 读取 channel 的等待队列（即阻塞的协程） sendq waitq // list of send waiters // 写入 channel 的等待队列 // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. lock mutex // 互斥锁 } // 双向链表结构，其中每一个元素代表着等待读取或写入 channel 的协程 type waitq struct { first *sudog last *sudog } 通过源码数据结构，对 go 的 channel 实现有了初步的了解，解答了在我们读取或写入 channel 时，其中元素在哪儿，我们的协程在哪儿等待等数据相关问题。 channel 底层实现是以队列作为载体，通过互斥锁保证在同一个时间点，只有一个待读取的协程读元素或待写入的协程写入元素。 如果有多个协程同时读取 channel 时，他们会进入读取等待队列：recvq，反之进入写入等待队列：sendq。 buf 作为指针，指向 channel 中存储元素的数组的地址。 sendx,recvx 作为channel 队列中写入和读取到元素的索引值。 closed 为 channel 当前是否已被关闭标志。 ","date":"2020-03-06","objectID":"/posts/go-channel/:1:0","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"主要方法（func） 以我们常用的 make(chan Type), 写入元素(chan \u003c- element)和读取元素(\u003c-chan)为例 ","date":"2020-03-06","objectID":"/posts/go-channel/:2:0","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"初始化（make） 在实际使用中 我会用下面的代码初始化一个 channel： make(chan Type, size int) 其实现源码入下： // t 为 channel 类型，size 为我们传入 channel 大小 func makechan(t *chantype, size int) *hchan { elem := t.elem // 如果 size 超过声明类型最大值 编译的时候会报错，但是这里多一次判断为了更安全 if elem.size \u003e= 1\u003c\u003c16 { // 抛出异常 throw(\"makechan: invalid channel element type\") } // align 为类型的对齐系数，不同平台上对其系数不完全一样，但是都最大值 maxAlign=8 // 不同类型的对齐系数不一样 但是均以 2^N 形式 if hchanSize%maxAlign != 0 || elem.align \u003e maxAlign { throw(\"makechan: bad alignment\") } // 检查是否channel 大小值是否溢出 mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u003e maxAlloc-hchanSize || size \u003c 0 { panic(plainError(\"makechan: size out of range\")) } // 根据 size 和原始是否为指针情况，分配内存初始化 channel var c *hchan switch { // channel size 为 0 case mem == 0: c = (*hchan)(mallocgc(hchanSize, nil, true)) c.buf = c.raceaddr() case elem.ptrdata == 0: // 元素不包含指针，则将为元素分配内存，并将 buf 指向该地址 c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // 元素包含指针，buf 指向该指针指向地址 c = new(hchan) c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) return c } 可以看出，channel 中的元素最终都是以指针的方式存储，即便初始化时 用非指针类型（如 string），在初始化话的时候 会先分配内存 并将 channel 的元素指针字段指向该地址。 ","date":"2020-03-06","objectID":"/posts/go-channel/:2:1","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"写入 先给出源码： // entry point for c \u003c- x from compiled code // 代码重 `c \u003c- x` 编译时，会编译成该方法从而被调用 func chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc()) } /* * generic single channel send/recv * If block is not nil, * then the protocol will not * sleep but return if it could * not complete. * * sleep can wake up with g.param == nil * when a channel involved in the sleep has * been closed. it is easiest to loop and re-run * the operation; we'll see that it's now closed. */ // 向 channel 写入 // c: channel // ep: 写入元素地址 // block: 表示该 channel 是否被阻塞 // callerpc: func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { if c == nil { // return or panic } if raceenabled { // 不同协程之前竞争写入 racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) } // 没有阻塞 \u0026\u0026 未关闭 \u0026\u0026 （channel 为空且没有协程读取 或 channel 已满，直接返回 false） if !block \u0026\u0026 c.closed == 0 \u0026\u0026 ((c.dataqsiz == 0 \u0026\u0026 c.recvq.first == nil) || (c.dataqsiz \u003e 0 \u0026\u0026 c.qcount == c.dataqsiz)) { return false } var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() } // 上锁 准备写 lock(\u0026c.lock) // 已关闭 解锁并 panic if c.closed != 0 { unlock(\u0026c.lock) panic(plainError(\"send on closed channel\")) } // 从等待读取的队列中 拿出第一个协程，写入并发送到该协程 if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true } // 如果 channel 缓存有空间，则向缓存中写入 // 此时是 channel 是有 buffer channel if c.qcount \u003c c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) // 应该是协程之间竞争，暂时没有完全搞懂 if raceenabled { raceacquire(qp) racerelease(qp) } // 写入缓存 typedmemmove(c.elemtype, qp, ep) // 写入位置加一 c.sendx++ // 如果写完 buffer 满了，将位置置位 0 if c.sendx == c.dataqsiz { c.sendx = 0 } // channel 数据总数加一 c.qcount++ // 解锁 unlock(\u0026c.lock) return true } // 如果是非阻塞类型 channel，则只返回 if !block { unlock(\u0026c.lock) return false } // 如果是阻塞类型，则一直阻塞一直到被读取，保证数据在被读取之前不被内存回收 // Block on the channel. Some receiver will complete our operation for us. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } KeepAlive(ep) // someone woke us up. if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil if gp.param == nil { if c.closed == 0 { throw(\"chansend: spurious wakeup\") } panic(plainError(\"send on closed channel\")) } gp.param = nil if mysg.releasetime \u003e 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) return true } ","date":"2020-03-06","objectID":"/posts/go-channel/:2:2","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"读取 近期补充。。。 使用 Channel是Go中的一个核心类型，你可以把它看成一个管道，通过它并发核心单元就可以发送或者接收数据进行通讯(communication)。 它的操作符是箭头 \u003c- 。 ch \u003c- v v := \u003c-ch (箭头的指向就是数据的流向) 就像 map 和 slice 数据类型一样, channel必须先创建再使用: ch := make(chan int) ","date":"2020-03-06","objectID":"/posts/go-channel/:2:3","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"Channel 类型 Channel类型的定义格式如下： ChannelType = ( \"chan\" | \"chan\" \"\u003c-\" | \"\u003c-\" \"chan\" ) ElementType . 它包括三种类型的定义。可选的\u003c-代表channel的方向。如果没有指定方向，那么Channel就是双向的，既可以接收数据，也可以发送数据。 chan T // 可以接收和发送类型为 T 的数据 chan\u003c- float64 // 只可以用来发送 float64 类型的数据 \u003c-chan int // 只可以用来接收 int 类型的数据 \u003c-总是优先和最左边的类型结合。(The \u003c- operator associates with the leftmost chan possible) chan\u003c- chan int // 等价 chan\u003c- (chan int) chan\u003c- \u003c-chan int // 等价 chan\u003c- (\u003c-chan int) \u003c-chan \u003c-chan int // 等价 \u003c-chan (\u003c-chan int) chan (\u003c-chan int) 使用make初始化Channel,并且可以设置容量: make(chan int, 100) 容量(capacity)代表Channel容纳的最多的元素的数量，代表Channel的缓存的大小。 如果没有设置容量，或者容量设置为0, 说明Channel没有缓存，只有sender和receiver都准备好了后它们的通讯(communication)才会发生(Blocking)。如果设置了缓存，就有可能不发生阻塞， 只有buffer满了后 send才会阻塞， 而只有缓存空了后receive才会阻塞。一个nil channel不会通信。 可以通过内建的close方法可以关闭Channel。 你可以在多个goroutine从/往 一个channel 中 receive/send 数据, 不必考虑额外的同步措施。 Channel可以作为一个先入先出(FIFO)的队列，接收的数据和发送的数据的顺序是一致的。 channel的 receive支持 multi-valued assignment，如 v, ok := \u003c-ch 它可以用来检查Channel是否已经被关闭了。 send语句 send语句用来往Channel中发送数据， 如ch \u003c- 3。 它的定义如下: SendStmt = Channel \"\u003c-\" Expression . Channel = Expression . 在通讯(communication)开始前channel和expression必选先求值出来(evaluated)，比如下面的(3+4)先计算出7然后再发送给channel。 c := make(chan int) defer close(c) go func() { c \u003c- 3 + 4 }() i := \u003c-c fmt.Println(i) send被执行前(proceed)通讯(communication)一直被阻塞着。如前所言，无缓存的channel只有在receiver准备好后send才被执行。如果有缓存，并且缓存未满，则send会被执行。 往一个已经被close的channel中继续发送数据会导致run-time panic。 往nil channel中发送数据会一致被阻塞着。 receive 操作符 \u003c-ch用来从channel ch中接收数据，这个表达式会一直被block,直到有数据可以接收。 从一个nil channel中接收数据会一直被block。 从一个被close的channel中接收数据不会被阻塞，而是立即返回，接收完已发送的数据后会返回元素类型的零值(zero value)。 如前所述，你可以使用一个额外的返回参数来检查channel是否关闭。 x, ok := \u003c-ch x, ok = \u003c-ch var x, ok = \u003c-ch ","date":"2020-03-06","objectID":"/posts/go-channel/:3:0","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"blocking 缺省情况下，发送和接收会一直阻塞着，知道另一方准备好。这种方式可以用来在gororutine中进行同步，而不必使用显示的锁或者条件变量。 如官方的例子中x, y := \u003c-c, \u003c-c这句会一直等待计算结果发送到channel中。 import \"fmt\" func sum(s []int, c chan int) { sum := 0 for _, v := range s { sum += v } c \u003c- sum } func main() { s := []int{7, 2, 8, -9, 4, 0} c := make(chan int) go sum(s[:len(s)/2], c) go sum(s[len(s)/2:], c) x, y := \u003c-c, \u003c-c // receive from c fmt.Println(x, y, x+y) } ","date":"2020-03-06","objectID":"/posts/go-channel/:4:0","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"Buffered Channels make的第二个参数指定缓存的大小：ch := make(chan int, 100)。 通过缓存的使用，可以尽量避免阻塞，提供应用的性能。 ","date":"2020-03-06","objectID":"/posts/go-channel/:5:0","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"Range for …… range语句可以处理Channel。 func main() { go func() { time.Sleep(1 * time.Hour) }() c := make(chan int) go func() { for i := 0; i \u003c 10; i = i + 1 { c \u003c- i } close(c) }() for i := range c { fmt.Println(i) } fmt.Println(\"Finished\") } range c产生的迭代值为Channel中发送的值，它会一直迭代知道channel被关闭。上面的例子中如果把close(c)注释掉，程序会一直阻塞在for …… range那一行。 ","date":"2020-03-06","objectID":"/posts/go-channel/:6:0","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"select select语句选择一组可能的send操作和receive操作去处理。它类似switch,但是只是用来处理通讯(communication)操作。 它的case可以是send语句，也可以是receive语句，亦或者default。 receive语句可以将值赋值给一个或者两个变量。它必须是一个receive操作。 最多允许有一个default case,它可以放在case列表的任何位置，尽管我们大部分会将它放在最后。 import \"fmt\" func fibonacci(c, quit chan int) { x, y := 0, 1 for { select { case c \u003c- x: x, y = y, x+y case \u003c-quit: fmt.Println(\"quit\") return } } } func main() { c := make(chan int) quit := make(chan int) go func() { for i := 0; i \u003c 10; i++ { fmt.Println(\u003c-c) } quit \u003c- 0 }() fibonacci(c, quit) } 如果有同时多个case去处理,比如同时有多个channel可以接收数据，那么Go会伪随机的选择一个case处理(pseudo-random)。如果没有case需要处理，则会选择default去处理，如果default case存在的情况下。如果没有default case，则select语句会阻塞，直到某个case需要处理。 需要注意的是，nil channel上的操作会一直被阻塞，如果没有default case,只有nil channel的select会一直被阻塞。 select语句和switch语句一样，它不是循环，它只会选择一个case来处理，如果想一直处理channel，你可以在外面加一个无限的for循环： for { select { case c \u003c- x: x, y = y, x+y case \u003c-quit: fmt.Println(\"quit\") return } } ","date":"2020-03-06","objectID":"/posts/go-channel/:7:0","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"timeout select有很重要的一个应用就是超时处理。 因为上面我们提到，如果没有case需要处理，select语句就会一直阻塞着。这时候我们可能就需要一个超时操作，用来处理超时的情况。 下面这个例子我们会在2秒后往channel c1中发送一个数据，但是select设置为1秒超时,因此我们会打印出timeout 1,而不是result 1。 import \"time\" import \"fmt\" func main() { c1 := make(chan string, 1) go func() { time.Sleep(time.Second * 2) c1 \u003c- \"result 1\" }() select { case res := \u003c-c1: fmt.Println(res) case \u003c-time.After(time.Second * 1): fmt.Println(\"timeout 1\") } } 其实它利用的是time.After方法，它返回一个类型为\u003c-chan Time的单向的channel，在指定的时间发送一个当前时间给返回的channel中。 ","date":"2020-03-06","objectID":"/posts/go-channel/:7:1","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"Timer 和 Ticker 我们看一下关于时间的两个Channel。 timer是一个定时器，代表未来的一个单一事件，你可以告诉timer你要等待多长时间，它提供一个Channel，在将来的那个时间那个Channel提供了一个时间值。下面的例子中第二行会阻塞2秒钟左右的时间，直到时间到了才会继续执行。 timer1 := time.NewTimer(time.Second * 2) \u003c-timer1.C fmt.Println(\"Timer 1 expired\") 当然如果你只是想单纯的等待的话，可以使用time.Sleep来实现。 你还可以使用timer.Stop来停止计时器。 timer2 := time.NewTimer(time.Second) go func() { \u003c-timer2.C fmt.Println(\"Timer 2 expired\") }() stop2 := timer2.Stop() if stop2 { fmt.Println(\"Timer 2 stopped\") } ticker是一个定时触发的计时器，它会以一个间隔(interval)往Channel发送一个事件(当前时间)，而Channel的接收者可以以固定的时间间隔从Channel中读取事件。下面的例子中ticker每500毫秒触发一次，你可以观察输出的时间。 ticker := time.NewTicker(time.Millisecond * 500) go func() { for t := range ticker.C { fmt.Println(\"Tick at\", t) } }() 类似timer, ticker也可以通过Stop方法来停止。一旦它停止，接收者不再会从channel中接收数据了。 ","date":"2020-03-06","objectID":"/posts/go-channel/:8:0","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"close 内建的close方法可以用来关闭channel。 总结一下channel关闭后sender的receiver操作。 如果channel c已经被关闭,继续往它发送数据会导致panic: send on closed channel: import \"time\" func main() { go func() { time.Sleep(time.Hour) }() c := make(chan int, 10) c \u003c- 1 c \u003c- 2 close(c) c \u003c- 3 } 但是从这个关闭的channel中不但可以读取出已发送的数据，还可以不断的读取零值: c := make(chan int, 10) c \u003c- 1 c \u003c- 2 close(c) fmt.Println(\u003c-c) //1 fmt.Println(\u003c-c) //2 fmt.Println(\u003c-c) //0 fmt.Println(\u003c-c) //0 但是如果通过range读取，channel关闭后for循环会跳出： c := make(chan int, 10) c \u003c- 1 c \u003c- 2 close(c) for i := range c { fmt.Println(i) } 通过i, ok := \u003c-c可以查看Channel的状态，判断值是零值还是正常读取的值。 c := make(chan int, 10) close(c) i, ok := \u003c-c fmt.Printf(\"%d, %t\", i, ok) //0, false ","date":"2020-03-06","objectID":"/posts/go-channel/:9:0","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["源码解读"],"content":"同步 channel可以用在goroutine之间的同步。 下面的例子中main goroutine通过done channel等待worker完成任务。 worker做完任务后只需往channel发送一个数据就可以通知main goroutine任务完成。 import ( \"fmt\" \"time\" ) func worker(done chan bool) { time.Sleep(time.Second) // 通知任务已完成 done \u003c- true } func main() { done := make(chan bool, 1) go worker(done) // 等待任务完成 \u003c-done } [参考资料]： https://gobyexample.com/channels https://tour.golang.org/concurrency/2 https://golang.org/ref/spec#Select_statements https://github.com/a8m/go-lang-cheat-sheet http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/ ","date":"2020-03-06","objectID":"/posts/go-channel/:10:0","tags":["go"],"title":"Go Channel 源码解读","uri":"/posts/go-channel/"},{"categories":["个人"],"content":"由于上一个博客项目的原文件丢失，无法继续更新，只会重新开启新的博客项目，重新做起~ 技术原因原博客已下线，原博客技术文档会逐步同步到新博客上。 ","date":"2020-03-06","objectID":"/posts/my-first-post/:0:0","tags":null,"title":"新的篇章","uri":"/posts/my-first-post/"},{"categories":["基础知识"],"content":"用 GO 实现图片处理和文字合成 Go 的图片处理 最近需要一个合成明信片的工具，即往背景图的固定位置上添加一个图片和一段文字， 最后合成一张图片。由于是 go 程序的一个子功能，所以我想我只加拿 go 写好了，正好有 go 的 image 库，拿来练练。 ","date":"2017-08-22","objectID":"/posts/go-image/:0:0","tags":["go","图片处理"],"title":"Go Image","uri":"/posts/go-image/"},{"categories":["基础知识"],"content":"图片合成 图片合成我用到了这个库 github.com/disintegration/imaging 代码： package main import ( \"fmt\" \"image\" \"github.com/disintegration/imaging\" ) func HandleUserImage(fileName string) (string, error) { m, err := imaging.Open(\"target.jpg\") if err != nil { fmt.Printf(\"open file failed\") } bm, err := imaging.Open(\"bg.jpg\") if err != nil { fmt.Printf(\"open file failed\") } // 图片按比例缩放 dst := imaging.Resize(m, 200, 200, imaging.Lanczos) // 将图片粘贴到背景图的固定位置 result := imaging.Overlay(bm, dst, image.Pt(120, 140), 1) fileName := fmt.Sprintf(\"%d.jpg\", fileName) err = imaging.Save(result, fileName) if err != nil { return \"\", err } return fileName, nil } 以上是将 target.jpg 文件先进行缩放，再贴到 bg.jpg 文件的 （120，140）位置，最后保存成文件。 ","date":"2017-08-22","objectID":"/posts/go-image/:1:0","tags":["go","图片处理"],"title":"Go Image","uri":"/posts/go-image/"},{"categories":["基础知识"],"content":"图片上写文字 以下是写文字和贴图的一块用的实例： package main import ( \"fmt\" \"image\" \"image/color\" \"io/ioutil\" \"github.com/disintegration/imaging\" \"github.com/golang/freetype\" \"github.com/golang/freetype/truetype\" \"golang.org/x/image/font\" ) func main() { HandleUserImage() } // HandleUserImage paste user image onto background func HandleUserImage() (string, error) { m, err := imaging.Open(\"target.png\") if err != nil { fmt.Printf(\"open file failed\") } bm, err := imaging.Open(\"bg.jpg\") if err != nil { fmt.Printf(\"open file failed\") } // 图片按比例缩放 dst := imaging.Resize(m, 200, 200, imaging.Lanczos) // 将图片粘贴到背景图的固定位置 result := imaging.Overlay(bm, dst, image.Pt(120, 140), 1) writeOnImage(result) fileName := fmt.Sprintf(\"%d.jpg\", 1234) err = imaging.Save(result, fileName) if err != nil { return \"\", err } return fileName, nil } var dpi = flag.Float64(\"dpi\", 256, \"screen resolution\") func writeOnImage(target *image.NRGBA) { c := freetype.NewContext() c.SetDPI(*dpi) c.SetClip(target.Bounds()) c.SetDst(target) c.SetHinting(font.HintingFull) // 设置文字颜色、字体、字大小 c.SetSrc(image.NewUniform(color.RGBA{R: 240, G: 240, B: 245, A: 180})) c.SetFontSize(16) fontFam, err := getFontFamily() if err != nil { fmt.Println(\"get font family error\") } c.SetFont(fontFam) pt := freetype.Pt(500, 400) _, err = c.DrawString(\"我是水印\", pt) if err != nil { fmt.Printf(\"draw error: %v \\n\", err) } } func getFontFamily() (*truetype.Font, error) { // 这里需要读取中文字体，否则中文文字会变成方格 fontBytes, err := ioutil.ReadFile(\"Hei.ttc\") if err != nil { fmt.Println(\"read file error:\", err) return \u0026truetype.Font{}, err } f, err := freetype.ParseFont(fontBytes) if err != nil { fmt.Println(\"parse font error:\", err) return \u0026truetype.Font{}, err } return f, err 最后来一张效果图 ","date":"2017-08-22","objectID":"/posts/go-image/:2:0","tags":["go","图片处理"],"title":"Go Image","uri":"/posts/go-image/"},{"categories":["基础知识"],"content":"总结 做的过程中，合作这一块比较好做，但是图片上写文字，相对比较麻烦，而且 freetype 库并没有默认的中英文字体，如果不指定字体会报错，而且字体格式只限制于 ttf 和 ttc 两种。 ","date":"2017-08-22","objectID":"/posts/go-image/:3:0","tags":["go","图片处理"],"title":"Go Image","uri":"/posts/go-image/"},{"categories":["网络编程"],"content":"udp 和 tcp 的简单比较和用 go 实现最简单的 udp 客户端和服务端 …… 用 go 实现简单的 udp 用户数据包协议（英语：User Datagram Protocol，缩写为UDP），又称用户数据报文协议，是一个简单的面向数据报的传输层协议，正式规范为RFC 768。 在TCP/IP模型中，UDP为网络层以上和应用层以下提供了一个简单的接口。UDP只提供数据的不可靠传递，它一旦把应用程序发给网络层的数据发送出去，就不保留数据备份（所以UDP有时候也被认为是不可靠的数据报协议）。UDP在IP数据报的头部仅仅加入了复用和数据校验（字段）。 ","date":"2017-08-02","objectID":"/posts/go-udp/:0:0","tags":["go","udp"],"title":"Go UDP Socket","uri":"/posts/go-udp/"},{"categories":["网络编程"],"content":"UDP 与 TCP 的比较 UDP – 用户数据协议包，是一个简单的面向数据报的运输层协议。UDP 不提供可靠性，它只是把应用程序给 IP 层的数据报发送出去，但是并不能保证他们能达到目的地。由于 UDP 在传输数据报之前不用在客户端和服务端之间建立连接，且没有超时机制，故而传输速度很快。 TCP – 传输控制协议，提供的是面向连接，可靠的字节流服务。当客户端和服务端彼此交换数据前，必须先在双方之间建立 TCP 连接，之后才能传输数据。TCP 提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一段传到另一端。 - TCP UDP 是否连接 面向连接 面向非连接 传输可靠性 可靠 会丢包，不可靠 应用场景 传输数据量大 传输数据量小 速度 慢 快 ","date":"2017-08-02","objectID":"/posts/go-udp/:1:0","tags":["go","udp"],"title":"Go UDP Socket","uri":"/posts/go-udp/"},{"categories":["网络编程"],"content":"TCP 与 UDP 的选择 当数据传输的性能必须让位于数据传输的完整性、可控制性和可靠性时，TCP协议是当然的选择。当强调传输性能而不是传输的完整性时，如：音频和多媒体应用，UDP是最好的选择。在数据传输时间很短，以至于此前的连接过程成为整个流量主体的情况下，UDP也是一个好的选择，如：DNS交换。把SNMP建立在UDP上的部分原因是设计者认为当发生网络阻塞时，UDP较低的开销使其有更好的机会去传送管理数据。TCP丰富的功能有时会导致不可预料的性能低下，但是我们相信在不远的将来，TCP可靠的点对点连接将会用于绝大多数的网络应用。 ","date":"2017-08-02","objectID":"/posts/go-udp/:2:0","tags":["go","udp"],"title":"Go UDP Socket","uri":"/posts/go-udp/"},{"categories":["网络编程"],"content":"UDP 使用场景 在选择使用协议的时候，选择UDP必须要谨慎。在网络质量令人十分不满意的环境下，UDP协议数据包丢失会比较严重。但是由于UDP的特性：它不属于连接型协议，因而具有资源消耗小，处理速度快的优点，所以通常音频、视频和普通数据在传送时使用UDP较多，因为它们即使偶尔丢失一两个数据包，也不会对接收结果产生太大影响。而且如果在内网的情况下，丢包率也很低，所以内网的数据传输也可以用 UDP 协议。我们常用的 QQ，一部分数据传输功能也是用 UDP协议来实现的。 ","date":"2017-08-02","objectID":"/posts/go-udp/:3:0","tags":["go","udp"],"title":"Go UDP Socket","uri":"/posts/go-udp/"},{"categories":["网络编程"],"content":"实现 下面分别是服务端和客户端实现代码： 服务端代码 server.go: package main import ( \"fmt\" \"net\" ) func main() { // 解析地址 addr, err := net.ResolveUDPAddr(\"udp\", \":3017\") if err != nil { fmt.Println(\"Can't resolve addr:\", err.Error()) panic(err) } // 监听端口 conn, err := net.ListenUDP(\"udp\", addr) if err != nil { fmt.Println(\"listen error:\", err.Error()) panic(err) } defer conn.Close() for { handlerClient(conn) } } func handlerClient(conn *net.UDPConn) { data := make([]byte, 1024) // 从 UDP 中读取内容并写到 data _, remoteAddr, err := conn.ReadFromUDP(data) if err != nil { fmt.Println(\"read udp msg failed with:\", err.Error()) return } // 给收到消息的 client 写回信息 conn.WriteToUDP([]byte(\"a\"), remoteAddr) } 客户端代码client.go： package client import ( \"fmt\" \"net\" ) var ( // Connection *net.UDPConn Connection []*net.UDPConn ) // Client 创建一个 UDP 连接 func Client() { addr, err := net.ResolveUDPAddr(\"udp\", \"127.0.0.1:3017\") if err != nil { fmt.Println(\"Can't resolve address: \", err) panic(err) } conn, err := net.DialUDP(\"udp\", nil, addr) if err != nil { fmt.Println(\"Can't dial: \", err) panic(err) } Connection = append(Connection, conn) } // WriteTo 像传入参数 conn 写数据 func WriteTo(conn *net.UDPConn) { _, err := conn.Write([]byte(\"hello from the other site\")) if err != nil { fmt.Println(\"failed:\", err) } data := make([]byte, 1024) _, err = conn.Read(data) if err != nil { fmt.Println(\"failed to read UDP msg because of \", err) } } ","date":"2017-08-02","objectID":"/posts/go-udp/:4:0","tags":["go","udp"],"title":"Go UDP Socket","uri":"/posts/go-udp/"},{"categories":["网络编程"],"content":"总结 以上是一个最简单的 UDP 客户端服务器的代码，只有启动服务和收发消息的功能，但实际应用 UDP 协议到具体需求的时候，需要考虑的问题很多，比如包的设计，包头的设计，错误处理，丢包处理，包顺序调换处理等。所以需要用到传输数据协议的时候，请考虑好需求和可能遇到的问题，以及对问题的处理方案。 ","date":"2017-08-02","objectID":"/posts/go-udp/:5:0","tags":["go","udp"],"title":"Go UDP Socket","uri":"/posts/go-udp/"},{"categories":["网络编程"],"content":"转载文章 Go语言TCP Socket编程 文章原始地址: http://tonybai.com/2015/11/17/tcp-programming-in-golang/ Golang的主要 设计目标之一就是面向大规模后端服务程序，网络通信这块是服务端 程序必不可少也是至关重要的一部分。在日常应用中，我们也可以看到Go中的net以及其subdirectories下的包均是“高频+刚需”，而TCP socket则是网络编程的主流，即便您没有直接使用到net中有关TCP Socket方面的接口，但net/http总是用到了吧，http底层依旧是用tcp socket实现的。 网络编程方面，我们最常用的就是tcp socket编程了，在posix标准出来后，socket在各大主流OS平台上都得到了很好的支持。关于tcp programming，最好的资料莫过于W. Richard Stevens 的网络编程圣经《UNIX网络 编程 卷1：套接字联网API》 了，书中关于tcp socket接口的各种使用、行为模式、异常处理讲解的十分细致。Go是自带runtime的跨平台编程语言，Go中暴露给语言使用者的tcp socket api是建立OS原生tcp socket接口之上的。由于Go runtime调度的需要，golang tcp socket接口在行为特点与异常处理方面与OS原生接口有着一些差别。这篇博文的目标就是整理出关于Go tcp socket在各个场景下的使用方法、行为特点以及注意事项。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:0:0","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"一、模型 从tcp socket诞生后，网络编程架构模型也几经演化，大致是：“每进程一个连接” –\u003e “每线程一个连接” –\u003e “Non-Block + I/O多路复用(linux epoll/windows iocp/freebsd darwin kqueue/solaris Event Port)”。伴随着模型的演化，服务程序愈加强大，可以支持更多的连接，获得更好的处理性能。 目前主流web server一般均采用的都是”Non-Block + I/O多路复用”（有的也结合了多线程、多进程）。不过I/O多路复用也给使用者带来了不小的复杂度，以至于后续出现了许多高性能的I/O多路复用框架， 比如libevent、libev、libuv等，以帮助开发者简化开发复杂性，降低心智负担。不过Go的设计者似乎认为I/O多路复用的这种通过回调机制割裂控制流 的方式依旧复杂，且有悖于“一般逻辑”设计，为此Go语言将该“复杂性”隐藏在Runtime中了：Go开发者无需关注socket是否是 non-block的，也无需亲自注册文件描述符的回调，只需在每个连接对应的goroutine中以**“block I/O”**的方式对待socket处理即可，这可以说大大降低了开发人员的心智负担。一个典型的Go server端程序大致如下： //go-tcpsock/server.go func handleConn(c net.Conn) { defer c.Close() for { // read from the connection // ... ... // write to the connection //... ... } } func main() { l, err := net.Listen(\"tcp\", \":8888\") if err != nil { fmt.Println(\"listen error:\", err) return } for { c, err := l.Accept() if err != nil { fmt.Println(\"accept error:\", err) break } // start a new goroutine to handle // the new connection. go handleConn(c) } } 用户层眼中看到的goroutine中的“block socket”，实际上是通过Go runtime中的netpoller通过Non-block socket + I/O多路复用机制“模拟”出来的，真实的underlying socket实际上是non-block的，只是runtime拦截了底层socket系统调用的错误码，并通过netpoller和goroutine 调度让goroutine“阻塞”在用户层得到的Socket fd上。比如：当用户层针对某个socket fd发起read操作时，如果该socket fd中尚无数据，那么runtime会将该socket fd加入到netpoller中监听，同时对应的goroutine被挂起，直到runtime收到socket fd 数据ready的通知，runtime才会重新唤醒等待在该socket fd上准备read的那个Goroutine。而这个过程从Goroutine的视角来看，就像是read操作一直block在那个socket fd上似的。具体实现细节在后续场景中会有补充描述。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:1:0","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"二、TCP连接的建立 众所周知，TCP Socket的连接的建立需要经历客户端和服务端的三次握手的过程。连接建立过程中，服务端是一个标准的Listen + Accept的结构(可参考上面的代码)，而在客户端Go语言使用net.Dial或DialTimeout进行连接建立： 阻塞Dial： conn, err := net.Dial(\"tcp\", \"google.com:80\") if err != nil { //handle error } // read or write on conn 或是带上超时机制的Dial： conn, err := net.DialTimeout(\"tcp\", \":8080\", 2 * time.Second) if err != nil { //handle error } // read or write on conn 对于客户端而言，连接的建立会遇到如下几种情形： ","date":"2017-07-31","objectID":"/posts/go-tcp/:2:0","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"1、网络不可达或对方服务未启动 如果传给Dial的Addr是可以立即判断出网络不可达，或者Addr中端口对应的服务没有启动，端口未被监听，Dial会几乎立即返回错误，比如： //go-tcpsock/conn_establish/client1.go ... ... func main() { log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Println(\"dial error:\", err) return } defer conn.Close() log.Println(\"dial ok\") } 如果本机8888端口未有服务程序监听，那么执行上面程序，Dial会很快返回错误： $go run client1.go 2015/11/16 14:37:41 begin dial... 2015/11/16 14:37:41 dial error: dial tcp :8888: getsockopt: connection refused ","date":"2017-07-31","objectID":"/posts/go-tcp/:2:1","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"2、对方服务的listen backlog满 还有一种场景就是对方服务器很忙，瞬间有大量client端连接尝试向server建立，server端的listen backlog队列满，server accept不及时((即便不accept，那么在backlog数量范畴里面，connect都会是成功的，因为new conn已经加入到server side的listen queue中了，accept只是从queue中取出一个conn而已)，这将导致client端Dial阻塞。我们还是通过例子感受Dial的行为特点： 服务端代码： //go-tcpsock/conn_establish/server2.go ... ... func main() { l, err := net.Listen(\"tcp\", \":8888\") if err != nil { log.Println(\"error listen:\", err) return } defer l.Close() log.Println(\"listen ok\") var i int for { time.Sleep(time.Second * 10) if _, err := l.Accept(); err != nil { log.Println(\"accept error:\", err) break } i++ log.Printf(\"%d: accept a new connection\\n\", i) } } 客户端代码： //go-tcpsock/conn_establish/client2.go ... ... func establishConn(i int) net.Conn { conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Printf(\"%d: dial error: %s\", i, err) return nil } log.Println(i, \":connect to server ok\") return conn } func main() { var sl []net.Conn for i := 1; i \u003c 1000; i++ { conn := establishConn(i) if conn != nil { sl = append(sl, conn) } } time.Sleep(time.Second * 10000) } 从程序可以看出，服务端在listen成功后，每隔10s钟accept一次。客户端则是串行的尝试建立连接。这两个程序在Darwin下的执行 结果： $go run server2.go 2015/11/16 21:55:41 listen ok 2015/11/16 21:55:51 1: accept a new connection 2015/11/16 21:56:01 2: accept a new connection ... ... $go run client2.go 2015/11/16 21:55:44 1 :connect to server ok 2015/11/16 21:55:44 2 :connect to server ok 2015/11/16 21:55:44 3 :connect to server ok ... ... 2015/11/16 21:55:44 126 :connect to server ok 2015/11/16 21:55:44 127 :connect to server ok 2015/11/16 21:55:44 128 :connect to server ok 2015/11/16 21:55:52 129 :connect to server ok 2015/11/16 21:56:03 130 :connect to server ok 2015/11/16 21:56:14 131 :connect to server ok ... ... 可以看出Client初始时成功地一次性建立了128个连接，然后后续每阻塞近10s才能成功建立一条连接。也就是说在server端 backlog满时(未及时accept)，客户端将阻塞在Dial上，直到server端进行一次accept。至于为什么是128，这与darwin 下的默认设置有关： $sysctl -a|grep kern.ipc.somaxconn kern.ipc.somaxconn: 128 如果我在ubuntu 14.04上运行上述server程序，我们的client端初始可以成功建立499条连接。 如果server一直不accept，client端会一直阻塞么？我们去掉accept后的结果是：在Darwin下，client端会阻塞大 约1分多钟才会返回timeout： 2015/11/16 22:03:31 128 :connect to server ok 2015/11/16 22:04:48 129: dial error: dial tcp :8888: getsockopt: operation timed out 而如果server运行在ubuntu 14.04上，client似乎一直阻塞，我等了10多分钟依旧没有返回。 阻塞与否看来与server端的网络实现和设置有关。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:2:2","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"3、网络延迟较大，Dial阻塞并超时 如果网络延迟较大，TCP握手过程将更加艰难坎坷（各种丢包），时间消耗的自然也会更长。Dial这时会阻塞，如果长时间依旧无法建立连接，则Dial也会返回“ getsockopt: operation timed out”错误。 在连接建立阶段，多数情况下，Dial是可以满足需求的，即便阻塞一小会儿。但对于某些程序而言，需要有严格的连接时间限定，如果一定时间内没能成功建立连接，程序可能会需要执行一段“异常”处理逻辑，为此我们就需要DialTimeout了。下面的例子将Dial的最长阻塞时间限制在2s内，超出这个时长，Dial将返回timeout error： //go-tcpsock/conn_establish/client3.go ... ... func main() { log.Println(\"begin dial...\") conn, err := net.DialTimeout(\"tcp\", \"104.236.176.96:80\", 2*time.Second) if err != nil { log.Println(\"dial error:\", err) return } defer conn.Close() log.Println(\"dial ok\") } 执行结果如下（需要模拟一个延迟较大的网络环境）： $go run client3.go 2015/11/17 09:28:34 begin dial... 2015/11/17 09:28:36 dial error: dial tcp 104.236.176.96:80: i/o timeout ","date":"2017-07-31","objectID":"/posts/go-tcp/:2:3","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"三、Socket读写 连接建立起来后，我们就要在conn上进行读写，以完成业务逻辑。前面说过Go runtime隐藏了I/O多路复用的复杂性。语言使用者只需采用goroutine+Block I/O的模式即可满足大部分场景需求。Dial成功后，方法返回一个net.Conn接口类型变量值，这个接口变量的动态类型为一个*TCPConn： //$GOROOT/src/net/tcpsock_posix.go type TCPConn struct { conn } TCPConn内嵌了一个unexported类型：conn，因此TCPConn”继承”了conn的Read和Write方法，后续通过Dial返回值调用的Write和Read方法均是net.conn的方法： //$GOROOT/src/net/net.go type conn struct { fd *netFD } func (c *conn) ok() bool { return c != nil \u0026\u0026 c.fd != nil } // Implementation of the Conn interface. // Read implements the Conn Read method. func (c *conn) Read(b []byte) (int, error) { if !c.ok() { return 0, syscall.EINVAL } n, err := c.fd.Read(b) if err != nil \u0026\u0026 err != io.EOF { err = \u0026OpError{Op: \"read\", Net: c.fd.net, Source: c.fd.laddr, Addr: c.fd.raddr, Err: err} } return n, err } // Write implements the Conn Write method. func (c *conn) Write(b []byte) (int, error) { if !c.ok() { return 0, syscall.EINVAL } n, err := c.fd.Write(b) if err != nil { err = \u0026OpError{Op: \"write\", Net: c.fd.net, Source: c.fd.laddr, Addr: c.fd.raddr, Err: err} } return n, err } 下面我们先来通过几个场景来总结一下conn.Read的行为特点。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:3:0","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"1、Socket中无数据 连接建立后，如果对方未发送数据到socket，接收方(Server)会阻塞在Read操作上，这和前面提到的“模型”原理是一致的。执行该Read操作的goroutine也会被挂起。runtime会监视该socket，直到其有数据才会重新 调度该socket对应的Goroutine完成read。由于篇幅原因，这里就不列代码了，例子对应的代码文件：go-tcpsock/read_write下的client1.go和server1.go。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:3:1","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"2、Socket中有部分数据 如果socket中有部分数据，且长度小于一次Read操作所期望读出的数据长度，那么Read将会成功读出这部分数据并返回，而不是等待所有期望数据全部读取后再返回。 Client端： //go-tcpsock/read_write/client2.go ... ... func main() { if len(os.Args) \u003c= 1 { fmt.Println(\"usage: go run client2.go YOUR_CONTENT\") return } log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Println(\"dial error:\", err) return } defer conn.Close() log.Println(\"dial ok\") time.Sleep(time.Second * 2) data := os.Args[1] conn.Write([]byte(data)) time.Sleep(time.Second * 10000) } Server端： //go-tcpsock/read_write/server2.go ... ... func handleConn(c net.Conn) { defer c.Close() for { // read from the connection var buf = make([]byte, 10) log.Println(\"start to read from conn\") n, err := c.Read(buf) if err != nil { log.Println(\"conn read error:\", err) return } log.Printf(\"read %d bytes, content is %s\\n\", n, string(buf[:n])) } } ... ... 我们通过client2.go发送”hi”到Server端： 运行结果: $go run client2.go hi 2015/11/17 13:30:53 begin dial... 2015/11/17 13:30:53 dial ok $go run server2.go 2015/11/17 13:33:45 accept a new connection 2015/11/17 13:33:45 start to read from conn 2015/11/17 13:33:47 read 2 bytes, content is hi ... Client向socket中写入两个字节数据(“hi”)，Server端创建一个len = 10的slice，等待Read将读取的数据放入slice；Server随后读取到那两个字节：”hi”。Read成功返回，n =2 ，err = nil。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:3:2","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"3、Socket中有足够数据 如果socket中有数据，且长度大于等于一次Read操作所期望读出的数据长度，那么Read将会成功读出这部分数据并返回。这个情景是最符合我们对Read的期待的了：Read将用Socket中的数据将我们传入的slice填满后返回：n = 10, err = nil。 我们通过client2.go向Server2发送如下内容：abcdefghij12345，执行结果如下： $go run client2.go abcdefghij12345 2015/11/17 13:38:00 begin dial... 2015/11/17 13:38:00 dial ok $go run server2.go 2015/11/17 13:38:00 accept a new connection 2015/11/17 13:38:00 start to read from conn 2015/11/17 13:38:02 read 10 bytes, content is abcdefghij 2015/11/17 13:38:02 start to read from conn 2015/11/17 13:38:02 read 5 bytes, content is 12345 client端发送的内容长度为15个字节，Server端Read buffer的长度为10，因此Server Read第一次返回时只会读取10个字节；Socket中还剩余5个字节数据，Server再次Read时会把剩余数据读出（如：情形2）。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:3:3","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"4、Socket关闭 如果client端主动关闭了socket，那么Server的Read将会读到什么呢？这里分为“有数据关闭”和“无数据关闭”。 “有数据关闭”是指在client关闭时，socket中还有server端未读取的数据，我们在go-tcpsock/read_write/client3.go和server3.go中模拟这种情况： $go run client3.go hello 2015/11/17 13:50:57 begin dial... 2015/11/17 13:50:57 dial ok $go run server3.go 2015/11/17 13:50:57 accept a new connection 2015/11/17 13:51:07 start to read from conn 2015/11/17 13:51:07 read 5 bytes, content is hello 2015/11/17 13:51:17 start to read from conn 2015/11/17 13:51:17 conn read error: EOF 从输出结果来看，当client端close socket退出后，server3依旧没有开始Read，10s后第一次Read成功读出了5个字节的数据，当第二次Read时，由于client端 socket关闭，Read返回EOF error。 通过上面这个例子，我们也可以猜测出“无数据关闭”情形下的结果，那就是Read直接返回EOF error。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:3:4","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"5、读取操作超时 有些场合对Read的阻塞时间有严格限制，在这种情况下，Read的行为到底是什么样的呢？在返回超时错误时，是否也同时Read了一部分数据了呢？这个实验比较难于模拟，下面的测试结果也未必能反映出所有可能结果。我们编写了client4.go和server4.go来模拟这一情形。 //go-tcpsock/read_write/client4.go ... ... func main() { log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Println(\"dial error:\", err) return } defer conn.Close() log.Println(\"dial ok\") data := make([]byte, 65536) conn.Write(data) time.Sleep(time.Second * 10000) } //go-tcpsock/read_write/server4.go ... ... func handleConn(c net.Conn) { defer c.Close() for { // read from the connection time.Sleep(10 * time.Second) var buf = make([]byte, 65536) log.Println(\"start to read from conn\") c.SetReadDeadline(time.Now().Add(time.Microsecond * 10)) n, err := c.Read(buf) if err != nil { log.Printf(\"conn read %d bytes, error: %s\", n, err) if nerr, ok := err.(net.Error); ok \u0026\u0026 nerr.Timeout() { continue } return } log.Printf(\"read %d bytes, content is %s\\n\", n, string(buf[:n])) } } 在Server端我们通过Conn的SetReadDeadline方法设置了10微秒的读超时时间，Server的执行结果如下： $go run server4.go 2015/11/17 14:21:17 accept a new connection 2015/11/17 14:21:27 start to read from conn 2015/11/17 14:21:27 conn read 0 bytes, error: read tcp 127.0.0.1:8888-\u003e127.0.0.1:60970: i/o timeout 2015/11/17 14:21:37 start to read from conn 2015/11/17 14:21:37 read 65536 bytes, content is 虽然每次都是10微秒超时，但结果不同，第一次Read超时，读出数据长度为0；第二次读取所有数据成功，没有超时。反复执行了多次，没能出现“读出部分数据且返回超时错误”的情况。 和读相比，Write遇到的情形一样不少，我们也逐一看一下。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:3:5","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"1、成功写 前面例子着重于Read，client端在Write时并未判断Write的返回值。所谓“成功写”指的就是Write调用返回的n与预期要写入的数据长度相等，且error = nil。这是我们在调用Write时遇到的最常见的情形，这里不再举例了。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:3:6","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"2、写阻塞 TCP连接通信两端的OS都会为该连接保留数据缓冲，一端调用Write后，实际上数据是写入到OS的协议栈的数据缓冲的。TCP是全双工通信，因此每个方向都有独立的数据缓冲。当发送方将对方的接收缓冲区以及自身的发送缓冲区写满后，Write就会阻塞。我们来看一个例子：client5.go和server.go。 //go-tcpsock/read_write/client5.go ... ... func main() { log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Println(\"dial error:\", err) return } defer conn.Close() log.Println(\"dial ok\") data := make([]byte, 65536) var total int for { n, err := conn.Write(data) if err != nil { total += n log.Printf(\"write %d bytes, error:%s\\n\", n, err) break } total += n log.Printf(\"write %d bytes this time, %d bytes in total\\n\", n, total) } log.Printf(\"write %d bytes in total\\n\", total) time.Sleep(time.Second * 10000) } //go-tcpsock/read_write/server5.go ... ... func handleConn(c net.Conn) { defer c.Close() time.Sleep(time.Second * 10) for { // read from the connection time.Sleep(5 * time.Second) var buf = make([]byte, 60000) log.Println(\"start to read from conn\") n, err := c.Read(buf) if err != nil { log.Printf(\"conn read %d bytes, error: %s\", n, err) if nerr, ok := err.(net.Error); ok \u0026\u0026 nerr.Timeout() { continue } } log.Printf(\"read %d bytes, content is %s\\n\", n, string(buf[:n])) } } ... ... Server5在前10s中并不Read数据，因此当client5一直尝试写入时，写到一定量后就会发生阻塞： $go run client5.go 2015/11/17 14:57:33 begin dial... 2015/11/17 14:57:33 dial ok 2015/11/17 14:57:33 write 65536 bytes this time, 65536 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 131072 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 196608 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 262144 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 327680 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 393216 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 458752 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 524288 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 589824 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 655360 bytes in total 在Darwin上，这个size大约在679468bytes。后续当server5每隔5s进行Read时，OS socket缓冲区腾出了空间，client5就又可以写入了： $go run server5.go 2015/11/17 15:07:01 accept a new connection 2015/11/17 15:07:16 start to read from conn 2015/11/17 15:07:16 read 60000 bytes, content is 2015/11/17 15:07:21 start to read from conn 2015/11/17 15:07:21 read 60000 bytes, content is 2015/11/17 15:07:26 start to read from conn 2015/11/17 15:07:26 read 60000 bytes, content is .... client端： 2015/11/17 15:07:01 write 65536 bytes this time, 720896 bytes in total 2015/11/17 15:07:06 write 65536 bytes this time, 786432 bytes in total 2015/11/17 15:07:16 write 65536 bytes this time, 851968 bytes in total 2015/11/17 15:07:16 write 65536 bytes this time, 917504 bytes in total 2015/11/17 15:07:27 write 65536 bytes this time, 983040 bytes in total 2015/11/17 15:07:27 write 65536 bytes this time, 1048576 bytes in total .... ... ","date":"2017-07-31","objectID":"/posts/go-tcp/:3:7","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"3、写入部分数据 Write操作存在写入部分数据的情况，比如上面例子中，当client端输出日志停留在“write 65536 bytes this time, 655360 bytes in total”时，我们杀掉server5，这时我们会看到client5输出以下日志： ... 2015/11/17 15:19:14 write 65536 bytes this time, 655360 bytes in total 2015/11/17 15:19:16 write 24108 bytes, error:write tcp 127.0.0.1:62245-\u003e127.0.0.1:8888: write: broken pipe 2015/11/17 15:19:16 write 679468 bytes in total 显然Write并非在655360这个地方阻塞的，而是后续又写入24108后发生了阻塞，server端socket关闭后，我们看到Wrote返回er != nil且n = 24108，程序需要对这部分写入的24108字节做特定处理。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:3:8","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"4、写入超时 如果非要给Write增加一个期限，那我们可以调用SetWriteDeadline方法。我们copy一份client5.go，形成client6.go，在client6.go的Write之前增加一行timeout设置代码： conn.SetWriteDeadline(time.Now().Add(time.Microsecond * 10)) 启动server6.go，启动client6.go，我们可以看到写入超时的情况下，Write的返回结果： $go run client6.go 2015/11/17 15:26:34 begin dial... 2015/11/17 15:26:34 dial ok 2015/11/17 15:26:34 write 65536 bytes this time, 65536 bytes in total ... ... 2015/11/17 15:26:34 write 65536 bytes this time, 655360 bytes in total 2015/11/17 15:26:34 write 24108 bytes, error:write tcp 127.0.0.1:62325-\u003e127.0.0.1:8888: i/o timeout 2015/11/17 15:26:34 write 679468 bytes in total 可以看到在写入超时时，依旧存在部分数据写入的情况。 综上例子，虽然Go给我们提供了阻塞I/O的便利，但在调用Read和Write时依旧要综合需要方法返回的n和err的结果，以做出正确处理。net.conn实现了io.Reader和io.Writer接口，因此可以试用一些wrapper包进行socket读写，比如bufio包下面的Writer和Reader、io/ioutil下的函数等。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:3:9","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"Goroutine safe 基于goroutine的网络架构模型，存在在不同goroutine间共享conn的情况，那么conn的读写是否是goroutine safe的呢？在深入这个问题之前，我们先从应用意义上来看read操作和write操作的goroutine-safe必要性。 对于read操作而言，由于TCP是面向字节流，conn.Read无法正确区分数据的业务边界，因此多个goroutine对同一个conn进行read的意义不大，goroutine读到不完整的业务包反倒是增加了业务处理的难度。对与Write操作而言，倒是有多个goroutine并发写的情况。不过conn读写是否goroutine-safe的测试不是很好做，我们先深入一下runtime代码，先从理论上给这个问题定个性： net.conn只是*netFD的wrapper结构，最终Write和Read都会落在其中的fd上： type conn struct { fd *netFD } netFD在不同平台上有着不同的实现，我们以net/fd_unix.go中的netFD为例： // Network file descriptor. type netFD struct { // locking/lifetime of sysfd + serialize access to Read and Write methods fdmu fdMutex // immutable until Close sysfd int family int sotype int isConnected bool net string laddr Addr raddr Addr // wait server pd pollDesc } 我们看到netFD中包含了一个runtime实现的fdMutex类型字段，从注释上来看，该fdMutex用来串行化对该netFD对应的sysfd的Write和Read操作。从这个注释上来看，所有对conn的Read和Write操作都是有fdMutex互斥的，从netFD的Read和Write方法的实现也证实了这一点： func (fd *netFD) Read(p []byte) (n int, err error) { if err := fd.readLock(); err != nil { return 0, err } defer fd.readUnlock() if err := fd.pd.PrepareRead(); err != nil { return 0, err } for { n, err = syscall.Read(fd.sysfd, p) if err != nil { n = 0 if err == syscall.EAGAIN { if err = fd.pd.WaitRead(); err == nil { continue } } } err = fd.eofError(n, err) break } if _, ok := err.(syscall.Errno); ok { err = os.NewSyscallError(\"read\", err) } return } func (fd *netFD) Write(p []byte) (nn int, err error) { if err := fd.writeLock(); err != nil { return 0, err } defer fd.writeUnlock() if err := fd.pd.PrepareWrite(); err != nil { return 0, err } for { var n int n, err = syscall.Write(fd.sysfd, p[nn:]) if n \u003e 0 { nn += n } if nn == len(p) { break } if err == syscall.EAGAIN { if err = fd.pd.WaitWrite(); err == nil { continue } } if err != nil { break } if n == 0 { err = io.ErrUnexpectedEOF break } } if _, ok := err.(syscall.Errno); ok { err = os.NewSyscallError(\"write\", err) } return nn, err } 每次Write操作都是受lock保护，直到此次数据全部write完。因此在应用层面，要想保证多个goroutine在一个conn上write操作的Safe，需要一次write完整写入一个“业务包”；一旦将业务包的写入拆分为多次write，那就无法保证某个Goroutine的某“业务包”数据在conn发送的连续性。 同时也可以看出即便是Read操作，也是lock保护的。多个Goroutine对同一conn的并发读不会出现读出内容重叠的情况，但内容断点是依 runtime调度来随机确定的。存在一个业务包数据，1/3内容被goroutine-1读走，另外2/3被另外一个goroutine-2读 走的情况。比如一个完整包：world，当goroutine的read slice size \u003c 5时，存在可能：一个goroutine读到 “worl”,另外一个goroutine读出”d”。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:3:10","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"四、Socket属性 原生Socket API提供了丰富的sockopt设置接口，但Golang有自己的网络架构模型，golang提供的socket options接口也是基于上述模型的必要的属性设置。包括 SetKeepAlive SetKeepAlivePeriod SetLinger SetNoDelay （默认no delay） SetWriteBuffer SetReadBuffer 不过上面的Method是TCPConn的，而不是Conn的，要使用上面的Method的，需要type assertion： tcpConn, ok := c.(*TCPConn) if !ok { //error handle } tcpConn.SetNoDelay(true) 对于listener socket, golang默认采用了 SO_REUSEADDR，这样当你重启 listener程序时，不会因为address in use的错误而启动失败。而listen backlog的默认值是通过获取系统的设置值得到的。不同系统不同：mac 128, linux 512等。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:4:0","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"五、关闭连接 和前面的方法相比，关闭连接算是最简单的操作了。由于socket是全双工的，client和server端在己方已关闭的socket和对方关闭的socket上操作的结果有不同。看下面例子： //go-tcpsock/conn_close/client1.go ... ... func main() { log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Println(\"dial error:\", err) return } conn.Close() log.Println(\"close ok\") var buf = make([]byte, 32) n, err := conn.Read(buf) if err != nil { log.Println(\"read error:\", err) } else { log.Printf(\"read % bytes, content is %s\\n\", n, string(buf[:n])) } n, err = conn.Write(buf) if err != nil { log.Println(\"write error:\", err) } else { log.Printf(\"write % bytes, content is %s\\n\", n, string(buf[:n])) } time.Sleep(time.Second * 1000) } //go-tcpsock/conn_close/server1.go ... ... func handleConn(c net.Conn) { defer c.Close() // read from the connection var buf = make([]byte, 10) log.Println(\"start to read from conn\") n, err := c.Read(buf) if err != nil { log.Println(\"conn read error:\", err) } else { log.Printf(\"read %d bytes, content is %s\\n\", n, string(buf[:n])) } n, err = c.Write(buf) if err != nil { log.Println(\"conn write error:\", err) } else { log.Printf(\"write %d bytes, content is %s\\n\", n, string(buf[:n])) } } ... ... 上述例子的执行结果如下： $go run server1.go 2015/11/17 17:00:51 accept a new connection 2015/11/17 17:00:51 start to read from conn 2015/11/17 17:00:51 conn read error: EOF 2015/11/17 17:00:51 write 10 bytes, content is $go run client1.go 2015/11/17 17:00:51 begin dial... 2015/11/17 17:00:51 close ok 2015/11/17 17:00:51 read error: read tcp 127.0.0.1:64195-\u003e127.0.0.1:8888: use of closed network connection 2015/11/17 17:00:51 write error: write tcp 127.0.0.1:64195-\u003e127.0.0.1:8888: use of closed network connection 从client1的结果来看，在己方已经关闭的socket上再进行read和write操作，会得到”use of closed network connection” error； 从server1的执行结果来看，在对方关闭的socket上执行read操作会得到EOF error，但write操作会成功，因为数据会成功写入己方的内核socket缓冲区中，即便最终发不到对方socket缓冲区了，因为己方socket并未关闭。因此当发现对方socket关闭后，己方应该正确合理处理自己的socket，再继续write已经无任何意义了。 ","date":"2017-07-31","objectID":"/posts/go-tcp/:5:0","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["网络编程"],"content":"六、小结 本文比较基础，但却很重要，毕竟golang是面向大规模服务后端的，对通信环节的细节的深入理解会大有裨益。另外Go的goroutine+阻塞通信的网络通信模型降低了开发者心智负担，简化了通信的复杂性，这点尤为重要。 本文代码实验环境：go 1.5.1 on Darwin amd64以及部分在ubuntu 14.04 amd64。 本文demo代码在这里可以找到。 © 2015, bigwhite. 版权所有. ","date":"2017-07-31","objectID":"/posts/go-tcp/:6:0","tags":["go","tcp"],"title":"Go TCP Socket","uri":"/posts/go-tcp/"},{"categories":["技术环境"],"content":"关于 容器、Docker 的基础知识、基础操作和常用的命令。 Docker 基础知识和使用 ","date":"2017-07-17","objectID":"/posts/docker/:0:0","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"关于Docker ","date":"2017-07-17","objectID":"/posts/docker/:1:0","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"容器技术 对于容器，目前并没有一个严格的定义，但是普遍被认可的说法是，它首先必须是一个相对独立的环境，在这一点上有点类似虚拟机，但是没有虚拟机那么彻底。另外，在一个容器环境中，应该最小化其对外界的影响，比如不能在容器中吧host上的资源耗尽，这就是资源的控制。 容器技术之所以受欢迎，一个重要的原因是它已经集成到了 Linux 内核中，已经被当作 Linux 内核原生提供的特征。当然其他平台也有相应的容器技术，但是我们讨论的以及Docker涉及的都是指 Linux 平台上的容器技术。 一般来说，容器技术主要包括Namespace和Cgroup两个内核特征。 Namespace 命名空间，它主要做的是访问隔离。其原理是对一类资源进行抽象，并将其封装在一起提供给容器使用，对于这类资源，因为每个容器都有自己的抽象，而他们彼此之间是不可见的，所以就做到访问隔离。 Cgroup是 control group 的简称，又称为控制组，它主要是控制资源控制。其原理是将一组进程放在一个控制组里，通过给这个控制组分配指定的可用资源，达到控制这一组进程可用资源的目的。 容器最核心技术是 Namespace+Cgroup，但是光有这两个抽象的技术概念是无法组成一个完整的容器的。 对于 linux 容器的最小组成，是由一下四个部分构成： Cgroup： 资源控制。 Namespace： 访问隔离。 rootfs： 系统文件隔离。 容器引擎： 生命周期控制。 ","date":"2017-07-17","objectID":"/posts/docker/:1:1","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"容器的创建原理 代码一 pid = clone(fun, stack, flags, clone_arg); (flags: CLONE_NEWPID | CLONE_NEWNS | CLONE_NEWUSER | CLONE_NEWNET | CLONE_NEWIPC | CLONE_NEWUTS | ...) 对于以上代码，通过clone系统调用，并传入各个Namespace对应的clone flag，创建了一个新的子进程，该进程拥有自己的Namespace。从上面的代码可以看出，该进程拥有自己的pid,mount,user,net,ipc,uts namespace 。 代码二： echo $pid \u003e /sys/fs/cgroup/cpu/tasks echo $pid \u003e /sys/fs/cgroup/cpuset/tasks echo $pid \u003e /sys/fs/cgroup/blkio/tasks echo $pid \u003e /sys/fs/cgroup/memory/tasks echo $pid \u003e /sys/fs/cgroup/devices/tasks echo $pid \u003e /sys/fs/cgroup/freezer/tasks 对于代码二，将代码一中的pid写入各个Cgroup子系统中，这样该进程就可以受到相应Cgroup子系统的控制。 代码三： fun () { ... pivot_root(\"path_of_rootfs/\", path); ... exec(\"/bin/bash\"); ... } 对于代码三，该fun函数由上面生成的新进程执行，在fun函数中，通过pivot_root系统调用，使进程进入新的rootfs，之后通过exec系统调用，在新的Namespace,Cgroup,rootfs中执行\"/bin/bash\"程序。 通过以上操作，成功在一个“容器”中运行了一个bash程序。对于Cgroup和Namespace的技术细节，我们下一节详细描述 ","date":"2017-07-17","objectID":"/posts/docker/:1:2","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"Cgroup Cgroup 是什么 Cgroup是control group 的简写，属于 Linux 内核提供的一个特性，用于限制和隔离一组进程对系统资源的使用。这些资源主要包括 CPU， 内存， block I/O（数据块 I/O） 和网络宽带。 Cgroup 从 2.6.24版本进入内核主线，目前各大发行版linux都默认打开了 Cgroup 特性 从实现的角度来看，Cgroup 实现了一个通用的进程分组的框架，而不同资源的具体管理则是由各个 Cgroup 子系统实现的。截止内核4.1版本，Cgroup 中实现的子系统的及其作用如下： devices： 设备权限控制 cpuset： 分配指定的CPU和内存节点 cpu： 控制 CPU 占用率 cpuacct： 统计 CPU 使用情况 memory： 限制内存的使用上限 freezer： 冻结（暂停）Cgroup 中的进程 net_cls： 配合tc（traffic controller）限制网络宽带 net_prio： 设置进程的网络流量优先级 huge_tlb： 限制HugeTLB（块表缓冲区）的使用 perf_event： 允许 Perf 工具基于Cgroup分组做性能测试 ","date":"2017-07-17","objectID":"/posts/docker/:1:3","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"Namespace Namespace 是什么 Namespace 是将内核的全局资源做封装，使得每个Namespace都有有一份独立的资源，因此不同的进程各自的 Namespace 内对同一个资源的使用不会互相干扰。 举个例子，执行 sethostname 这个系统调用时，可以改变系统的主机名，这个主机名就是一个内核的全局资源。内核通过实现 UTS Namespace，可以将不同的进程分隔在不同的 UTS Namespace 中，在某个 Namespace 修改主机名时，另一个 Namespace 的主机名还是保持不变。 目前 Linux 内核总共实现了6种 Namespace： IPC： 隔离 System V IPC 和 POSIX 消息队列 Network： 隔离网络资源 Mount： 隔离文件系统挂载点 PID： 隔离进程 ID UTS： 隔离主机名和域名 User： 隔离用户 ID 和 组 ID Namespace 和 Cgroup 的使用是灵活的，同时也有不少需要注意的地方，因此直接操作 Namespace 和 Cgroup 并不是很容易。正是因为这些原因，Docker 通过 Libcontainer 来处理这些底层的事情。这样一来，Docker 只需简单地调用 Libcontainer 的 API ，就能将完整的容器搭建起来。而作为 Docker 的用户，就更不用操心这些事情了。 ","date":"2017-07-17","objectID":"/posts/docker/:1:4","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"容器造就 Docker 关于容器是否是 Docker 的技术核心技术，业界一直存在着争议。 在理解了容器，理解了容器的核心技术 Cgroup 和 Namespace，理解了容器技术如何巧妙且轻量地实现“容器”本身的资源控制和访问隔离之后，可以看到 Docker 和容器是一种完美的融合和辅助相成的关系，它们不是唯一的搭配，但一定是最完美的结合（目前来说）。与其说是容器造就了 Docker ， 不如说是它们造就了彼此，容器技术让 Docker 得到更多的应用和推广，Docker 也使得容器技术被更多人熟知。 ","date":"2017-07-17","objectID":"/posts/docker/:1:5","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"基本操作 ","date":"2017-07-17","objectID":"/posts/docker/:2:0","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"启动容器 新建并启动 所需的命令是 docker run 例如： $ docker run ubuntu:14.04 /bin/echo 'hello, worl' 容器执行后面的命令直接就会终止 . 下面的命令会启动容器并起一个 bash 终端,允许用户进行交互 $ docker run -t -i ubuntu:14.04 /bin/bash 其中 -t 让 Docker 分配一个伪终端 (pseudo-tty) 并绑定到容器的标准输入上, -i 则让容器的标准输入保持打开 . 利用 docker run 来创建容器是, Docker 在后台运行的标准操作包括: 检查本地是否存在指定的镜像,不存在就从共有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统并在只读的镜像层外面挂载一层可读写层 在宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器终止 启动已终止容器 可以利用 docker start 命令,直接将一个已经终止的容器启动运行 . 可以通过 docker ps -a 查看所有的容器和其状态 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES aada74689bf7 cockroachdb/cockroach \"/cockroach/cockro...\" 3 weeks ago Exited (137) 3 weeks ago roach_master 2e9eb6cf3f66 owncloud \"/entrypoint.sh ap...\" 3 weeks ago Up 3 weeks 0.0.0.0:80-\u003e80/tcp owncloud 91290c737c73 postgres \"docker-entrypoint...\" 3 weeks ago Up 3 weeks 5432/tcp owncloud-postgres 8f546ec65e61 mysql \"docker-entrypoint...\" 3 weeks ago Up 3 weeks 0.0.0.0:3306-\u003e3306/tcp mysql 不难发现 name 为 roch_master 的容器已经终止了,想重新启动它,可以执行下面的命令 $ docker start aada74689bf7 参数为容器的 id . ","date":"2017-07-17","objectID":"/posts/docker/:2:1","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"后台( background )运行 在很多时候,我们需要让 docker 在后台运行而并不是把执行结果直接输出出来. 这个时候我们可以添加 -d 参数来实现 如果使用 -d 参数运行容器 $ docker run -d mysql:5.7.17 77b2dc01fe0f3f1265df143181e7b9af5e05279a884f4776ee75350ea9d8017a 只会输出运行的容器 id, 而输出结果可以用 docker logs 查看 . $ docker logs [container ID or NAMES] ","date":"2017-07-17","objectID":"/posts/docker/:2:2","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"终止容器 可以使用 docker stop 来终止正在运行的容器 . 此外,当 Docker 容器中指定的应用终结时, 容器也自动终止 . 例如运行一个容器时,指定了一个终端后,当退出终端的时候,所创建的容器也会立刻终止 . 终止状态的容器, 可以通过 docker start 来重新启动 . 此外,docker restart 命令会将一个运行态的容器终止,然后重新启动它 . ","date":"2017-07-17","objectID":"/posts/docker/:2:3","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"进入容器 在使用 -d 参数时, docker 容器会在后台运行. 有些时候需要进入容器,如运行数据库时,需要进入增删改查库里的内容. 进入容器有很多种办法. attach 命令 docker attach 是 Docker 自带的命令,用法\u0008 但是使用 attach 命令有个缺陷,即多个窗口同时用 attach 命令到同一个容器的时候,所有的窗口都是同步显示的,如果其中一个窗口阻塞的时候,其他窗口也无法使用 . nsenter 命令 这个工具需要用如下命令安装 $ docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter 使用方法也比较简单,首先是你要进入的容器的 ID $ PID=$(docker inspect --format {{.State.Pid}} \u003ccontainer ID or NAMES\u003e) 然后通过这个 PID 进入容器 $ nsenter --target $PID --mount --uts --ipc --net --pid 如果无法通过上述的命令连接到容器,有可能是因为宿主的默认 shell 在容器中并不存在,比如 zsh, 可以使用如下命令显示地使用 bash . exec 命令 $docker exec -it [container ID or NAMES] -i -t 前面说过为了标准输入输出保持打开 . ","date":"2017-07-17","objectID":"/posts/docker/:2:4","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"导出和导入容器 导出容器 如果要导出本地某个容器,可以使用 docker export 命令 . $ docker export [container ID or NAMES] \u003e target.tar 这样将导出容器快照到本地文件 . 导入容器快照 可以使用 docker import 从容器快照文件导入镜像, $ cat target.tar | docker import - test/mysql:v1.0 $ sudo docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE test/ubuntu v1.0 9d37a6082e97 About a minute ago 171.3 MB 此外,还可以通过指定 URL 或者某个目录来导入 $ docker import http://example.com/exampleimage.tgz example/imagerepo *注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库,也可以使用 docker import 来导入一个容器快照到本地镜像库 .这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态）,而镜像存储文件将保存完整记录,体积也要大 .此外,从容器快照文件导入时可以重新指定标签等元数据信息 . ","date":"2017-07-17","objectID":"/posts/docker/:2:5","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"删除容器 单独删除 可以使用 docker rm 来删除一个处于终止状态的容器 . $ docker rm [container ID or NAMES] 如果要删除一个运行中的容器,可以添加 -f 参数 .Docker 会发送 SIGKILL 信号给容器 . 清理所有处于终止状态的容器 用 docker ps -a 命令可以查看所有已创建的包括终止状态的容器,如果想批量删除多个容器的话(当然是终止状态的容器) ,可以用这个命令 $ docker rm $(docker ps -a -q) *注意：这个命令其实会试图删除所有的包括还在运行中的容器,不过就像上面提过的 docker rm 默认并不会删除运行中的容器 . ","date":"2017-07-17","objectID":"/posts/docker/:2:6","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"访问仓库 仓库（Repository）是集中存放镜像的地方 . 一个容易混淆的概念是注册服务器（Registry） .实际上注册服务器是管理仓库的具体服务器,每个服务器上可以有多个仓库,而每个仓库下面有多个镜像 .从这方面来说,仓库可以被认为是一个具体的项目或目录 .例如对于仓库地址dl.dockerpool.com/ubuntu 来说, dl.dockerpool.com 是注册服务器地址, ubuntu 是仓库名 . 大部分时候,并不需要严格区分这两者的概念 . ","date":"2017-07-17","objectID":"/posts/docker/:3:0","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"Docker Hub 目前 Docker 官方维护了一个公共仓库 Docker Hub, 但是开始把阵地移到 Docker Store 这个平台上,其上能找到几乎所有的能想得到的容器, 不可小觑 . 登录 可以通过执行 docker login 命令来输入用户名、密码和邮箱来完成注册和登录 . 注册成功后,本地用户目录的.dockercfg 中将保存用户的认证信息 . 基本操作 用户无需登录即可通过 docker search 命令来查找官方仓库中的镜像, 并利用 docker pull 命令来将它下载到本地 . 以搜索 mongo 为关键字搜索: $ docker search mongo NAME DESCRIPTION STARS OFFICIAL AUTOMATED mongo MongoDB document databases provide high av... 3427 [OK] mongo-express Web-based MongoDB admin interface, written... 168 [OK] mvertes/alpine-mongo light MongoDB container 51 [OK] mongoclient/mongoclient Official docker image for Mongoclient, fea... 29 [OK] torusware/speedus-mongo Always lastmod official MongoDB docker ima... 9 [OK] mongooseim/mongooseim-docker MongooseIM server the latest stable version 9 [OK] ​搜索结果可以看到很多包含关键字的镜像,其中包括镜像名字、描述、星数（表示该镜像的受欢迎程度）、是否官方创建、是否自动创建 . 官方的镜像说明是官方项目组创建和维护的,automated 资源允许用户验证镜像的来源和内容 . ​根据是否为官方提供, 镜像资源可分为两类 . 一类是累类似 mongo这样的基础镜像 . 这些镜像由 Docker 的用户创建、验证、支持、提供 . 这样的镜像往往是使用单个单词作为名字 . 另一种类型,比如mvertes/alpine-mongo 镜像,它是由 Docker 的用户创建并维护的,往往带有用户名称前缀 . 可以通过前缀 user_name/ 来指定使用某个用户提供的镜像 . 另外,在查找的时候通过 -s N 参数可以指定仅显示星数为 N 以上的镜像 （新版本的 Docker 推荐使用 --flter=stars=N 参数） . 下载镜像到本地 $ sudo docker pull centos Pulling repository centos 0b443ba03958: Download complete 539c0211cd76: Download complete 511136ea3c5a: Download complete 7064731afe90: Download complete 用户也可以登录之后通过 docker push 命令来讲镜像推送到 Docker Hub . 自动创建 ​自动创建（automated builds）功能对于需要经常升级镜像内程序来说,十分方便 .有时候,用户创建了镜像安装了某个软件,如果软件发布新版本则需要手动更新镜像 . .而自动创建允许用户通过 Docker Hub 指定跟踪一个目标网站（目前支持 GitHub或 BitBucket）上的项目,一旦项目发生新的提交,则自动执行创建 . 要配置自动创建,包括如下的步骤： 创建并登录 Docker Hub,以及目标网站； 在目标网站中连接帐户到 Docker Hub； 在 Docker Hub 中 配置一个自动创建； 选取一个目标网站中的项目（需要含 Dockerfile）和分支； 指定 Dockerfile 的位置,并提交创建 . 之后,可以 在Docker Hub 的 自动创建页面 中跟踪每次创建的状态 . ","date":"2017-07-17","objectID":"/posts/docker/:3:1","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"私有仓库 有时候使用 Docker Hub 这样的公共仓库由于网络等原因可能不方便,用户可以创建一个本地仓库供私人使用 . 需要用到 docker-registry 工具 . docker-registry 是官方提供的工具,可以用于构建私有的镜像仓库 . 安装运行 docker-registry 容器运行 在安装了 Docker 后,可以通过获取官方 registry 镜像来运行 . $ docker run -d -p 5000:5000 registry 这将使用官方的 registry 镜像来启动本地的私有仓库 .用户可以通过制定参数来配置私有仓库位置,例如配置镜像存储到 Amazon S3 服务 . $ sudo docker run \\ -e SETTINGS_FLAVOR=s3 \\ -e AWS_BUCKET=acme-docker \\ -e STORAGE_PATH=/registry \\ -e AWS_KEY=AKIAHSHB43HS3J92MXZ \\ -e AWS_SECRET=xdDowwlK7TJajV1Y7EoOZrmuPEJlHYcNP2k4j49T \\ -e SEARCH_BACKEND=sqlalchemy \\ -p 5000:5000 \\ registry 此外,还可以指定本地路径（如/home/user/registry-conf ）下的配置文件 . $ sudo docker run -d -p 5000:5000 -v /home/user/registry-conf:/r egistry-conf -e DOCKER_REGISTRY_CONFIG=/registry-conf/config.yml registry 默认情况下,仓库会被创建在容器的 /var/lib/registry 下 .可以通过 -v 参数来将镜像文件存放在本地的指定路径 . 例如下面的例子将上传的镜像放到 /opt/data/registy 目录 . $ sudo docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib /registry registry 本地安装 对于 Ubuntu 或 CentOS 等发行版,可以直接安装 . Ubuntu $ sudo apt-get install -y build-essential python-dev libevent-dev python-pip liblzma-dev $ sudo pip install docker-registry CentOS $ sudo yum install -y python-devel libevent-devel python-pip gcc xz-devel $ sudo python-pip install docker-registry 也可以从 docker-registry 项目下载源码进行安装 . $ sudo apt-get install build-essential python-dev libevent-dev python-pip libssl-dev liblzma-dev libffi-dev $ git clone https://github.com/docker/docker-registry.git $ cd docker-registry $ sudo python setup.py install 然后修改配置文件,主要修改 dev 模板段的 storage_path 到本地的存储仓库的路径 . $ cp config/config_sample.yml config/config.yml 之后启动 web 服务 . $ sudo gunicorn -c contrib/gunicorn.py docker_registry.wsgi:application 或者 $ sudo gunicorn --access-logfile - --error-logfile - -k gevent -b 0.0.0.0:5000 -w 4 --max-requests 100 docker_registry.wsgi:application 此时使用 crul 访问本地的 5000 端口,看到输出 docker-registry 的版本信息说明运行成功 . *注 ： config/config_sample.yml 文件时示例配置文件 在私有仓库上传、下载、搜索镜像 创建好私有仓库之后,就可以使用 docker tag 来标记一个镜像,然后推送它到仓库,别的机器上就可以下载了 .如 私有仓库地址为 1192.168.7.26:5000 先在本机上查看已有的镜像 . $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE node latest f93ba6280cbd 3 weeks ago 667MB cockroachdb/cockroach latest 404f7ee26d38 4 weeks ago 163MB postgres latest ca3a55649cfc 7 weeks ago 269MB tomcat latest 0785a1d16826 7 weeks ago 367MB owncloud latest 2327c8d59618 8 weeks ago 572MB mysql latest e799c7f9ae9c 2 months ago 407MB 使用 docker tag 将 tomcat 这个镜像标记为 192.168.7.26：5000/test [root@vultr ~]# docker tag tomcat 192.168.7.26:5000/test [root@vultr ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE node latest f93ba6280cbd 3 weeks ago 667MB cockroachdb/cockroach latest 404f7ee26d38 4 weeks ago 163MB postgres latest ca3a55649cfc 7 weeks ago 269MB 192.168.7.26:5000/test latest 0785a1d16826 7 weeks ago 367MB tomcat latest 0785a1d16826 7 weeks ago 367MB owncloud latest 2327c8d59618 8 weeks ago 572MB mysql latest e799c7f9ae9c 2 months ago 407MB 用 docker push 上传标记的镜像 . $ docker push 192.168.7.26:5000/test The push refers to a repository [192.168.7.26:5000/test] (len: 1) Sending image list Pushing repository 192.168.7.26:5000/test (1 tags) Image 511136ea3c5a already pushed, skipping Image 9bad880da3d2 already pushed, skipping Image 25f11f5fb0cb already pushed, skipping Image ebc34468f71d already pushed, skipping Image 2318d26665ef already pushed, skipping Image ba5877dc9bec already pushed, skipping Pushing tag for rev [ba5877dc9bec] on {http://192.168.7.26:5000/ v1/repositories/test/tags/latest} 用 curl 查看仓库中的镜像 curl http://192.168.7.26:5000/v1/search {\"num_results\": 7, \"query\": \"\", \"results\": [{\"description\": \"\",\"name\": \"library/miaxis_j2ee\"}, {\"description\": \"\", \"name\": \"library/tomcat\"}, {\"description\": \"\", \"name\": \"library/ubuntu\"}, {\"description\": \"\", \"name\": \"library/ubuntu_office\"}, {\"description\": \"\", \"name\": \"library/desktop_ubu\"}, {\"description\": \"\", \"name\": \"dockerfile/ubuntu\"}, {\"description\": \"\", \"name\": \"library/test\"}]} 这里可以看到 {\"description\": \"\", \"name\": \"library/test\"} ,表面镜像已经上传成功了 . 下载可以用另一台机器去下载这个镜像 . $ docker pull 192.168.7.26","date":"2017-07-17","objectID":"/posts/docker/:3:2","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"仓库配置文件 Docker 的 registry 利用配置文件提供 了一些仓库的模板（flavor）,用户可以直接使用它们来进行开发或身产环境 . 模板 在 config_sample.yml 文件中,可以看到一些现成的模板段： common ：基础配置 local ：存储数据到本地文件系统 s3 ：存储数据到 AWS S3 中 dev ：使用 local 模板的基本配置 test ：单元测试使用 prod ：生产环境配置（基本上跟s3配置类似） gcs ：存储数据到 Google 的云存储 swift ：存储数据到 OpenStack Swift 服务 glance ：存储数据到 OpenStack Glance 服务,本地文件系统为后备 glance-swift ：存储数据到 OpenStack Glance 服务,Swift 为后备 elliptics ：存储数据到 Elliptics key/value 存储 用户可以添加自定义的模板段 . 默认情况下使用的模板是 dev ,要是使用某个模板作为默认值,可以添加 SETTING-FLAVOR 到环境变量中去, export SETTING_FLAVOR=dev 另外,配置文件中支持从环境变量中加载,语法格式为 _env:VARIABLENAME[:DEFAULT] 示例配置 common: loglevel: info search_backend: \"_env:SEARCH_BACKEND:\" sqlalchemy_index_database: \"_env:SQLALCHEMY_INDEX_DATABASE:sqlite:////tmp/docker-re gistry.db\" prod: loglevel: warn storage: s3 s3_access_key: _env:AWS_S3_ACCESS_KEY s3_secret_key: _env:AWS_S3_SECRET_KEY s3_bucket: _env:AWS_S3_BUCKET boto_bucket: _env:AWS_S3_BUCKET storage_path: /srv/docker smtp_host: localhost from_addr: docker@myself.com to_addr: my@myself.com dev: loglevel: debug storage: local storage_path: /home/myself/docker test: storage: local storage_path: /tmp/tmpdockertmp ","date":"2017-07-17","objectID":"/posts/docker/:3:3","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"Docker 数据管理 在容器管理中数据主要有两种方式： 数据卷 （Data volumes） 数据卷容器 （Data volume containers） ","date":"2017-07-17","objectID":"/posts/docker/:4:0","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"数据卷 数据卷是一个可提供一个或多个容器使用的特殊目录,它绕过 UFS, 可以提供很多有用的特征： 数据卷可以再荣期间共享和重用 对数据卷的修改立马生效 对数据及的更新,不会影响镜像 数据卷默认会一直存在,即使容器被删除 注：数据卷的使用,类似于Linux 下对目录或文件进行 mount, 镜像中的被指定为挂载点的目录中的文件会隐藏掉,能显示看的是挂载的数据卷 创建一个数据卷 ​在使用 docker run 命令的时候,使用 -v 参数来创建一个数据卷并挂载到容器里 .在一次 run 中可以挂载多个数据卷 . 下面创建一个名为 web 的容器,并加载一个数据卷到容器的 /webapp 目录 . $ docker run -d -p --name web -v /webapp training/webapp python app.py 注：也可以在 Docker 中使用 volume 来添加一个或多个新的卷到有该镜像创建的任意容器 . 删除数据卷 数据卷是被设计用来持久化数据的,它的生命周期独立于容器,Docker 不会在容器被删除后自动删除数据卷,并且也不存在垃圾回收这样的机制来处理没有任何容器引用的数据卷 .日光需要在删除容器的同时移除数据卷,可以再删除容器的时候使用 docker rm -v 这个命令 . 挂载一个主句目录作为数据卷 使用 -v 参数也可以指定挂载一个本地主机的目录到容器中去 . $ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py ​ 上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp 目录 .这个功能在进行测试的时候十分方便,比如用户可以放置一些程序到本地目录中,来查看容器是否正常工作 .本地目录的路径必须是绝对路径,如果目录不存在 Docker会自动为你创建它 . 注：Dockerfile 中不支持这种用法,因为 Dockerfile 是为了移植和分享用的 . 然而,不同的操作系统的路径格式不一样,所以目前还不支持 Docker 挂载数据卷的默认权限是读写, 用户也可以通过 :ro 指定为只读 $ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py 加了 :ro 之后,就挂载为只读了 . 查看数据卷的具体信息 在主机里使用以下命令可以查看指定容器的信息 $ docker inspect web ... 在输出的内容中找到其中和数据卷相关的部分,可以看到所有的数据卷都是创建在主句的 /var/lib/docker/volumes/ 下面的 \"Volumes\": { \"/webapp\": \"/var/lib/docker/volumes/fac362...80535\" }, \"VolumesRW\": { \"/webapp\": true } ... 注：从 Docker 1.8.0 起,数据卷配置在 “Mounts” Key 下面, 可以看到所有的数据卷都是创建在主机的 /mnt/sda1/var/lib/docker/volumes/... 下面了 . \"Mounts\": [ { \"Name\": \"b53ebd40054dae599faf7c9666acfe205c3e922 fc3e8bc3f2fd178ed788f1c29\", \"Source\": \"/mnt/sda1/var/lib/docker/volumes/b53e bd40054dae599faf7c9666acfe205c3e922fc3e8bc3f2fd178ed788f1c29/_data\", \"Destination\": \"/webapp\", \"Driver\": \"local\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"\" } ] ... 挂载一个本地主机文件作为数据卷 -v 参数也可以从主机挂载单个文件到文件到容器中 $ sudo docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash 这样就可以记录在容器输入过得命令了 . ","date":"2017-07-17","objectID":"/posts/docker/:4:1","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"数据卷容器 如果你有一些持续更新的数据需要在容器之间共享,最好创建数据卷容器 . 数据卷容器,其实就是一个正常的容器,专门用来提供数据卷供其他容器挂载的 . 首先,创建一个名为 dbdata 的数据卷容器： $ sudo docker run -d -v /dbdata --name dbdata training/postgres echo Data-only container for postgres 然后,在其他容器中使用 --volumes-from 来挂载 dbdata 容器中的数据卷 . $ sudo docker run -d --volumes-form dbdata --name db1 training/postgres $ sudo docker run -d --volumes-form dbdata --name db2 training/postgres 可以使用超过一个的--volumes-from 参数来指定从多个容器挂载不同的数据卷 . 也可以从其他已经挂载了数据卷的容器来级联挂载数据卷 . $ docker run -d --name db3 --volumes-from db1 training/postgres 注：使用 --volumes-from 参数所挂载数据卷的容器自己并不需要保持运行状态 如果删除了挂载的容器（包括 dbdata、db1 和 db2 ）,数据卷并不会被自动删除 .如果删除一个数据卷,必须在删除最后一个还挂着它的容器时使用 docker rm -v 命令来指定同时删除关联的容器 .这可以让用户在容器之间升级和移到数据卷 . 利用数据卷容器来备份、恢复、迁移数据卷 可以利用数据卷对其中的数据进行备份、恢复和迁移 . 备份 首先使用 --volumes-from 标记来创建一个加载 dbdata 数据卷的容器,并从主机挂载当前目录到容器的 /backup 目录 .命令如下： $ sudo docker run --volumes-from dbdata -v$(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata 容器启动后,使用了 tar 命令来将 dbdata 卷备份为容器中 /backup/backup.tar 文件,也就是主机当前目录下的名为 backup.tar 的文件 . 恢复 如果要恢复数据到一个容器,首先创建一个带有空数据卷的容器 dbdata2 . $ docker run -v /dbdata --name dbdata2 ubuntu /bin/bash 然后创建另一个容器,挂载 dbdata2 容器卷中的数据卷,并使用 untar 解压备份文件到挂载的容器卷中 . $ sudo docker run --volumes-form dbdata2 -v $(pwd):/backup busybox tar xvf /backup/backup.tar 为了查看/验证恢复的数据,可以再启动一个容器挂载同样的容器卷来查看 $ docker run --volumes-from dbdata2 busybox /bin/ls dbdata 迁移数据卷 代写 . . . Docker 中的网络 Docker 允许通过外部访问容器或容器互联的方式来提供网络服务 . ","date":"2017-07-17","objectID":"/posts/docker/:4:2","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"外部访问容器 容器中可以与运行一些网络应用,要让外部也可以访问这些应用,可以通过 -P 或 -p 参数来指定端口映射 . 当使用 -P 参数时,Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口 . 使用 docker ps 可以看到,本地主机的49155 被映射到了容器的5000 端口 . 此时访问本机的49155 端口即可访问容器内 web 应用提供的界面 . $ sudo docker run -d -P training/webapp python app.py $ sudo docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES bc533791f3f5 training/webapp:latest python app.py 5 seconds ag o Up 2 seconds 0.0.0.0:49155-\u003e5000/tcp nostalgic_morse -P （小写）则可以指定要映射的端口,并且在一个指定端口上只可以绑定一个容器 .支持的格式有 ip:HostPort:containerPort ip::containerPort hostPort:containerPort ","date":"2017-07-17","objectID":"/posts/docker/:5:0","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"映射所有接口地址 使用 hostPort ：containerPort 格式本地的5000端口映射到容器的5000端口,可以执行 $ docker run -d -p 5000:5000 training/webapp python app.py 此时默认会绑定本地所有接口上的所有接口 . ","date":"2017-07-17","objectID":"/posts/docker/:5:1","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"映射到指定地址的指定端口 可以使用 ip:hostPort:containerPort 格式指定映射使用一个特定地址,比如 localhost 地址 127.0.0.1 $ sudo docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py ","date":"2017-07-17","objectID":"/posts/docker/:5:2","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"查看映射端口配置 使用 docker port 来查看当前映射的端口配置,也可以查看到绑定的地址 $ docker port gogs 22/tcp -\u003e 0.0.0.0:10022 3000/tcp -\u003e 0.0.0.0:10080 可以看到 gogs 有两个容器内的端口 22, 3000 分别映射主机的10022,10080 端口 . 注： -p 可以多次使用来绑定多个端口,也就是说一条命令可以有多个 -p ,如：上面👆的 gogs 容器就绑定了俩端口 ","date":"2017-07-17","objectID":"/posts/docker/:5:3","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"容器互联 容器的连接（linking）系统是除了端口映射外,另一种跟容器中应用交互的方式 .该系统会在源和接受容器之间创建一个通道,接受容器可以看到源容器指定的信息 . ","date":"2017-07-17","objectID":"/posts/docker/:6:0","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"自定义容器命名 连接系统依据容器的名称来执行 .因此,首先需要自定义一个好记的容器命名 . 虽然创建容器的时候,系统默认会分配给一个名字 .但是自定义命名容器的话,第一,好记,第二,可以作为有用的参考的 . 使用 --name 参数可以为容器自定义命名 . $ docker run -d -p 8181:4040 --name own-cloud owncloud 使用 docker ps 来查看正运行的容器 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2c2e766e86fd owncloud \"/entrypoint.sh ap...\" 23 hours ago Up 23 hours 80/tcp, 0.0.0.0:8181-\u003e4040/tcp own-cloud 使用 docker inspect 命令来查看容器名字 $ docker inspect -f \"{{.Name}}\" 2c2e766e86fd /own-cloud 注：容器的名称是唯一的 .如果已经命名了一个叫 own-cloud 的容器,当你再次使用这个名词的时候,需要先把之前的的同名容器删除 tips：在执行 docker run 的时候可以添加 —rm 参数,这样容器在终止后立刻删除 .注意,—rm 和 -d 参数不能同时使用 . ","date":"2017-07-17","objectID":"/posts/docker/:6:1","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"容器互联 使用 --link 参数可以让容器之间安全的进行交互 . 下面是,运行 Nginx 容器的时候把 gogs 这个容器连接上 docker run -d --name my_nginx --link gogs:app --link own-cloud:app2 -p 80:80 -v /root/nginx/config:/etc/nginx/conf.d nginx 此时,gogs 容器和 my_nginx 容器建立互联关系 --link 参数的格式为 --link name:alias ,其中 name 是要连接的容器名称, alias 是这个连接的别名 . 可以通过 docker inspect 命令查看 my_nginx 容器信息,就会发现有这么一段信息 \"Links\": [ \"/gogs:/trusting_brown/app\", \"/own-cloud:/trusting_brown/app2\" ], 表面此容器已经连上两个容器, gogs 和 own-cloud,trusting_brown 是系统分配给 Nginx 的名称,连接名称分别是 app 和 app2 . Docker 在两个互联的容器之间创建了一个安全的隧道,而且不用映射到它们的端口到主机上 .在启动被连接的容器的时候不用添加 -p 或 -P 参数,从而避免暴露端口到外部网络上 . 连接之后,在 Nginx 容器里,就会发生两个变化 . 一是环境变量 .在 Nginx 容器中会出现6个新增的环境变量,这些环境变量的名称分贝时由被连接的服务别名、端口等拼接而成的 . 由于起得 gogs 容器有两个端口,所以其中 APP_PORT、APP_NAME、APP_ENV_GOGS_CUSTOM 是公用的,其它8个变量每四个的分别对应22, 3000 端口 # env | grep APP APP_PORT_3000_TCP=tcp://172.17.0.2:3000 APP_PORT_22_TCP_PROTO=tcp APP_ENV_GOGS_CUSTOM=/data/gogs APP_PORT_3000_TCP_ADDR=172.17.0.2 APP_PORT_3000_TCP_PROTO=tcp APP_PORT_22_TCP_PORT=22 APP_PORT_3000_TCP_PORT=3000 APP_PORT=tcp://172.17.0.2:22 APP_NAME=/my_nginx/app APP_PORT_22_TCP=tcp://172.17.0.2:22 APP_PORT_22_TCP_ADDR=172.17.0.2 二是 hosts 文件 .在 Nginx 容器的 hosts 文件看到下面的记录 .这就是说,一切访问 连接别名（app）、容器 ID（ac4c0cf35adf）和容器名（gogs）的请求都会被重新导向到实时实际的 app 的 ip 地址上 . # cat /etc/hosts | grep app 172.17.0.2 app ac4c0cf35adf gogs ","date":"2017-07-17","objectID":"/posts/docker/:6:2","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"高级网络配置 当 Docker 启动时,会自动的主机上创建一个 docker0 虚拟网桥,实际上是 Linux 的一个 bridge,可以理解为一个软件交换机 .它会挂载到它的网口之间进行转发 . $ ip addr | grep docker0 docker0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UP link/ether 02:42:23:c6:3f:1c brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:23ff:fec6:3f1c/64 scope link valid_lft forever preferred_lft forever 同时,Docker 随机分一个本地未占用的私有网段（在 RFC1919 中定义）中的一个地址给 docker0 接口 .比如我的主机上的 docker0 ip 为 172.17.0.1 ,掩码为 255.255.0.0 .此后启动的容器内的网口也会自动分配有个一个同一网段（172.17.0.0/16）的地址 . 当创建一个 Docker 容器的时候,同时会创建一对 vath pair 接口（当数据包发送到一个接口,另一个接口也可以收到相同的数据包） .这对接口一段在容器内,即 eth0 ；另一端在本地并挂载到 docker0 网桥,名称以 veth 开头 .通过这种方式,主机可以跟容器通信,容器之间也可以相互通信 . Docker 就创建了在主机和所有容器之间一个虚拟共享网络 . ​ 图 i.i docker 网络 接下来部分将介绍在一些场景中,Docker 所有的网络定制配置 .以及通过 Linux 命令来调整、补充、甚至替换 Docker 默认的网络配置 . ","date":"2017-07-17","objectID":"/posts/docker/:7:0","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["技术环境"],"content":"快速配置 下面是一个跟 Docker 网络相关的命令列表 . 其中有些命令选项只有在 Docker 服务启动的时候才能配置,而且不能马上生效 . -b BRIDGE or --bridge==BRIDGE –指定容器挂载的网桥 --bip=CIDR — 定制 docker0 的掩码 -H SOCKET... or --host=SOCKET… —Docker 服务端接受命令的通道 --icc=true|false –是否支持容器之间进行通信 --ip-forward=true|false —容器是否能访问外网（详细解析请看下文的容器通信） --iptables=true|false –是否允许 Docker 添加 iptables 规则 --mtu=BYTES —容器网络中的 MTU 下面的两个命令既可以在服务启动时指定,也可以 Docker 容器启动（docker run ）时候指定 . 在 Docker 服务启动的时候指定则会成为默认值,后面执行docker run 时可以覆盖设置的默认值 . --dns=IP_ADDRESS… —使用指定的 DNS 服务器 --dns-search=DOMAIN... 指定 DNS 搜索域 最后这些选项只有在 docker run 执行时使用,因为它是针对容器的特性内容 . -h HOSTNAME or --hostname=HOSTNAME –配置容器主机名 --link=CONRATAINER_NAME:ALIAS —添加到另一个容器的连接 ","date":"2017-07-17","objectID":"/posts/docker/:7:1","tags":["go","docker"],"title":"Docker 基础知识和基本操作","uri":"/posts/docker/"},{"categories":["源码解读"],"content":"go 的 interface 的实现和原理。 Go interface ","date":"2017-06-08","objectID":"/posts/go-interface/:0:0","tags":["go"],"title":"GO interface","uri":"/posts/go-interface/"},{"categories":["源码解读"],"content":"interface 在 Golang 中 interface 是一个很重要的概念和特性。 ","date":"2017-06-08","objectID":"/posts/go-interface/:1:0","tags":["go"],"title":"GO interface","uri":"/posts/go-interface/"},{"categories":["源码解读"],"content":"什么是 interface？ In object-oriented programming, a protocol or interface is a common means for unrelated objects to communicate with each other. These are definitions of methods and values which the objects agree upon in order to co-operate. — wikipedia 这是 wikipedia 关于 protocal 的定义，将 interface 类比如 protocal 是一种非常助于理解的方式。protocol，中文一般叫做协议，比如网络传输中的 TCP 协议。protocol 可以认为是一种双方为了交流而做出的约定，interface 可以类比如此。 在 Golang 中，interface 是一种抽象类型，相对于抽象类型的是具体类型（concrete type）：int，string。如下是 io 包里面的例子。 // Writer is the interface that wraps the basic Write method. // // Write writes len(p) bytes from p to the underlying data stream. // It returns the number of bytes written from p (0 \u003c= n \u003c= len(p)) // and any error encountered that caused the write to stop early. // Write must return a non-nil error if it returns n \u003c len(p). // Write must not modify the slice data, even temporarily. // // Implementations must not retain p. type Writer interface { Write(p []byte) (n int, err error) } // Closer is the interface that wraps the basic Close method. // // The behavior of Close after the first call is undefined. // Specific implementations may document their own behavior. type Closer interface { Close() error } 在 Golang 中，interface 是一组 method 的集合，是 duck-type programming (鸭子类型)的一种体现。不关心属性（数据），只关心行为（方法）。具体使用中你可以自定义自己的 struct，并提供特定的 interface 里面的 method 就可以把它当成 interface 来使用。下面是一种 interface 的典型用法，定义函数的时候参数定义成 interface，调用函数的时候就可以做到非常的灵活。 type MyInterface interface{ Print() } func TestFunc(x MyInterface) {} type MyStruct struct {} func (me MyStruct) Print() {} func main() { var me MyStruct TestFunc(me) } ","date":"2017-06-08","objectID":"/posts/go-interface/:1:1","tags":["go"],"title":"GO interface","uri":"/posts/go-interface/"},{"categories":["源码解读"],"content":"为什么 interface Gopher China 上给出了下面的三个理由： writing generic algorithm （泛型编程） hiding implementation detail （隐藏具体实现） providing interception points （提供监听点/拦截点？） write generic algorithm 严格来说，在 Golang 中并不支持泛型编程。在 C++ 等高级语言中使用泛型编程非常的简单，所以泛型编程一直是 Golang 诟病最多的地方。但是使用 interface 我们可以实现泛型编程，我这里简单说一下，具体可以参考我前面给出来的那篇文章。比如我们现在要写一个泛型算法，形参定义采用 interface 就可以了，以标准库的 sort 为例。 package sort // A type, typically a collection, that satisfies sort.Interface can be // sorted by the routines in this package. The methods require that the // elements of the collection be enumerated by an integer index. type Interface interface { // Len is the number of elements in the collection. Len() int // Less reports whether the element with // index i should sort before the element with index j. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int) } ... // Sort sorts data. // It makes one call to data.Len to determine n, and O(n*log(n)) calls to // data.Less and data.Swap. The sort is not guaranteed to be stable. func Sort(data Interface) { // Switch to heapsort if depth of 2*ceil(lg(n+1)) is reached. n := data.Len() maxDepth := 0 for i := n; i \u003e 0; i \u003e\u003e= 1 { maxDepth++ } maxDepth *= 2 quickSort(data, 0, n, maxDepth) } Sort 函数的形参是一个 interface，包含了三个方法：Len()，Less(i,j int)，Swap(i, j int)。使用的时候不管数组的元素类型是什么类型（int, float, string…），只要我们实现了这三个方法就可以使用 Sort 函数，这样就实现了“泛型编程”。有一点比较麻烦的是，我们需要将数组自定义一下。下面是一个例子。 type Person struct { Name string Age int } func (p Person) String() string { return fmt.Sprintf(\"%s: %d\", p.Name, p.Age) } // ByAge implements sort.Interface for []Person based on // the Age field. type ByAge []Person //自定义 func (a ByAge) Len() int { return len(a) } func (a ByAge) Swap(i, j int) { a[i], a[j] = a[j], a[i] } func (a ByAge) Less(i, j int) bool { return a[i].Age \u003c a[j].Age } func main() { people := []Person{ {\"Bob\", 31}, {\"John\", 42}, {\"Michael\", 17}, {\"Jenny\", 26}, } fmt.Println(people) sort.Sort(ByAge(people)) fmt.Println(people) } 另外 Gopher China 上还提到了一个比较有趣的东西和大家分享一下。在我们设计函数的时候，下面是一个比较好的准则。 Be conservative in what you send, be liberal in what you accept. — Robustness Principle 对应到 Golang 就是： Return concrete types, receive interfaces as parameter. — Robustness Principle applied to Go 话说这么说，但是当我们翻阅 Golang 源码的时候，有些函数的返回值也是 interface。 hiding implement detail 隐藏具体实现，这个很好理解。比如我设计一个函数给你返回一个 interface，那么你只能通过 interface 里面的方法来做一些操作，但是内部的具体实现是完全不知道的。Francesc 举了个 context 的例子。 context 最先由 google 提供，现在已经纳入了标准库，而且在原有 context 的基础上增加了：cancelCtx，timerCtx，valueCtx。语言的表达有时候略显苍白无力，看一下 context 包的代码吧。 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { c := newCancelCtx(parent) propagateCancel(parent, \u0026c) return \u0026c, func() { c.cancel(true, Canceled) } } 表明上 WithCancel 函数返回的还是一个 Context interface，但是这个 interface 的具体实现是 cancelCtx struct。 // newCancelCtx returns an initialized cancelCtx. func newCancelCtx(parent Context) cancelCtx { return cancelCtx{ Context: parent, done: make(chan struct{}), } } // A cancelCtx can be canceled. When canceled, it also cancels any children // that implement canceler. type cancelCtx struct { Context //注意一下这个地方 done chan struct{} // closed by the first cancel call. mu sync.Mutex children map[canceler]struct{} // set to nil by the first cancel call err error // set to non-nil by the first cancel call } func (c *cancelCtx) Done() \u003c-chan struct{} { return c.done } func (c *cancelCtx) Err() error { c.mu.Lock() defer c.mu.Unlock() return c.err } func (c *cancelCtx) String() string { return fmt.Sprintf(\"%v.WithCancel\", c.Context) } 尽管内部实现上下面三个函数返回的具体 struct （都实现了 Context interface）不同，但是对于使用者来说是完全无感知的。 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) //返回 cancelCtx func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) //返回 timerCtx func WithValue(parent Context, key, val interface{}) Context //返回 valueCtx providing interception points 这里的 interception 想表达的意思应该是 wrapper 或者装饰器，他给出了一个例子如下： type header struct { rt http.RoundTripper v map[string]string } func (h header) RoundTrip(r *htt","date":"2017-06-08","objectID":"/posts/go-interface/:1:2","tags":["go"],"title":"GO interface","uri":"/posts/go-interface/"},{"categories":["源码解读"],"content":"非侵入式 什么是侵入式呢？比如 Java 的 interface 实现需要显示的声明。 public class MyWriter implements io.Writer {} 这样就意味着如果要实现多个 interface 需要显示地写很多遍，同时 package 的依赖还需要进行管理。Dependency is evil。比如我要实现 io 包里面的 Reader，Writer，ReadWriter 接口，代码可以像下面这样写。 type MyIO struct {} func (io *MyIO) Read(p []byte) (n int, err error) {...} func (io *MyIO) Write(p []byte) (n int, err error) {...} // io package type Reader interface { Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) } type ReadWriter interface { Reader Writer } 这种写法真的很方便，而且不用去显示的 import io package，interface 底层实现的时候会动态的检测。这样也会引入一些问题： 性能下降。使用 interface 作为函数参数，runtime 的时候会动态的确定行为。而使用 struct 作为参数，编译期间就可以确定了。 不知道 struct 实现哪些 interface。这个问题可以使用 guru 工具来解决。 综上，Golang interface 的这种非侵入实现真的很难说它是好，还是坏。但是可以肯定的一点是，对开发人员来说代码写起来更简单了。 ","date":"2017-06-08","objectID":"/posts/go-interface/:1:3","tags":["go"],"title":"GO interface","uri":"/posts/go-interface/"},{"categories":["源码解读"],"content":"interface type assertion interface 像其他类型转换的时候一般我们称作断言，举个例子。 func do(v interface{}) { n := v.(int) // might panic } 这样写的坏处在于：一旦断言失败，程序将会 panic。一种避免 panic 的写法是使用 type assertion。 func do(v interface{}) { n, ok := v.(int) if !ok { // 断言失败处理 } } 对于 interface 的操作可以使用 reflect 包来处理，关于 reflect 包的原理和使用可以参考我的文章。 ","date":"2017-06-08","objectID":"/posts/go-interface/:1:4","tags":["go"],"title":"GO interface","uri":"/posts/go-interface/"},{"categories":["源码解读"],"content":"总结 interface 是 Golang 的一种重要的特性，但是这是以 runtime 为代价的，也就意味着性能的损失（关于 interface 的底层实现之后有时间再写）。抛开性能不谈，interface 对于如何设计我们的代码确实给了一个很好的思考。 ","date":"2017-06-08","objectID":"/posts/go-interface/:1:5","tags":["go"],"title":"GO interface","uri":"/posts/go-interface/"},{"categories":["源码解读"],"content":"参考 Golang “泛型编程” 谈一谈 Golang 的 interface 和 reflect understanding golang interface(Gopher China) — youtube understanding golang interface(Gopher China) — slide ","date":"2017-06-08","objectID":"/posts/go-interface/:2:0","tags":["go"],"title":"GO interface","uri":"/posts/go-interface/"},{"categories":["代码规范"],"content":"go 代码的一些规范和命名规则…… Golang 代码规范 ","date":"2017-06-04","objectID":"/posts/go-format/:0:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"项目目录结构 PROJECT_NAME ├── README.md 介绍软件及文档入口 ├── bin 编译好的二进制文件,执行./build.sh自动生成，该目录也用于程序打包 ├── build.sh 自动编译的脚本 ├── doc 该项目的文档 ├── pack 打包后的程序放在此处 ├── pack.sh 自动打包的脚本，生成类似xxxx.20170713_14:45:35.tar.gz的文件，放在pack文件下 └── src 该项目的源代码 ├── main 项目主函数 ├── model 项目代码 ├── research 在实现该项目中探究的一些程序 └── vendor 存放go的库 ├── github.com/xxx 第三方库 └── xxx.com/obc 公司内部的公共库 项目的目录结构尽量做到简明、层次明确。 ","date":"2017-06-04","objectID":"/posts/go-format/:1:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"命名规范 ","date":"2017-06-04","objectID":"/posts/go-format/:2:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"文件名命名规范 用小写，尽量见名思义，看见文件名就可以知道这个文件下的大概内容，对于源代码里的文件，文件名要很好的代表了一个模块实现的功能。 ","date":"2017-06-04","objectID":"/posts/go-format/:2:1","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"包名 包名用小写，使用短命名，尽量不要和标准库冲突。 ","date":"2017-06-04","objectID":"/posts/go-format/:2:2","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"接口名 单个函数的接口以 er 作为后缀，如 Reader， Writer 接口的实现则去掉后缀 type Reader interface { Read(p []byte) (int, error) } 两个函数的接口名综合两个函数名 type WriteFlusher interface { Write([]byte) (int, error) Flush() error } 三个以上函数的接口名，类似于结构体名 type Car interface { Start([]byte) Stop() error Recover() } ","date":"2017-06-04","objectID":"/posts/go-format/:2:3","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"变量 全局变量：采用驼峰命名法，仅限在包内的全局变量，包外引用需要写接口，提供调用； 局部变量：驼峰式，第一个单词的首字母小写，如有两个以上单词组成的变量名，第二个单词开始首字母大写。 ","date":"2017-06-04","objectID":"/posts/go-format/:2:4","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"常量 全局：驼峰命名，每个单词的首字母大写 局部：与变量的风格一样 ","date":"2017-06-04","objectID":"/posts/go-format/:2:5","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"函数名 函数名采用驼峰命名法，不要使用下划线。 ","date":"2017-06-04","objectID":"/posts/go-format/:3:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"import 规范 import在多行的情况下，goimports 会自动帮你格式化，在一个文件里面引入了一个package，建议采用如下格式： import ( \"fmt\" ) 如果你的包引入了三种类型的包，标准库包，程序内部包，第三方包，建议采用如下方式进行组织你的包： import { \"net\" \"strings\" \"github.com/astaxie/beego\" \"gopkg.in/mgo.v2\" \"myproject/models\" \"myproject/utils\" } 项目中最好不要使用相对路径导入包： // 这是不好的导入 import “../net” // 这是正确的做法 import “xxxx.com/proj/net” ","date":"2017-06-04","objectID":"/posts/go-format/:4:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"错误处理 error作为函数的值返回,必须尽快对error进行处理 采用独立的错误流进行处理 不要采用这种方式 if err != nil { // error handling } else { // normal code } 而采用以下方式 if err != nil { // error handling return // or continue, etc. } // normal code 如果返回值需要初始化，则采用以下方式 x, err := f() if err != nil { // error handling return } // use x ","date":"2017-06-04","objectID":"/posts/go-format/:5:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"panic 在逻辑处理中禁用panic 在 main 包中只有当实在不可运行的情况采用 panic，例如文件无法打开，数据库无法连接导致程序无法 正常运行，但是对于其他的 package 对外的接口不能有 panic，只能在包内采用。 建议在 main 包中使用 log.Fatal 来记录错误，这样就可以由 log 来结束程序。 ","date":"2017-06-04","objectID":"/posts/go-format/:5:1","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"Recover recover 用于捕获 runtime 的异常，禁止滥用 recover，在开发测试阶段尽量不要用 recover，recover 一般放在你认为会有不可预期的异常的地方。 func server(workChan \u003c-chan *Work) { for work := range workChan { go safelyDo(work) } } func safelyDo(work *Work) { defer func() { if err := recover(); err != nil { log.Println(\"work failed:\", err) } }() // do 函数可能会有不可预期的异常 do(work) } ","date":"2017-06-04","objectID":"/posts/go-format/:6:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"Defer defer 在函数 return 之前执行，对于一些资源的回收用 defer 是好的，但也禁止滥用 defer，defer 是需要消耗性能的,所以频繁调用的函数尽量不要使用 defer。 // Contents returns the file's contents as a string. func Contents(filename string) (string, error) { f, err := os.Open(filename) if err != nil { return \"\", err } defer f.Close() // f.Close will run when we're finished. var result []byte buf := make([]byte, 100) for { n, err := f.Read(buf[0:]) result = append(result, buf[0:n]...) // append is discussed later. if err != nil { if err == io.EOF { break } return \"\", err // f will be closed if we return here. } } return string(result), nil // f will be closed if we return here. } ","date":"2017-06-04","objectID":"/posts/go-format/:7:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"控制结构 ","date":"2017-06-04","objectID":"/posts/go-format/:8:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"if if接受初始化语句，约定如下方式建立局部变量 if err := file.Chmod(0664); err != nil { return err } ","date":"2017-06-04","objectID":"/posts/go-format/:8:1","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"for 采用短声明建立局部变量 sum := 0 for i := 0; i \u003c 10; i++ { sum += i } ","date":"2017-06-04","objectID":"/posts/go-format/:8:2","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"range 如果只需要第一项（key），就丢弃第二个： for key := range m { if key.expired() { delete(m, key) } } 如果只需要第二项，则把第一项置为下划线 sum := 0 for _, value := range array { sum += value } ","date":"2017-06-04","objectID":"/posts/go-format/:8:3","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"return 尽早return：一旦有错误发生，马上返回 f, err := os.Open(name) if err != nil { return err } d, err := f.Stat() if err != nil { f.Close() return err } codeUsing(f, d) ","date":"2017-06-04","objectID":"/posts/go-format/:8:4","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"方法接收器 名称一般采用 struct 的第一个字母且为小写， 而不是 this，me 或 self type Transfer struct{} func(t *Transfer) Get() {} 如果接收者是 map， slice 或者 chan，不要用指针传递 //Map package main import ( \"fmt\" ) type mp map[string]string func (m mp) Set(k, v string) { m[k] = v } func main() { m := make(mp) m.Set(\"k\", \"v\") fmt.Println(m) } //Channel package main import ( \"fmt\" ) type ch chan interface{} func (c ch) Push(i interface{}) { c \u003c- i } func (c ch) Pop() interface{} { return \u003c-c } func main() { c := make(ch, 1) c.Push(\"i\") fmt.Println(c.Pop()) } 如果需要对 slice 进行修改，通过返回值的方式重新复制 //Slice package main import ( \"fmt\" ) type slice []byte func main() { s := make(slice, 0) s = s.addOne(42) fmt.Println(s) } func (s slice) addOne(b byte) []byte { return append(s, b) } 如果接收者是含有 sync.Mutex 或者类似同步字段的结构体，必须使用指针传递避免复制 package main import ( \"sync\" ) type T struct { m sync.Mutex } func (t *T) lock() { t.m.Lock() } /* Wrong !!! func (t T) lock() { t.m.Lock() } */ func main() { t := new(T) t.lock() } 如果接收者是大的结构体或者数组，使用指针传递会更有效率。 package main import ( \"fmt\" ) type T struct { data [1024]byte } func (t *T) Get() byte { return t.data[0] } func main() { t := new(T) fmt.Println(t.Get()) } ","date":"2017-06-04","objectID":"/posts/go-format/:9:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"一键代码规范 使用 JetBrain 系列 IDE 的同学，可以按快捷键或者鼠标右键来一键使用 go 提供的 format 命令; 快捷键： cmd + option + shift + f 对当前文件进行 format cmd + option + shift + p 对当前项目所有 go 文件进行 format 鼠标右键： 在 IDE 内点击鼠标右键，选择 Go Tools,然后可以选择对单个文件或项目进行 format。 用 vscode 的同学，在设置里面加上以下语句即可以保存文件后自动进行 format \"go.formatOnSave\": true ","date":"2017-06-04","objectID":"/posts/go-format/:10:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":["代码规范"],"content":"总结 代码风格和代码规范是体现一个程序员的基本素质的一项指标，也是对自己的代码和他人的一个最基本的尊重。 ","date":"2017-06-04","objectID":"/posts/go-format/:11:0","tags":["go"],"title":"Go Format","uri":"/posts/go-format/"},{"categories":null,"content":"Go 测试用例 开发程序其中很重要的一点是测试，我们如何保证代码的质量，如何保证每个函数是可运行，运行结果是正确的，又如何保证写出来的代码性能是好的，我们知道单元测试的重点在于发现程序设计或实现的逻辑错误，使问题及早暴露，便于问题的定位解决，而性能测试的重点在于发现程序设计上的一些问题，让线上的程序能够在高并发的情况下还能保持稳定。本小节将带着这一连串的问题来讲解Go语言中如何来实现单元测试和性能测试。 Go语言中自带有一个轻量级的测试框架testing和自带的go test命令来实现单元测试和性能测试，testing框架和其他语言中的测试框架类似，你可以基于这个框架写针对相应函数的测试用例，也可以基于该框架写相应的压力测试用例，那么接下来让我们一一来看一下怎么写。 另外建议安装gotests插件自动生成测试代码: go get -u -v github.com/cweill/gotests/... ","date":"2017-06-01","objectID":"/posts/go-test/:0:0","tags":["go"],"title":"GO test","uri":"/posts/go-test/"},{"categories":null,"content":"如何编写测试用例 由于go test命令只能在一个相应的目录下执行所有文件，所以我们接下来新建一个项目目录gotest,这样我们所有的代码和测试代码都在这个目录下。 接下来我们在该目录下面创建两个文件：gotest.go和gotest_test.go gotest.go:这个文件里面我们是创建了一个包，里面有一个函数实现了除法运算: package gotest import ( \"errors\" ) func Division(a, b float64) (float64, error) { if b == 0 { return 0, errors.New(\"除数不能为0\") } return a / b, nil } gotest_test.go:这是我们的单元测试文件，但是记住下面的这些原则： 文件名必须是_test.go结尾的，这样在执行go test的时候才会执行到相应的代码 你必须import testing这个包 所有的测试用例函数必须是Test开头 测试用例会按照源代码中写的顺序依次执行 测试函数TestXxx()的参数是testing.T，我们可以使用该类型来记录错误或者是测试状态 测试格式：func TestXxx (t *testing.T),Xxx部分可以为任意的字母数字的组合，但是首字母不能是小写字母[a-z]，例如Testintdiv是错误的函数名。 函数中通过调用testing.T的Error, Errorf, FailNow, Fatal, FatalIf方法，说明测试不通过，调用Log方法用来记录测试的信息。 下面是我们的测试用例的代码： package gotest import ( \"testing\" ) func Test_Division_1(t *testing.T) { if i, e := Division(6, 2); i != 3 || e != nil { //try a unit test on function t.Error(\"除法函数测试没通过\") // 如果不是如预期的那么就报错 } else { t.Log(\"第一个测试通过了\") //记录一些你期望记录的信息 } } func Test_Division_2(t *testing.T) { t.Error(\"就是不通过\") } 我们在项目目录下面执行go test,就会显示如下信息： --- FAIL: Test_Division_2 (0.00 seconds) gotest_test.go:16: 就是不通过 FAIL exit status 1 FAIL gotest 0.013s 从这个结果显示测试没有通过，因为在第二个测试函数中我们写死了测试不通过的代码t.Error，那么我们的第一个函数执行的情况怎么样呢？默认情况下执行go test是不会显示测试通过的信息的，我们需要带上参数go test -v，这样就会显示如下信息： === RUN Test_Division_1 --- PASS: Test_Division_1 (0.00 seconds) gotest_test.go:11: 第一个测试通过了 === RUN Test_Division_2 --- FAIL: Test_Division_2 (0.00 seconds) gotest_test.go:16: 就是不通过 FAIL exit status 1 FAIL gotest 0.012s 上面的输出详细的展示了这个测试的过程，我们看到测试函数1Test_Division_1测试通过，而测试函数2Test_Division_2测试失败了，最后得出结论测试不通过。接下来我们把测试函数2修改成如下代码： func Test_Division_2(t *testing.T) { if _, e := Division(6, 0); e == nil { //try a unit test on function t.Error(\"Division did not work as expected.\") // 如果不是如预期的那么就报错 } else { t.Log(\"one test passed.\", e) //记录一些你期望记录的信息 } } 然后我们执行go test -v，就显示如下信息，测试通过了： === RUN Test_Division_1 --- PASS: Test_Division_1 (0.00 seconds) gotest_test.go:11: 第一个测试通过了 === RUN Test_Division_2 --- PASS: Test_Division_2 (0.00 seconds) gotest_test.go:20: one test passed. 除数不能为0 PASS ok gotest 0.013s ","date":"2017-06-01","objectID":"/posts/go-test/:1:0","tags":["go"],"title":"GO test","uri":"/posts/go-test/"},{"categories":null,"content":"如何编写压力测试 压力测试用来检测函数(方法）的性能，和编写单元功能测试的方法类似,此处不再赘述，但需要注意以下几点： 压力测试用例必须遵循如下格式，其中XXX可以是任意字母数字的组合，但是首字母不能是小写字母 func BenchmarkXXX(b *testing.B) { ... } go test不会默认执行压力测试的函数，如果要执行压力测试需要带上参数-test.bench，语法:-test.bench=\"test_name_regex\",例如go test -test.bench=\".*\"表示测试全部的压力测试函数 在压力测试用例中,请记得在循环体内使用testing.B.N,以使测试可以正常的运行 文件名也必须以_test.go结尾 下面我们新建一个压力测试文件webbench_test.go，代码如下所示： package gotest import ( \"testing\" ) func Benchmark_Division(b *testing.B) { for i := 0; i \u003c b.N; i++ { //use b.N for looping Division(4, 5) } } func Benchmark_TimeConsumingFunction(b *testing.B) { b.StopTimer() //调用该函数停止压力测试的时间计数 //做一些初始化的工作,例如读取文件数据,数据库连接之类的, //这样这些时间不影响我们测试函数本身的性能 b.StartTimer() //重新开始时间 for i := 0; i \u003c b.N; i++ { Division(4, 5) } } 我们执行命令go test -file webbench_test.go -test.bench=\".*\"，可以看到如下结果： PASS Benchmark_Division 500000000 7.76 ns/op Benchmark_TimeConsumingFunction 500000000 7.80 ns/op ok gotest 9.364s 上面的结果显示我们没有执行任何TestXXX的单元测试函数，显示的结果只执行了压力测试函数，第一条显示了Benchmark_Division执行了500000000次，每次的执行平均时间是7.76纳秒，第二条显示了Benchmark_TimeConsumingFunction执行了500000000，每次的平均执行时间是7.80纳秒。最后一条显示总共的执行时间。 ","date":"2017-06-01","objectID":"/posts/go-test/:2:0","tags":["go"],"title":"GO test","uri":"/posts/go-test/"},{"categories":null,"content":"小结 通过上面对单元测试和压力测试的学习，我们可以看到testing包很轻量，编写单元测试和压力测试用例非常简单，配合内置的go test命令就可以非常方便的进行测试，这样在我们每次修改完代码,执行一下go test就可以简单的完成回归测试了。 ","date":"2017-06-01","objectID":"/posts/go-test/:3:0","tags":["go"],"title":"GO test","uri":"/posts/go-test/"},{"categories":["基础知识"],"content":"GO 文件操作 在任何计算机设备中，文件是都是必须的对象，而在Web编程中,文件的操作一直是Web程序员经常遇到的问题,文件操作在Web应用中是必须的,非常有用的,我们经常遇到生成文件目录,文件(夹)编辑等操作,现在我们来看看 go 对文件是怎么操作的。 ","date":"2017-05-22","objectID":"/posts/go-file/:0:0","tags":["go"],"title":"Go 文件操作","uri":"/posts/go-file/"},{"categories":["基础知识"],"content":"目录操作 文件操作的大多数函数都是在os包里面，下面列举了几个目录操作的： func Mkdir(name string, perm FileMode) error 创建名称为name的目录，权限设置是perm，例如0777 func MkdirAll(path string, perm FileMode) error 根据path创建多级子目录，例如 test/test1/test2。 func Remove(name string) error 删除名称为name的目录，当目录下有文件或者其他目录时会出错 func RemoveAll(path string) error 根据path删除多级子目录，如果path是单个名称，那么该目录下的子目录全部删除。 以下是简单的使用： package main import ( \"fmt\" \"os\" ) func main() { os.Mkdir(\"test\", 0777) os.MkdirAll(\"test/test1/test2\", 0777) err := os.Remove(\"test\") if err != nil { fmt.Printf(\"crash with error %v \\n\", err) } os.RemoveAll(\"test\") } ","date":"2017-05-22","objectID":"/posts/go-file/:1:0","tags":["go"],"title":"Go 文件操作","uri":"/posts/go-file/"},{"categories":["基础知识"],"content":"文件操作 ","date":"2017-05-22","objectID":"/posts/go-file/:2:0","tags":["go"],"title":"Go 文件操作","uri":"/posts/go-file/"},{"categories":["基础知识"],"content":"建立与打开文件 新建文件可以通过如下两个方法 func Create(name string) (file *File, err Error) 根据提供的文件名创建新的文件，返回一个文件对象，默认权限是0666的文件，返回的文件对象是可读写的。 func NewFile(fd uintptr, name string) *File 根据文件描述符创建相应的文件，返回一个文件对象 通过如下两个方法来打开文件： func Open(name string) (file *File, err Error) 该方法打开一个名称为name的文件，但是是只读方式，内部实现其实调用了OpenFile。 func OpenFile(name string, flag int, perm uint32) (file *File, err Error) 打开名称为name的文件，flag是打开的方式，只读、读写等，perm是权限 ","date":"2017-05-22","objectID":"/posts/go-file/:2:1","tags":["go"],"title":"Go 文件操作","uri":"/posts/go-file/"},{"categories":["基础知识"],"content":"写文件 写文件函数： func (file *File) Write(b []byte) (n int, err Error) 写入byte类型的信息到文件 func (file *File) WriteAt(b []byte, off int64) (n int, err Error) 在指定位置开始写入byte类型的信息 func (file *File) WriteString(s string) (ret int, err Error) 写入string信息到文件 写文件的示例代码 package main import ( \"fmt\" \"os\" ) func main() { userFile := \"yusank.txt\" fout, err := os.Create(userFile) if err != nil { fmt.Println(userFile, err) return } defer fout.Close() for i := 0; i \u003c 10; i++ { fout.WriteString(\"Just a test!\\r\\n\") fout.Write([]byte(\"Just a test!\\r\\n\")) } } ","date":"2017-05-22","objectID":"/posts/go-file/:2:2","tags":["go"],"title":"Go 文件操作","uri":"/posts/go-file/"},{"categories":["基础知识"],"content":"读文件 读文件函数： func (file *File) Read(b []byte) (n int, err Error) 读取数据到b中 func (file *File) ReadAt(b []byte, off int64) (n int, err Error) 从 off 开始读取数据到 b 中 读文件的示例代码: package main import ( \"fmt\" \"os\" ) func main() { userFile := \"yusank.txt\" fl, err := os.Open(userFile) if err != nil { fmt.Println(userFile, err) return } defer fl.Close() buf := make([]byte, 1024) for { n, _ := fl.Read(buf) if 0 == n { break } os.Stdout.Write(buf[:n]) } } ","date":"2017-05-22","objectID":"/posts/go-file/:2:3","tags":["go"],"title":"Go 文件操作","uri":"/posts/go-file/"},{"categories":["基础知识"],"content":"删除文件 Go语言里面删除文件和删除文件夹是同一个函数 func Remove(name string) Error 调用该函数就可以删除文件名为name的文件 ","date":"2017-05-22","objectID":"/posts/go-file/:2:4","tags":["go"],"title":"Go 文件操作","uri":"/posts/go-file/"},{"categories":["基础知识"],"content":"计算文件哈希值 在网络上传输文件完成后，往往都会有一步文件的校验。需要确认传过来的文件是否是损坏的。 小文件 代码： package main import ( \"crypto/md5\" \"fmt\" \"io\" \"os\" ) func main() { testFile := \"/path/to/file\" file, err := os.Open(testFile) if err != nil { fmt.Println(err) return } // 以上是为了获的 os.File 对象 md5h := md5.New() io.Copy(md5h, file) fmt.Printf(\"%x\", md5h.Sum([]byte(\"\"))) // 打印出来的是 MD5 算法下的哈希结果 } 大文件 代码： package main import ( \"crypto/md5\" \"fmt\" \"io\" \"math\" \"os\" ) const filechunk = 8192 // 假定 8KB 以上为大文件 func main() { file, err := os.Open(\"utf8.txt\") if err != nil { panic(err.Error()) } defer file.Close() // 计算大小 info, _ := file.Stat() filesize := info.Size() blocks := uint64(math.Ceil(float64(filesize) / float64(filechunk))) hash := md5.New() for i := uint64(0); i \u003c blocks; i++ { blocksize := int(math.Min(filechunk, float64(filesize-int64(i*filechunk)))) buf := make([]byte, blocksize) file.Read(buf) io.WriteString(hash, string(buf)) // append into the hash } fmt.Printf(\"%s checksum is %x\\n\", file.Name(), hash.Sum(nil)) } 代码内容是打开本地文件分块读取进行哈希计算，在网络传输中，可以每次传入一包的文件，先用 io.WriteString() 方法添加到哈希并在最后进行 hash.Sum() 操作 ","date":"2017-05-22","objectID":"/posts/go-file/:2:5","tags":["go"],"title":"Go 文件操作","uri":"/posts/go-file/"},{"categories":["网络编程"],"content":"Unix 网络编程 ​ 卷II - 进程间通信 IPC是进程间通信（interprocess communication）的简称。传统上该术语描述的是运行在某个操作系统之上的不同进程间各种消息传递（message passing）的方式。 进程间的通信一般是一下四种形式： 消息传递（管道、FIFO和消息队列）； 同步（互斥量、条件变量、读写锁、文件和记录锁、信号量）； 共享内存（匿名的和具名的）； 远程过程调用（Solaris 门和 Sun RPC）。 消息队列 消息传递： 管道和FIFO； Posix 消息队列； System V消息队列。 ","date":"2017-04-22","objectID":"/posts/unix-network/:0:0","tags":["unix"],"title":"Unix 网络编程","uri":"/posts/unix-network/"},{"categories":["网络编程"],"content":"管道和FIFO 管道是最初的Unix IPC 形式。由于管道没有名字，所以它只能用于有亲缘关系的进程间的通信。 实现机制： 管道是由内核管理的一个缓冲区，相当于我们放入内存中的一个纸条。管道的一端连接一个进程的输出。这个进程会向管道中放入信息。管道的另一端连接一个进程的输入，这个进程取出被放入管道的信息。一个缓冲区不需要很大，它被设计成为环形的数据结构，以便管道可以被循环利用。当管道中没有信息的话，从管道中读取的进程会等待，直到另一端的进程放入信息。当管道被放满信息的时候，尝试放入信息的进程会等待，直到另一端的进程取出信息。当两个进程都终结的时候，管道也自动消失。 #include \u003cunistd.h\u003e int pipe (int fd[2]) //返回：若成功返回0，若出错返回-1 该函数返回两个文件描述符：fd[0] 和 fd[1]。前者打开来读，后者打开来写。 管道尽管是单个进程创建，但是管道的典型用途是为两个不同的进程（一个父进程，一个子进程）提供进程间的通信手段。 ​ 数据流 »»» 首先是，由一个进程（它将成为父进程）创建一个 pipe 后调用 fork 派生一个自身的副本，接着关闭着个 pipe 的读成端，子进程关闭同一个 pipe 的写入端。这就是进程间提供了一个单向数据流，如下图。 int main(void) { int n; int fd[2]; pid_t pid; char line[MAXLINE]; if(pipe(fd) === 0){ // 先建立管道得到一对文件描述符 exit(0); } if((pid = fork()) == 0) // 父进程把文件描述符复制给子进程 exit(1); else if(pid \u003e 0){ // 父进程写 close(fd[0]); // 关闭读描述符 write(fd[1], \"\\nhello world\\n\", 14); } else{ // 子进程读 close(fd[1]); // 关闭写端 n = read(fd[0], line, MAXLINE); write(STDOUT_FILENO, line, n); } exit(0); } technically，自从可以在进程间传递描述符后，管道也能用于无亲缘关系的进程间，而现实中管道通常用于具有共同祖先的进程间。 FIFO：命名管道(named PIPE) 管道尽管对很多操作来说是很有用的，但是它的根本局限性在于没有名字，从而只能由亲缘关系的进程（父子进程）使用。为了解决这一问题，Linux提供了FIFO方式连接进程。有了FIFO之后这一缺点得以改正。FIFO有时也称之为有名管道（named pipe）。FIFO除了有管道的功能外，它还允许无亲缘关系的进程的通信。pipe 和 FIFO 都是使用通常的 read 和 write 函数访问的。 FIFO (First in, First out)为一种特殊的文件类型，它在文件系统中有对应的路径。当一个进程以读(r)的方式打开该文件，而另一个进程以写(w)的方式打开该文件，那么内核就会在这两个进程之间建立管道，所以FIFO实际上也由内核管理，不与硬盘打交道。之所以叫FIFO，是因为管道本质上是一个先进先出的队列数据结构，最早放入的数据被最先读出来，从而保证信息交流的顺序。FIFO只是借用了文件系统(file system,命名管道是一种特殊类型的文件，因为Linux中所有事物都是文件，它在文件系统中以文件名的形式存在。)来为管道命名。写模式的进程向FIFO文件中写入，而读模式的进程从FIFO文件中读出。当删除FIFO文件时，管道连接也随之消失。FIFO的好处在于我们可以通过文件的路径来识别管道，从而让没有亲缘关系的进程之间建立连接 #include \u003csys/types.h\u003e#include \u003csys/stat.h\u003e int mkfifo (const char *pathname, mode_t mode); // 返回： 成功返回0，出错返回 -1 其中 pathname 是一个普通的 Unix 路径名，它是该 FIFO 的名字。 mkfifo 函数中参数 mode 指定 FIFO 的读写权限。 mkfifo 函数是要么创建一个新的 FIFO ，要么返回一个 EEXIST 错误（如果该 FIFO 已存在），如果不希望创建一个新的 FIFO 那就用 open 函数就可以。 FIFO 不能打开既写又读。 如果一个 FIFO 只读不写，只写不读都会形成阻塞。 下边是一个简单地例子： #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e # define FIFO1 \"/tmp/my_fifo\" int main() { int res = mkfifo(\"/tmp/my_fifo\", 0777); if (res == 0) { printf(\"FIFO created/n\"); } // 打开FIFO //writefd = Open(FIFO1, O_WRONLY | O_NONBLOCK, 0) //readfd = Open(FIFO1, O_RDONLY, 0) exit(EXIT_SUCCESS); } open 第二个参数中的选项O_NONBLOCK，选项O_NONBLOCK表示非阻塞，加上这个选项后，表示open调用是非阻塞的，如果没有这个选项，则表示open调用是阻塞的。 对于以只读方式（O_RDONLY）打开的FIFO文件，如果open调用是阻塞的（即第二个参数为O_RDONLY），除非有一个进程以写方式打开同一个FIFO，否则它不会返回；如果open调用是非阻塞的的（即第二个参数为O_RDONLY|O_NONBLOCK），则即使没有其他进程以写方式打开同一个FIFO文件，open调用将成功并立即返回。 对于以只写方式（O_WRONLY）打开的FIFO文件，如果open调用是阻塞的（即第二个参数为O_WRONLY），open调用将被阻塞，直到有一个进程以只读方式打开同一个FIFO文件为止；如果open调用是非阻塞的（即第二个参数为O_WRONLY|O_NONBLOCK），open总会立即返回，但如果没有其他进程以只读方式打开同一个FIFO文件，open调用将返回-1，并且FIFO也不会被打开。 关于管道或 FIFO 的读写的若干规则： 如果请求读出的数据量多于管道或 FIFO 中当前的可用数据量，那么只会返回这些可用的数据。 如果请求你写入的数据的字节数小于或等于 PIPE_BUF (可原子地写入往一个管道或 FIFO 的最大数据量， Posix 要求至少为512)，那么 write 操作保证是原子的。这意味着，如果两个进程差不多同时往同一个管道或 FIFO 写，那么不管是先写入来自第一个进程的所有数据再写第二个，还是顺序颠倒过来。系统都不会相互混杂来自两个进程的数据。然而如果数据的字节数大于 PIPE_BUF ，那么 write 操作不能保证是原子的。 不止以上这些。。。 小结： FIFO 与管道类似，但是它用 mkfifo 创建，之后需要open 打开。打开管道必须小心，因为许多规则（read 只写管道、write 只读管道、从空的管道或FIFO read 等的情况的返回结果。）制约着 open 的阻塞与否。 ","date":"2017-04-22","objectID":"/posts/unix-network/:1:0","tags":["unix"],"title":"Unix 网络编程","uri":"/posts/unix-network/"},{"categories":["网络编程"],"content":"Posix IPC Posix–可移植性操作系统接口（Protable operating system interface） 有关Unix标准化的大多数活动是由 Posix 和 Open Group 做的。 Posix 不是单一的标准，是一系列的标准。 以下三种类型的IPC合成为“Posix IPC” Posix 消息队列 Posix 信号量 Posix 共享内存区 ","date":"2017-04-22","objectID":"/posts/unix-network/:2:0","tags":["unix"],"title":"Unix 网络编程","uri":"/posts/unix-network/"},{"categories":["网络编程"],"content":"Posix 消息队列 消息队列可认为是个消息链表。有足够写权限的进程可往队列放置信息，有足够读权限的进程可从队列读取信息。每一个信息都是一条记录，它是由发送者赋予一个优先级。在某个进程往一个队列写入消息之前，并不需要另一个进程在该队列上等待消息的到达。这根管道和 FIFO 是相反的。 一个进程可以往某些队列写入一些信息，然后终止，再让另外一个进程在以后的某个时刻读取这些信息。 Posix 消息队列和下面讲的System V 消息队列有许多的相似性。以下是主要的差别： 对 Posix 消息队列的读总是返回最高优先级的最早消息，对 System V 消息队列的读则可以返回任意指定优先级的消息； 当往一个空队列放置一个信息时，Posix 消息队列允许产生一个信号或启动一个线程，System V消息队列则是不提供类似的机制。 队列中的每一个消息都有如下属性： 一个无符号整数优先级（Posix）或 一个长整数类型（system V）； 消息的数据部分长度（可以为0）； 数据本身（如果长度大于0）。 一个消息队列的可能布局。 我们所设想的是一个链表，该链表的有中含有当前队列的两个属性：队列中允许的最大开销数以及每一个消息的最大大小。 **mq_open ,mq_close 和 mq_unlink 函数 **： mq_open 函数创建一个新的消息队列或打开一个已存在的消息队列。 # include \u003cmqueue.h\u003e mqd_t mq_open (const char *name, int oflag, ... /* mode_t mode, struct mq_attr *attr */); //返回： 成功返回消息对列描述符，出错返回-1 其中 name 有自己的一套命名规则，因为 Posix IPC 使用“Posix IPC 名字”进行标识。为方便于移植起见，Posix IPC 名字必须以斜杠符开头并且不能再包含任何斜杠符。 oflag 是O_RDONLY、O_WRONLY 或 O_RDWR 之一， 可能按位或上O_CREATE(若不存在则创建)、O_EXCL(与O_CREATE一起，若已存在返回EEXIST 错误)或 O_NONBLOCK（非阻塞标识符）。 当实际操作创建一个新的消息队列时（指定O_CREATE标志，且请求的队列不存在），mode 和 attr 参数是需要的。mode上面介绍过。attr参数用于给新队列指定某些属性。 mq_open 返回值称为消息队列描述符（message queue descriptor），这个值用作其他消息队列函数的第一参数。 已打开的消息队列是由 mq_close 关闭的。 #include \u003cmqueue.h\u003e int mq_close(mqd_t mqdes) //返回： 成功返回0，出错返回-1 关闭之后调用进程不再使用该描述符，但其消息队列并不从系统中删除。一个进程终止时，它打开着的消息队列都关闭，就像调用mq_close 一样。 要从系统中删除消息队列则用mq_unlink 函数，其第一参数为 mq_open 的第一参数 name。 # include \u003cmqueue.h\u003e int mq_unlink(const char *name) //返回： 成功返回0，出错返回-1 mq_getattr 和 mq_setattr 函数 消息队列有四个属性，这两个函数是获取和修改这些属性。 mq_flags //队列阻塞标志位 mq_maxmsg //队列最大允许消息数 mq_msgsize //队列消息最大字节数 mq_curmsgs //队列当前消息条数 #include \u003cmqueue.h\u003e int mq_getattr(mqd_t mqdes,struct mq_attr *attr); int mq_setattr(mqd_t mqdes,const struct mq_attr *attr, struct mq_attr *oattr); //返回：均成功返回0，出错返回-1 mq_send 和 mq_receive 函数 ​ 这两个函数分别往一个队列放置一个信息和从一个队列取走一个消息。每一个消息都有优先级，它是一个小于MQ_PRIO_MAX 的无符号整数。Posix要求这个上限至少为32. ​ mq_receive 总是返回所指定队列中优先级最高的的最早消息，而且该优先级能随该消息的内容及其长度一同返回。 #include \u003cmqueue.h\u003e int mq_send(mqd_t mqdes, const char *ptr, size_t len, unsigned int prio); //返回： 成功返回0，出错返回-1 ssize_t mq_reccevie(mqd_t mqdes, char *ptr, size_t len, unsigned int *priop); //返回： 成功返回消息中的字节数，出错返回-1 mq_receive 的 len 参数的值不能小于能加到所指定队列中的最大大小（该队列 mq_attr 结构的 mq_msgsize ）。要是 len 小于该值， mq_receive立即返回 EMSGSIZE 错误。 mq_send 的 prio 参数是待发信息的优先级，其值必须小于 MQ_PRIO_MAX 。如果 mq_receive 的 priop 参数是一个非空指针，所返回消息的优先级就通过该指针存放。如果应用不必使用优先级不同的消息，那就给mq_send 指针值为0的优先级，给 mq_receive 指定一个空指针作为其最后一个参数。 往某个队列中增加一个消息 #include \u003cmqueue.h\u003e int main(int argc, char **argv) { mqd_t mqd; //描述符 void *ptr; //指向缓冲区的指针 size_t len; //长度 uint_t prio; //优先度 if (argc != 4) err_quit(\"usage: mqsend \u003cname\u003e \u003c#bytes\u003e \u003cpriority\u003e\"); len = atoi(argv[2]); prio = atoi(argv[3]); mqd = Mq_open(argv[1], O_WRONLY); // 创建一个消息队列 ptr = Calloc(len, sizeof(char));// 所用的缓冲区用colloc分配，该函数会把该缓冲区初始化为0 Mq_send(mqd, ptr, len, prio); exit(0); } 待发消息的大小和优先级必须作为命令行参数指定。 从某队列读出下一个信息 #include \"unpipc.h\" int main(int argc, char **argv) { int c,flags; mqd_t maq; ssize_t n; uint_t prio; void *buff; struct mq_attr attr; flags = O_RDONLY; while ( (c = Getopt(argc, argv, \"n\")) != -1) { switch (c) { case 'n': flags |= O_NONBLOCK; break; } } if (optind != argc - 1) err_quit(\"usage: mqreceive [-n] \u003cname\u003e\"); mqd =Mq_open(argv[optind], flags); Mq_getattr(mqd, \u0026attr); buff = Malloc(attr.mq_msgsize); n = Mq_receive(mqd, buff, attr.mq_msgsize, \u0026prio); printf(\"read %ld bytes, priority = %u\\n\", (long) n, prio); exit(0); } 命令行选项 -n 指定非阻塞属性，这样如果所指定的队列中没有消息， 则返回一个错误。 调用 mq_getattr 打开队列并取得属性。需要确定最大消息大小，因为必须为调用的 mq_receive 分配一个这样大小的缓冲区。最后输出所读出消息的大小及其属性。 solaris %mqcreate /test1 创建并获取属性 solaris %mqgetattr /test1 max solaris % mqsend /test1 100 9999 以无效的优先级发送 mq_send error: Invalid argument solaris % mqsend /test1 100 6 100字节，优先级6 solaris % mqsend /test1 50 18 50字节，优先级18 solaris % mqsend /test1 33 18 33字节，优先级18 solaris % mqreceive /test1 read 50 bytes, priority = 18 返回优先级最高的最早消息 solaris % mqreceive /test1 read 33 bytes, priority = 18 solaris % mqreceive /test1 read 100 bytes, priority = 6 solaris % mqreceive /test1 指定非阻塞属性，队列为空 mq_recevie error: Resource temporarily unavalibale 消息队列限制","date":"2017-04-22","objectID":"/posts/unix-network/:3:0","tags":["unix"],"title":"Unix 网络编程","uri":"/posts/unix-network/"},{"categories":["网络编程"],"content":"System V 消息队列 以下三种类型的IPC称为 System V IPC： System V 消息队列； System V 信号量； System V 共享内存区。 这个称为作为这三个IPC机制的通称是因为它们源自 System V Unix 。这三种IPC最先出现在AT\u0026T System v UNIX上面，并遵循XSI标准，有时候也被称为XSI IPC。 System V 消息队列使用消息队列标识符（message queue identifier） 标识。有足够权限的任何进程可往队列放置信息，有足够权限的任何进程可从队列读取信息。跟 Posix 一样，在某个进程往一个队列写入消息之前，不求另外某个进程正在等待该队列上一个消息的到达。 对于系统的每个消息队列，内核维护一个定义在 \u003csys/msg.h\u003e 头文件中的信息结构. struct msqid_ds { struct ipc_perm msg_perm //operation permission structure struct msg *msg_frist //ptr to frist message on queue struct msg *msg_last //ptr to last message on queue msglen_t msg_cbytes //current #bytes on queue msgqnum_t msg_qnum //number of messages currently on queue msglen_t msg_qbytes //maximum number of bytes allowed on queue pid_t msg_lspid //process ID of last msgsnd() pid_t msg_lrpid //process ID of last msgrcv() time_t msg_stime //time of last msgsnd() time_t msg_rtime //time of last msgrcv() time_t msg_ctime //time of last change } Unix 98 不要求有 msg_frist、msg_last 和 msg_cbytes 成员。然而普通的源自 System V 的实现中可以找到这三个成员。就算提供了这两个指针，那么它们指向的是内核内存空间，对于应用来说基本没有作用的。 我们可以将内核中某个特定的消息队列画为一个消息链表，如图。 msgget 函数 msgget 函数用于创建一个新的消息队列或访问一个已存在的消息队列。 #include \u003csys/msg.h\u003eint msgget (key_t key, int oflag) //返回： 成功返回非负标识符，出错返回-1 返回值是一个整数标识符，其他三个msg函数就用它来指代该队列。 oflag是读写权限的组合。（稍微复杂。。。） 当创建一个新的消息队列的时，msqid_ds 结构的如下成员被初始化。 msg_perm 结构的 uid 和 cuid 成员被设置成当前进程的有效用户ID，gid 和 cgid 成员被设置成当前的进程的有效组ID。 oflag 中的读写权限位存放在msg_perm.mode 中。 msg_qnum、msg_lspid，msg_lrpid、msg_stime 和 msg_rtime 被设置为0. msg_ctime 被设置为当前时间。 msg_qbytes 被设置成系统限制值。 struct ipc_perm { key_t key; /*调用shmget()时给出的关键字*/ uid_t uid; /*共享内存所有者的有效用户ID */ gid_t gid; /* 共享内存所有者所属组的有效组ID*/ uid_t cuid; /* 共享内存创建 者的有效用户ID*/ gid_t cgid; /* 共享内存创建者所属组的有效组ID*/ mode_t mode; /* Permissions + SHM_DEST和SHM_LOCKED标志*/ ulong_t seq; /* 序列号*/ }; ​ msgsnd 函数 使用 msgget 函数打开一个消息队列后，使用 msgsnd 函数往其上放置一个消息。 # include \u003csys/msg.h\u003e int msgsnd(int msqid, const void *ptr,size_t length, int flag); 其中msqid 是由msgget 函数返回的标识符。ptr 是一个结构指针，该结构具有如下的模板： struct msgbuf { long mtype; // message type ,must be \u003e 0 char mtext[1] // message data }; 消息类型必须大于0，因为对于 msgrcv 函数来说，非正的消息类型用作特殊的指示器。 mtext虽然起名是 text ，但是消息类型并不局限于文本。任何形式的数据都是允许的。内核根本不解释消 息数据的内容。ptr 所指向的是一个含有消息类型的长整数，消息本身则紧跟着它之后。 msgsnd 的 length 参数以字节为单位指定待发送消息的长度。是用户自定义的，可以是0. flag 参数既可以是0，也可以是IPC_NOWAIT 。IPC_NOWAIT 标志使得 msgsnd 调用非阻塞：如果没有存放新消息的可用空间，该函数马上返回。这个条件可能发生的情况包括： 在指定的队列中已有太多的字节（对应 该队列的msqid_ds 结构中的msg_qbytes 值）； 在系统范围存在太多的消息。 如果两个条件一个存在，而且IPC_NOWAIT标志已指定，msgsnd 就返回一个EAGAIN 错误。如果两个条件一个存在，标志未指定，那么调用线程就被投入睡眠，直到： 具备存放新消息的空间； 由 msqgid 标识的消息队列从系统中删除（这个情况下回返回一个EIDRM 错误）； 调用线程被某个捕获的信息所中断。 ","date":"2017-04-22","objectID":"/posts/unix-network/:4:0","tags":["unix"],"title":"Unix 网络编程","uri":"/posts/unix-network/"},{"categories":["技术"],"content":"跨域资源共享 CORS 详解 CORS是一个W3C标准，全称是\"跨域资源共享\"（Cross-origin resource sharing）。 它允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。 本文详细介绍CORS的内部机制。 ","date":"2017-01-30","objectID":"/posts/cors/:0:0","tags":["go","cors"],"title":"跨域资源共享 CORS 详解","uri":"/posts/cors/"},{"categories":["技术"],"content":"一、简介 CORS需要浏览器和服务器同时支持。目前，所有浏览器都支持该功能，IE浏览器不能低于IE10。 整个CORS通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS通信与同源的AJAX通信没有差别，代码完全一样。浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。 因此，实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信。 ","date":"2017-01-30","objectID":"/posts/cors/:1:0","tags":["go","cors"],"title":"跨域资源共享 CORS 详解","uri":"/posts/cors/"},{"categories":["技术"],"content":"二、两种请求 浏览器将CORS请求分成两类：简单请求（simple request）和非简单请求（not-so-simple request）。 只要同时满足以下两大条件，就属于简单请求。 请求方法是以下三种方法之一： HEAD GET POST （2）HTTP的头信息不超出以下几种字段： Accept Accept-Language Content-Language Last-Event-ID Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain 凡是不同时满足上面两个条件，就属于非简单请求。 浏览器对这两种请求的处理，是不一样的。 ","date":"2017-01-30","objectID":"/posts/cors/:2:0","tags":["go","cors"],"title":"跨域资源共享 CORS 详解","uri":"/posts/cors/"},{"categories":["技术"],"content":"三、简单请求 ","date":"2017-01-30","objectID":"/posts/cors/:3:0","tags":["go","cors"],"title":"跨域资源共享 CORS 详解","uri":"/posts/cors/"},{"categories":["技术"],"content":"3.1 基本流程 对于简单请求，浏览器直接发出CORS请求。具体来说，就是在头信息之中，增加一个Origin字段。 下面是一个例子，浏览器发现这次跨源AJAX请求是简单请求，就自动在头信息之中，添加一个Origin字段。 GET /cors HTTP/1.1 Origin: http://api.bob.com Host: api.alice.com Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... 上面的头信息中，Origin字段用来说明，本次请求来自哪个源（协议 + 域名 + 端口）。服务器根据这个值，决定是否同意这次请求。 如果Origin指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应。浏览器发现，这个回应的头信息没有包含Access-Control-Allow-Origin字段（详见下文），就知道出错了，从而抛出一个错误，被XMLHttpRequest的onerror回调函数捕获。注意，这种错误无法通过状态码识别，因为HTTP回应的状态码有可能是200。 如果Origin指定的域名在许可范围内，服务器返回的响应，会多出几个头信息字段。 Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Credentials: true Access-Control-Expose-Headers: FooBar Content-Type: text/html; charset=utf-8 上面的头信息之中，有三个与CORS请求相关的字段，都以Access-Control-开头。 （1）Access-Control-Allow-Origin 该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。 （2）Access-Control-Allow-Credentials 该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。 （3）Access-Control-Expose-Headers 该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。上面的例子指定，getResponseHeader('FooBar')可以返回FooBar字段的值。 ","date":"2017-01-30","objectID":"/posts/cors/:3:1","tags":["go","cors"],"title":"跨域资源共享 CORS 详解","uri":"/posts/cors/"},{"categories":["技术"],"content":"3.2 withCredentials 属性 上面说到，CORS请求默认不发送Cookie和HTTP认证信息。如果要把Cookie发到服务器，一方面要服务器同意，指定Access-Control-Allow-Credentials字段。 Access-Control-Allow-Credentials: true 另一方面，开发者必须在AJAX请求中打开withCredentials属性。 var xhr = new XMLHttpRequest(); xhr.withCredentials = true; 否则，即使服务器同意发送Cookie，浏览器也不会发送。或者，服务器要求设置Cookie，浏览器也不会处理。 但是，如果省略withCredentials设置，有的浏览器还是会一起发送Cookie。这时，可以显式关闭withCredentials。 xhr.withCredentials = false; 需要注意的是，如果要发送Cookie，Access-Control-Allow-Origin就不能设为星号，必须指定明确的、与请求网页一致的域名。同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传，其他域名的Cookie并不会上传，且（跨源）原网页代码中的document.cookie也无法读取服务器域名下的Cookie。 ","date":"2017-01-30","objectID":"/posts/cors/:3:2","tags":["go","cors"],"title":"跨域资源共享 CORS 详解","uri":"/posts/cors/"},{"categories":["技术"],"content":"四、非简单请求 ","date":"2017-01-30","objectID":"/posts/cors/:4:0","tags":["go","cors"],"title":"跨域资源共享 CORS 详解","uri":"/posts/cors/"},{"categories":["技术"],"content":"4.1 预检请求 非简单请求是那种对服务器有特殊要求的请求，比如请求方法是PUT或DELETE，或者Content-Type字段的类型是application/json。 非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为\"预检\"请求（preflight）。 浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。 下面是一段浏览器的JavaScript脚本。 var url = 'http://api.alice.com/cors'; var xhr = new XMLHttpRequest(); xhr.open('PUT', url, true); xhr.setRequestHeader('X-Custom-Header', 'value'); xhr.send(); 上面代码中，HTTP请求的方法是PUT，并且发送一个自定义头信息X-Custom-Header。 浏览器发现，这是一个非简单请求，就自动发出一个\"预检\"请求，要求服务器确认可以这样请求。下面是这个\"预检\"请求的HTTP头信息。 OPTIONS /cors HTTP/1.1 Origin: http://api.bob.com Access-Control-Request-Method: PUT Access-Control-Request-Headers: X-Custom-Header Host: api.alice.com Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... “预检\"请求用的请求方法是OPTIONS，表示这个请求是用来询问的。头信息里面，关键字段是Origin，表示请求来自哪个源。 除了Origin字段，“预检\"请求的头信息包括两个特殊字段。 （1）Access-Control-Request-Method 该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法，上例是PUT。 （2）Access-Control-Request-Headers 该字段是一个逗号分隔的字符串，指定浏览器CORS请求会额外发送的头信息字段，上例是X-Custom-Header。 ","date":"2017-01-30","objectID":"/posts/cors/:4:1","tags":["go","cors"],"title":"跨域资源共享 CORS 详解","uri":"/posts/cors/"},{"categories":["技术"],"content":"4.2 预检请求的回应 服务器收到\"预检\"请求以后，检查了Origin、Access-Control-Request-Method和Access-Control-Request-Headers字段以后，确认允许跨源请求，就可以做出回应。 HTTP/1.1 200 OK Date: Mon, 01 Dec 2008 01:15:39 GMT Server: Apache/2.0.61 (Unix) Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Methods: GET, POST, PUT Access-Control-Allow-Headers: X-Custom-Header Content-Type: text/html; charset=utf-8 Content-Encoding: gzip Content-Length: 0 Keep-Alive: timeout=2, max=100 Connection: Keep-Alive Content-Type: text/plain 上面的HTTP回应中，关键的是Access-Control-Allow-Origin字段，表示http://api.bob.com可以请求数据。该字段也可以设为星号，表示同意任意跨源请求。 Access-Control-Allow-Origin: * 如果浏览器否定了\"预检\"请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段。这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被XMLHttpRequest对象的onerror回调函数捕获。控制台会打印出如下的报错信息。 XMLHttpRequest cannot load http://api.alice.com. Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin. 服务器回应的其他CORS相关字段如下。 Access-Control-Allow-Methods: GET, POST, PUT Access-Control-Allow-Headers: X-Custom-Header Access-Control-Allow-Credentials: true Access-Control-Max-Age: 1728000 （1）Access-Control-Allow-Methods 该字段必需，它的值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。注意，返回的是所有支持的方法，而不单是浏览器请求的那个方法。这是为了避免多次\"预检\"请求。 （2）Access-Control-Allow-Headers 如果浏览器请求包括Access-Control-Request-Headers字段，则Access-Control-Allow-Headers字段是必需的。它也是一个逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在\"预检\"中请求的字段。 （3）Access-Control-Allow-Credentials 该字段与简单请求时的含义相同。 （4）Access-Control-Max-Age 该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是20天（1728000秒），即允许缓存该条回应1728000秒（即20天），在此期间，不用发出另一条预检请求。 ","date":"2017-01-30","objectID":"/posts/cors/:4:2","tags":["go","cors"],"title":"跨域资源共享 CORS 详解","uri":"/posts/cors/"},{"categories":["技术"],"content":"4.3 浏览器的正常请求和回应 一旦服务器通过了\"预检\"请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。 下面是\"预检\"请求之后，浏览器的正常CORS请求。 PUT /cors HTTP/1.1 Origin: http://api.bob.com Host: api.alice.com X-Custom-Header: value Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... 上面头信息的Origin字段是浏览器自动添加的。 下面是服务器正常的回应。 Access-Control-Allow-Origin: http://api.bob.com Content-Type: text/html; charset=utf-8 上面头信息中，Access-Control-Allow-Origin字段是每次回应都必定包含的。 ","date":"2017-01-30","objectID":"/posts/cors/:4:3","tags":["go","cors"],"title":"跨域资源共享 CORS 详解","uri":"/posts/cors/"},{"categories":["技术"],"content":"五、与JSONP的比较 CORS与JSONP的使用目的相同，但是比JSONP更强大。 JSONP只支持GET请求，CORS支持所有类型的HTTP请求。JSONP的优势在于支持老式浏览器，以及可以向不支持CORS的网站请求数据。 （完） ","date":"2017-01-30","objectID":"/posts/cors/:5:0","tags":["go","cors"],"title":"跨域资源共享 CORS 详解","uri":"/posts/cors/"},{"categories":["基础知识"],"content":"welcome to learn terminal command!!! linux命令 ","date":"2016-12-28","objectID":"/posts/linux-cmd/:0:0","tags":["linux"],"title":"linux命令","uri":"/posts/linux-cmd/"},{"categories":["基础知识"],"content":"永！远！不！要！执！行！你！不！清！楚！在！干！啥！的！命！令！ ","date":"2016-12-28","objectID":"/posts/linux-cmd/:0:1","tags":["linux"],"title":"linux命令","uri":"/posts/linux-cmd/"},{"categories":["基础知识"],"content":"实用性 $ ls -l | sed '1d' | sort -n -k5 | awk '{printf \"%15s %10s\\n\", $9,$5}' 按文件大小增序打印出当前目录下的文件名及其文件大小(单位字节） $ history | awk '{print $2}' | sort | uniq -c | sort -rn | head -10 输出你最常用的十条命令 $ http POST http://localhost:4000/ \u003c /\u003cjson文件路径\u003e 做测试的时候很有用的一个命令，需要下载http $ brew install http $ lsof -n -P -i TCP -s TCP:LISTEN COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME QQ 290 smartestee 33u IPv4 0x2f3beaa58a62d73b 0t0 TCP 127.0.0.1:4300 (LISTEN) QQ 290 smartestee 34u IPv4 0x2f3beaa58c69673b 0t0 TCP 127.0.0.1:4301 (LISTEN) idea 3257 smartestee 164u IPv4 0x2f3beaa588d11e43 0t0 TCP 127.0.0.1:6942 (LISTEN) idea 3257 smartestee 385u IPv4 0x2f3beaa58c69316b 0t0 TCP 127.0.0.1:63342 (LISTEN) 查看端口的使用情况 $ ps -ef 查看进程 $ kill xxxx 端口冲突时，用此命令，关闭某个端口。用PID替换xxxx $ history 查看历史命令记录 $ pwd 当前位置 $ which xx path位置，搭建环境的时候肯定会用得到 ","date":"2016-12-28","objectID":"/posts/linux-cmd/:1:0","tags":["linux"],"title":"linux命令","uri":"/posts/linux-cmd/"},{"categories":["基础知识"],"content":"Linux 文件系统命令 修改问价拥有者 $ chgrp -R 组名 文件 / 目录 $ chown -R 账户名 文件 / 目录 修改文件权限 $ chmod 使用数字 r：4, w：2, x：1 每种身份的权限的累加的。 $ chmod 777 test 使用符号修改 u: user, g: group, o: others, a: all 添加权限用+， 除去用-， 设置用= $ chmod u=rwx, g=rw, o=r test $ chmod a-x test $ chmod go+r test ​ $ sudo !! 以root权限执行上一条命令（注意上一条命令的内容，以免发生意外） 例如：在Ubuntu 安装软件或插件的时候需要用到这个命令 $ sudo apt-get install nginx 查看和修改： $ cat $ more $ less $ head $ tail $ vi $ vim $ mkdir $ touch ","date":"2016-12-28","objectID":"/posts/linux-cmd/:1:1","tags":["linux"],"title":"linux命令","uri":"/posts/linux-cmd/"},{"categories":["基础知识"],"content":"git $ git 先给出比较常用的 $ git add \u003c一个或多个文件名(文件名之间是用空格，也可以是一个点，表示添加全部)\u003e $ git commit -m \"注释\" 本地提交 $ git checkout \u003c分支名或master\u003e 切换分支与master $ git branch \u003c分支名\u003e 新开一个分支 $ git merge \u003c分支名\u003e 主分支与分支的合并 $ git push origin master 提交到github上 $ fuck 纠正命令行输入的错误，比手动改快，实用。 安装： $ brew install thefuck ","date":"2016-12-28","objectID":"/posts/linux-cmd/:1:2","tags":["linux"],"title":"linux命令","uri":"/posts/linux-cmd/"},{"categories":["基础知识"],"content":"娱乐 $ cmatrix $ telnet towel.blinkenlights.nl telnet是基于Telnet协议的远程登录客户端程序,经常用来远程登录服务器.除此还可以用它来观看星球大战 $ fortune 随机输出名言或者笑话， 还有很多，有兴趣的可以通过这个链接去看：知乎 个人博客 yusank 比较牛逼的一个查找命令的网站：http://www.commandlinefu.com/commands/browse/sort-by-votes 每天都有更新各种命令组合 ","date":"2016-12-28","objectID":"/posts/linux-cmd/:2:0","tags":["linux"],"title":"linux命令","uri":"/posts/linux-cmd/"}]