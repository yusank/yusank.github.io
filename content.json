{"meta":{"title":"Yusank's blog","subtitle":null,"description":"Always have a dream.","author":"Yusank","url":"http://yusank.github.io"},"pages":[{"title":"","date":"2017-02-18T06:09:54.000Z","updated":"2016-12-16T10:15:30.000Z","comments":true,"path":"多说.css","permalink":"http://yusank.github.io/多说.css","excerpt":"","text":"/* 浏览器识别效果 */ span.ua { display: inline-block !important; margin: auto 1px .3em !important; color: #fff !important; } .os_other { background-color: #bdb2a7!important; color: #fff; border: 1px solid #BBB!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_other { background-color: #bdb2a7!important; color: #fff; border: 1px solid #BBB!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_other { opacity: 1; } .os_other:hover { opacity: .4; } .ua_ie { background-color: #428bca!important; border-color: #357ebd!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_ie:hover { opacity: .4; } .ua_firefox { background-color: #f0ad4e!important; border-color: #eea236!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_firefox:hover { opacity: .4; } .ua_maxthon { background-color: #7373B9!important; border-color: #7373B9!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_maxthon:hover { opacity: .4; } .ua_ucweb { background-color: #FF740F!important; border-color: #d43f3a!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_ucweb:hover { opacity: .4; } .ua_sogou { background-color: #78ACE9!important; border-color: #4cae4c!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_sogou:hover { opacity: .4; } .ua_2345explorer { background-color: #2478B8!important; border-color: #4cae4c!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_2345explorer:hover { opacity: .4; } .ua_2345chrome { background-color: #F9D024!important; border-color: #4cae4c!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_2345chrome:hover { opacity: .4; } .ua_mi { background-color: #FF4A00!important; border-color: #4cae4c!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_mi:hover { opacity: .4; } .ua_lbbrowser { background-color: #FC9D2E!important; border-color: #4cae4c!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_lbbrowser:hover { opacity: .4; } .ua_chrome { background-color: #EE6252!important; border-color: #4cae4c!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_chrome:hover { opacity: .4; } .ua_qq { background-color: #3D88A8!important; border-color: #4cae4c!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_qq:hover { opacity: .4; } .ua_apple { background-color: #E95620!important; border-color: #4cae4c!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_apple:hover { opacity: .4; } .ua_opera { background-color: #d9534f!important; border-color: #d43f3a!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .ua_opera:hover { opacity: .4; } .os_vista,.os_2000,.os_windows,.os_xp,.os_7,.os_8,.os_8_1 { background-color: #39b3d7!important; border-color: #46b8da!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .os_vista:hover,.os_2000:hover,.os_windows:hover,.os_xp:hover,.os_7:hover,.os_8:hover,.os_8_1:hover { opacity: .4; } .os_android { background-color: #98C13D!important; border-color: #01B171!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .os_android:hover { opacity: .4; } .os_ubuntu { background-color: #DD4814!important; border-color: #01B171!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .os_ubuntu:hover { opacity: .4; } .os_linux { background-color: #3A3A3A!important; border-color: #1F1F1F!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .os_linux:hover { opacity: .4; } .os_mac { background-color: #666666!important; border-color: #1F1F1F!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .os_mac:hover { opacity: .4; } .os_unix { background-color: #006600!important; border-color: #1F1F1F!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .os_unix:hover { opacity: .4; } .os_nokia { background-color: #014485!important; border-color: #1F1F1F!important; border-radius: 4px; padding: 0 5px!important; opacity: 1; } .os_nokia:hover { opacity: .4; } /* UA End */ /* 博主标记 CSS */ .sskadmin { background-color: #00a67c!important; border-color: #01B171!important; border-radius: 4px; padding: 0 5px!important; } .sskadmin:hover { opacity: .5; } /* 鼠标悬停旋转头像 */ #ds-reset .ds-avatar img,#ds-reset .ds-avatar img:hover { -webkit-animation-fill-mode: both; -moz-animation-fill-mode: both; -ms-animation-fill-mode: both; -o-animation-fill-mode: both; animation-fill-mode: both; -webkit-animation-duration: 0s; -moz-animation-duration: 0s; -ms-animation-duration: 0s; -o-animation-duration: 0s; animation-duration: 0s; -webkit-animation-duration: .7s; -moz-animation-duration: .7s; -ms-animation-duration: .7s; -o-animation-duration: .7s; animation-duration: .7s } @-webkit-keyframes wobble { 0% { -webkit-transform: translateX(0) } 15% { -webkit-transform: translateX(-25%) rotate(-5deg) } 30% { -webkit-transform: translateX(20%) rotate(3deg) } 45% { -webkit-transform: translateX(-15%) rotate(-3deg) } 60% { -webkit-transform: translateX(10%) rotate(2deg) } 75% { -webkit-transform: translateX(-5%) rotate(-1deg) } 100% { -webkit-transform: translateX(0) } } @-moz-keyframes wobble { 0% { -moz-transform: translateX(0) } 15% { -moz-transform: translateX(-25%) rotate(-5deg) } 30% { -moz-transform: translateX(20%) rotate(3deg) } 45% { -moz-transform: translateX(-15%) rotate(-3deg) } 60% { -moz-transform: translateX(10%) rotate(2deg) } 75% { -moz-transform: translateX(-5%) rotate(-1deg) } 100% { -moz-transform: translateX(0) } } @-o-keyframes wobble { 0% { -o-transform: translateX(0) } 15% { -o-transform: translateX(-25%) rotate(-5deg) } 30% { -o-transform: translateX(20%) rotate(3deg) } 45% { -o-transform: translateX(-15%) rotate(-3deg) } 60% { -o-transform: translateX(10%) rotate(2deg) } 75% { -o-transform: translateX(-5%) rotate(-1deg) } 100% { -o-transform: translateX(0) } } @keyframes wobble { 0% { transform: translateX(0) } 15% { transform: translateX(-25%) rotate(-5deg) } 30% { transform: translateX(20%) rotate(3deg) } 45% { transform: translateX(-15%) rotate(-3deg) } 60% { transform: translateX(10%) rotate(2deg) } 75% { transform: translateX(-5%) rotate(-1deg) } 100% { transform: translateX(0) } } #ds-reset .ds-avatar img:hover { -webkit-animation-name: wobble; -moz-animation-name: wobble; -o-animation-name: wobble; animation-name: wobble } /* 社交账号登陆透明度 */ #ds-thread #ds-reset .ds-login-buttons { opacity: 1; } #ds-thread #ds-reset .ds-login-buttons:hover { opacity: 1; } /* 留言板 CSS */ #ds-thread.ds-narrow #ds-reset .ds-replybox{ padding-left: 0px; } #ds-thread #ds-reset .ds-replybox{ width: auto; font-size: 12px; z-index: 3; margin: 8px 0; position: relative; padding: 0; border: 1px solid #2F2F2F; border-radius: 6px; -webkit-box-shadow: 4px 4px 18px rgba(0,0,0,0.46); box-shadow: 4px 4px 18px rgba(0,0,0,0.46); } #ds-thread #ds-reset .ds-replybox .ds-avatar{ display: none; } #ds-thread #ds-reset .ds-textarea-wrapper{ border: none; border-bottom: none; background-color: rgba(255, 255, 255, 0.01); background-image: none; } #ds-thread #ds-reset .ds-comment-body p, #ds-thread #ds-reset .ds-textarea-wrapper textarea { color: #FFF; } /* “发布”按钮背景 */ #ds-thread #ds-reset .ds-post-toolbar { box-shadow: none; background-color: #414141; } #ds-thread #ds-reset .ds-post-toolbar .ds-post-options { background-color: rgb(65, 65, 65); border-radius: 5px; border: 0px solid #2F2F2F; } #ds-thread #ds-reset .ds-sync{ right: 27px; } #ds-thread #ds-reset .ds-post-button { background: #2f2f2f; width: 62px; text-shadow: none; color: #FFF; height: 26px; border: 0px #FFF; margin-right: 18px; margin-top: 1px; border-radius: 6px; background-image: none; box-shadow: none; } #ds-thread #ds-reset .ds-post-button:hover{ background: #EE6252; color: #FFF; } #ds-thread #ds-reset .ds-powered-by a{ color: #999; } #ds-thread #ds-reset .ds-powered-by a:hover{ color: #FFF; } #ds-reset .ds-gradient-bg { background-color: rgba(63, 63, 63, 0); background-image: none; } /* 评论列表背景 */ #ds-thread #ds-reset a{ color: #999; } #ds-thread #ds-reset a:hover{ color: #FFF; } #ds-thread #ds-reset .ds-comments{ background-color: #3F3F3F; } #ds-reset .ds-avatar{ background-color: rgba(255, 255, 255, 0); } /* 喜欢 */ #ds-thread #ds-reset a.ds-like-thread-button { border: 1px solid #EE6252; border-radius: 42px; width: 120px; background-color: rgba(224, 224, 224, 0); margin-right: 12px; padding: 9px 15px; text-shadow: none; background-image: none; } #ds-thread #ds-reset a.ds-like-thread-button span { color: #EE6252; } #ds-thread #ds-reset .ds-like-tooltip{ border-radius: 6px; border: 1px solid #1F1F1F; text-shadow: none; position: absolute; z-index: 9999; background-color: #3F3F3F; background-repeat: repeat-x; background-image: -khtml-gradient(linear, left top, left bottom, from(#3F3F3F), to(#3F3F3F)); background: -moz-linear-gradient(top, #3F3F3F 0, #3F3F3F 100%); background: -webkit-gradient(linear, left top, left bottom, color-stop(0, #3F3F3F), color-stop(100%, #3F3F3F)); background: -webkit-linear-gradient(top, #3F3F3F 0, #3F3F3F 100%); background: -ms-linear-gradient(top, #3F3F3F 0, #3F3F3F 100%); background: linear-gradient(top, #3F3F3F 0, #3F3F3F 100%); } #ds-thread #ds-reset .ds-meta { border-bottom: 1px solid rgba(0, 0, 0, 0); } #ds-thread #ds-reset .ds-header { font-weight: bold; font-size: 14px; color: #999; line-height: 30px; padding: 0 12px; } #ds-thread #ds-reset #ds-hot-posts { border: none; } /* 简介 */ #ds-reset .ds-highlight { color: #3dbcf5 !important; } #ds-thread #ds-reset .ds-comment-body p, #ds-thread #ds-reset .ds-textarea-wrapper textarea { color: #FFFFFF; font-size: 13px; font-family: Helvetica, Arial, \"Hiragino Sans GB\", sans-serif; } #ds-thread #ds-reset .ds-comment-actions a,#ds-thread #ds-reset a,#ds-thread #ds-reset .ds-comment-actions a,#ds-thread #ds-reset .ds-time{ color: #999; } #ds-thread #ds-reset .ds-comment-actions a .ds-icon:hover#ds-thread #ds-reset .ds-comment-actions a:hover,#ds-thread #ds-reset a:hover{ color: #FFF; } #ds-thread #ds-reset .ds-comments-info{ padding: 8px 0 0 0; border-bottom: 3px solid rgba(61, 61, 61, 0); } #ds-thread #ds-reset li.ds-post { width: 100%; overflow: hidden; clear: both; border-top: 1px dashed rgb(8, 8, 8); margin: 0; padding-top: 8px; list-style: none; } #ds-thread #ds-reset .ds-comments { width: 100%; border-bottom: 1px solid rgba(0, 0, 0, 0); } #ds-thread #ds-reset .ds-account-control ul { display: none; position: absolute; top: 19px; left: 0; border: 1px solid #080808; background: #3F3F3F; box-shadow: none; border-radius: 6px; text-align: center; } #ds-thread #ds-reset .ds-account-control ul li a { border: none; display: block; padding: 3px 10px; text-shadow: none; } /* 头像简介 */ #ds-thread #ds-reset #ds-bubble{ position: absolute; background: #2f2f2f; padding: 10px; color: #333; border-radius: 6px; border: 1px solid #0C0C0C; } #ds-thread #ds-reset .ds-arrow-down{ border-left: 5px solid rgb(63, 63, 63); border-right: 5px solid rgb(63, 63, 63); border-top: 5px solid #0C0C0C; } /* 新回复弹窗 */ #ds-notify { position: fixed; z-index: 9999; max-width: 144px; _width: 130px; display: block; float: none; padding: 8px 12px; background-color: #3F3F3F; -webkit-border-radius: 5px; border-radius: 5px; box-shadow: 0 1px 1px rgba(0,0,0,0.25); border: 1px solid #2F2F2F; } #ds-notify #ds-reset ul.ds-notify-unread li a { color: #FFF; text-decoration: none; } #ds-wrapper #ds-reset .ds-dialog-inner { width: 100%; position: relative; border: 1px solid #000; background: #3F3F41; border-radius: 6px; } #ds-wrapper #ds-reset h2 { display: block; font-weight: normal; font-size: 16px; margin: 0 0 15px 0; color: #999; } #ds-wrapper #ds-reset .ds-unread-list li { position: relative; margin: 0; padding: 0; border-top: 0; line-height: 1.5em; color: #777; } #ds-wrapper #ds-reset .ds-dialog-footer { display: none; clear: both; border-top: 1px dotted #ccc; padding: 10px 15px 6px; } #ds-wrapper #ds-reset .ds-unread-list li a[rel~=\"author\"] { color: #FFF; } #ds-thread #ds-reset .ds-paginator div.ds-border { border-top: 1px dashed #080808; margin-bottom: 15px; } #ds-thread #ds-reset .ds-paginator { border-bottom: 1px solid rgba(0, 0, 0, 0); text-align: right; padding-bottom: 15px; clear: both; line-height: 1em; } #ds-thread #ds-reset .ds-paginator a.ds-current { color: #FFFFFF; border: 1px solid #2F2F2F; background-color: #2F2F2F; border-radius: 4px; } #ds-thread #ds-reset .ds-post-toolbar { box-shadow: none; background-color: rgba(255, 255, 255, 0); } #ds-thread #ds-reset ul.ds-children { margin-left: 70px; }","raw":null,"content":null},{"title":"404","date":"2016-12-16T12:55:50.000Z","updated":"2016-12-16T12:55:50.000Z","comments":true,"path":"404/index.html","permalink":"http://yusank.github.io/404/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"Gallery","date":"2017-02-18T06:09:54.000Z","updated":"2017-01-04T06:44:02.000Z","comments":true,"path":"gallery/index.html","permalink":"http://yusank.github.io/gallery/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"about me","date":"2016-12-18T03:47:39.000Z","updated":"2017-01-07T02:29:04.000Z","comments":true,"path":"about/index.html","permalink":"http://yusank.github.io/about/index.html","excerpt":"","text":"I`m Yusan , Welcome to my persnol blog Here`s my favorite song.","raw":null,"content":null},{"title":"友情链接","date":"2016-12-18T03:47:54.000Z","updated":"2016-12-18T03:49:55.000Z","comments":true,"path":"links/index.html","permalink":"http://yusank.github.io/links/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"","date":"2017-02-18T06:09:54.000Z","updated":"2016-12-18T03:10:50.000Z","comments":true,"path":"tags/index.html","permalink":"http://yusank.github.io/tags/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"分类","date":"2016-12-16T08:09:00.000Z","updated":"2017-08-15T07:36:08.000Z","comments":false,"path":"categories/index.html","permalink":"http://yusank.github.io/categories/index.html","excerpt":"","text":"技术","raw":null,"content":null}],"posts":[{"title":"Go TCP Socket","slug":"Go-TCP Socket","date":"2017-08-01T02:00:01.000Z","updated":"2017-08-14T05:51:02.000Z","comments":true,"path":"Go-TCP Socket.html/","link":"","permalink":"http://yusank.github.io/Go-TCP Socket.html/","excerpt":"","text":"转载文章 Go语言TCP Socket编程文章原始地址: http://tonybai.com/2015/11/17/tcp-programming-in-golang/ Golang的主要 设计目标之一就是面向大规模后端服务程序，网络通信这块是服务端 程序必不可少也是至关重要的一部分。在日常应用中，我们也可以看到Go中的net以及其subdirectories下的包均是“高频+刚需”，而TCP socket则是网络编程的主流，即便您没有直接使用到net中有关TCP Socket方面的接口，但net/http总是用到了吧，http底层依旧是用tcp socket实现的。 网络编程方面，我们最常用的就是tcp socket编程了，在posix标准出来后，socket在各大主流OS平台上都得到了很好的支持。关于tcp programming，最好的资料莫过于W. Richard Stevens 的网络编程圣经《UNIX网络 编程 卷1：套接字联网API》 了，书中关于tcp socket接口的各种使用、行为模式、异常处理讲解的十分细致。Go是自带runtime的跨平台编程语言，Go中暴露给语言使用者的tcp socket api是建立OS原生tcp socket接口之上的。由于Go runtime调度的需要，golang tcp socket接口在行为特点与异常处理方面与OS原生接口有着一些差别。这篇博文的目标就是整理出关于Go tcp socket在各个场景下的使用方法、行为特点以及注意事项。 一、模型从tcp socket诞生后，网络编程架构模型也几经演化，大致是：“每进程一个连接” –&gt; “每线程一个连接” –&gt; “Non-Block + I/O多路复用(linux epoll/windows iocp/freebsd darwin kqueue/solaris Event Port)”。伴随着模型的演化，服务程序愈加强大，可以支持更多的连接，获得更好的处理性能。 目前主流web server一般均采用的都是”Non-Block + I/O多路复用”（有的也结合了多线程、多进程）。不过I/O多路复用也给使用者带来了不小的复杂度，以至于后续出现了许多高性能的I/O多路复用框架， 比如libevent、libev、libuv等，以帮助开发者简化开发复杂性，降低心智负担。不过Go的设计者似乎认为I/O多路复用的这种通过回调机制割裂控制流 的方式依旧复杂，且有悖于“一般逻辑”设计，为此Go语言将该“复杂性”隐藏在Runtime中了：Go开发者无需关注socket是否是 non-block的，也无需亲自注册文件描述符的回调，只需在每个连接对应的goroutine中以“block I/O”的方式对待socket处理即可，这可以说大大降低了开发人员的心智负担。一个典型的Go server端程序大致如下： //go-tcpsock/server.go func handleConn(c net.Conn) { defer c.Close() for { // read from the connection // ... ... // write to the connection //... ... } } func main() { l, err := net.Listen(\"tcp\", \":8888\") if err != nil { fmt.Println(\"listen error:\", err) return } for { c, err := l.Accept() if err != nil { fmt.Println(\"accept error:\", err) break } // start a new goroutine to handle // the new connection. go handleConn(c) } } 用户层眼中看到的goroutine中的“block socket”，实际上是通过Go runtime中的netpoller通过Non-block socket + I/O多路复用机制“模拟”出来的，真实的underlying socket实际上是non-block的，只是runtime拦截了底层socket系统调用的错误码，并通过netpoller和goroutine 调度让goroutine“阻塞”在用户层得到的Socket fd上。比如：当用户层针对某个socket fd发起read操作时，如果该socket fd中尚无数据，那么runtime会将该socket fd加入到netpoller中监听，同时对应的goroutine被挂起，直到runtime收到socket fd 数据ready的通知，runtime才会重新唤醒等待在该socket fd上准备read的那个Goroutine。而这个过程从Goroutine的视角来看，就像是read操作一直block在那个socket fd上似的。具体实现细节在后续场景中会有补充描述。 二、TCP连接的建立众所周知，TCP Socket的连接的建立需要经历客户端和服务端的三次握手的过程。连接建立过程中，服务端是一个标准的Listen + Accept的结构(可参考上面的代码)，而在客户端Go语言使用net.Dial或DialTimeout进行连接建立： 阻塞Dial： conn, err := net.Dial(\"tcp\", \"google.com:80\") if err != nil { //handle error } // read or write on conn 或是带上超时机制的Dial： conn, err := net.DialTimeout(\"tcp\", \":8080\", 2 * time.Second) if err != nil { //handle error } // read or write on conn 对于客户端而言，连接的建立会遇到如下几种情形： 1、网络不可达或对方服务未启动如果传给Dial的Addr是可以立即判断出网络不可达，或者Addr中端口对应的服务没有启动，端口未被监听，Dial会几乎立即返回错误，比如： //go-tcpsock/conn_establish/client1.go ... ... func main() { log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Println(\"dial error:\", err) return } defer conn.Close() log.Println(\"dial ok\") } 如果本机8888端口未有服务程序监听，那么执行上面程序，Dial会很快返回错误： $go run client1.go 2015/11/16 14:37:41 begin dial... 2015/11/16 14:37:41 dial error: dial tcp :8888: getsockopt: connection refused 2、对方服务的listen backlog满还有一种场景就是对方服务器很忙，瞬间有大量client端连接尝试向server建立，server端的listen backlog队列满，server accept不及时((即便不accept，那么在backlog数量范畴里面，connect都会是成功的，因为new conn已经加入到server side的listen queue中了，accept只是从queue中取出一个conn而已)，这将导致client端Dial阻塞。我们还是通过例子感受Dial的行为特点： 服务端代码： //go-tcpsock/conn_establish/server2.go ... ... func main() { l, err := net.Listen(\"tcp\", \":8888\") if err != nil { log.Println(\"error listen:\", err) return } defer l.Close() log.Println(\"listen ok\") var i int for { time.Sleep(time.Second * 10) if _, err := l.Accept(); err != nil { log.Println(\"accept error:\", err) break } i++ log.Printf(\"%d: accept a new connection\\n\", i) } } 客户端代码： //go-tcpsock/conn_establish/client2.go ... ... func establishConn(i int) net.Conn { conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Printf(\"%d: dial error: %s\", i, err) return nil } log.Println(i, \":connect to server ok\") return conn } func main() { var sl []net.Conn for i := 1; i &lt; 1000; i++ { conn := establishConn(i) if conn != nil { sl = append(sl, conn) } } time.Sleep(time.Second * 10000) } 从程序可以看出，服务端在listen成功后，每隔10s钟accept一次。客户端则是串行的尝试建立连接。这两个程序在Darwin下的执行 结果： $go run server2.go 2015/11/16 21:55:41 listen ok 2015/11/16 21:55:51 1: accept a new connection 2015/11/16 21:56:01 2: accept a new connection ... ... $go run client2.go 2015/11/16 21:55:44 1 :connect to server ok 2015/11/16 21:55:44 2 :connect to server ok 2015/11/16 21:55:44 3 :connect to server ok ... ... 2015/11/16 21:55:44 126 :connect to server ok 2015/11/16 21:55:44 127 :connect to server ok 2015/11/16 21:55:44 128 :connect to server ok 2015/11/16 21:55:52 129 :connect to server ok 2015/11/16 21:56:03 130 :connect to server ok 2015/11/16 21:56:14 131 :connect to server ok ... ... 可以看出Client初始时成功地一次性建立了128个连接，然后后续每阻塞近10s才能成功建立一条连接。也就是说在server端 backlog满时(未及时accept)，客户端将阻塞在Dial上，直到server端进行一次accept。至于为什么是128，这与darwin 下的默认设置有关： $sysctl -a|grep kern.ipc.somaxconn kern.ipc.somaxconn: 128 如果我在ubuntu 14.04上运行上述server程序，我们的client端初始可以成功建立499条连接。 如果server一直不accept，client端会一直阻塞么？我们去掉accept后的结果是：在Darwin下，client端会阻塞大 约1分多钟才会返回timeout： 2015/11/16 22:03:31 128 :connect to server ok 2015/11/16 22:04:48 129: dial error: dial tcp :8888: getsockopt: operation timed out 而如果server运行在ubuntu 14.04上，client似乎一直阻塞，我等了10多分钟依旧没有返回。 阻塞与否看来与server端的网络实现和设置有关。 3、网络延迟较大，Dial阻塞并超时如果网络延迟较大，TCP握手过程将更加艰难坎坷（各种丢包），时间消耗的自然也会更长。Dial这时会阻塞，如果长时间依旧无法建立连接，则Dial也会返回“ getsockopt: operation timed out”错误。 在连接建立阶段，多数情况下，Dial是可以满足需求的，即便阻塞一小会儿。但对于某些程序而言，需要有严格的连接时间限定，如果一定时间内没能成功建立连接，程序可能会需要执行一段“异常”处理逻辑，为此我们就需要DialTimeout了。下面的例子将Dial的最长阻塞时间限制在2s内，超出这个时长，Dial将返回timeout error： //go-tcpsock/conn_establish/client3.go ... ... func main() { log.Println(\"begin dial...\") conn, err := net.DialTimeout(\"tcp\", \"104.236.176.96:80\", 2*time.Second) if err != nil { log.Println(\"dial error:\", err) return } defer conn.Close() log.Println(\"dial ok\") } 执行结果如下（需要模拟一个延迟较大的网络环境）： $go run client3.go 2015/11/17 09:28:34 begin dial... 2015/11/17 09:28:36 dial error: dial tcp 104.236.176.96:80: i/o timeout 三、Socket读写连接建立起来后，我们就要在conn上进行读写，以完成业务逻辑。前面说过Go runtime隐藏了I/O多路复用的复杂性。语言使用者只需采用goroutine+Block I/O的模式即可满足大部分场景需求。Dial成功后，方法返回一个net.Conn接口类型变量值，这个接口变量的动态类型为一个*TCPConn： //$GOROOT/src/net/tcpsock_posix.go type TCPConn struct { conn } TCPConn内嵌了一个unexported类型：conn，因此TCPConn”继承”了conn的Read和Write方法，后续通过Dial返回值调用的Write和Read方法均是net.conn的方法： //$GOROOT/src/net/net.go type conn struct { fd *netFD } func (c *conn) ok() bool { return c != nil &amp;&amp; c.fd != nil } // Implementation of the Conn interface. // Read implements the Conn Read method. func (c *conn) Read(b []byte) (int, error) { if !c.ok() { return 0, syscall.EINVAL } n, err := c.fd.Read(b) if err != nil &amp;&amp; err != io.EOF { err = &amp;OpError{Op: \"read\", Net: c.fd.net, Source: c.fd.laddr, Addr: c.fd.raddr, Err: err} } return n, err } // Write implements the Conn Write method. func (c *conn) Write(b []byte) (int, error) { if !c.ok() { return 0, syscall.EINVAL } n, err := c.fd.Write(b) if err != nil { err = &amp;OpError{Op: \"write\", Net: c.fd.net, Source: c.fd.laddr, Addr: c.fd.raddr, Err: err} } return n, err } 下面我们先来通过几个场景来总结一下conn.Read的行为特点。 1、Socket中无数据连接建立后，如果对方未发送数据到socket，接收方(Server)会阻塞在Read操作上，这和前面提到的“模型”原理是一致的。执行该Read操作的goroutine也会被挂起。runtime会监视该socket，直到其有数据才会重新调度该socket对应的Goroutine完成read。由于篇幅原因，这里就不列代码了，例子对应的代码文件：go-tcpsock/read_write下的client1.go和server1.go。 2、Socket中有部分数据如果socket中有部分数据，且长度小于一次Read操作所期望读出的数据长度，那么Read将会成功读出这部分数据并返回，而不是等待所有期望数据全部读取后再返回。 Client端： //go-tcpsock/read_write/client2.go ... ... func main() { if len(os.Args) &lt;= 1 { fmt.Println(\"usage: go run client2.go YOUR_CONTENT\") return } log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Println(\"dial error:\", err) return } defer conn.Close() log.Println(\"dial ok\") time.Sleep(time.Second * 2) data := os.Args[1] conn.Write([]byte(data)) time.Sleep(time.Second * 10000) } Server端： //go-tcpsock/read_write/server2.go ... ... func handleConn(c net.Conn) { defer c.Close() for { // read from the connection var buf = make([]byte, 10) log.Println(\"start to read from conn\") n, err := c.Read(buf) if err != nil { log.Println(\"conn read error:\", err) return } log.Printf(\"read %d bytes, content is %s\\n\", n, string(buf[:n])) } } ... ... 我们通过client2.go发送”hi”到Server端：运行结果: $go run client2.go hi 2015/11/17 13:30:53 begin dial... 2015/11/17 13:30:53 dial ok $go run server2.go 2015/11/17 13:33:45 accept a new connection 2015/11/17 13:33:45 start to read from conn 2015/11/17 13:33:47 read 2 bytes, content is hi ... Client向socket中写入两个字节数据(“hi”)，Server端创建一个len = 10的slice，等待Read将读取的数据放入slice；Server随后读取到那两个字节：”hi”。Read成功返回，n =2 ，err = nil。 3、Socket中有足够数据如果socket中有数据，且长度大于等于一次Read操作所期望读出的数据长度，那么Read将会成功读出这部分数据并返回。这个情景是最符合我们对Read的期待的了：Read将用Socket中的数据将我们传入的slice填满后返回：n = 10, err = nil。 我们通过client2.go向Server2发送如下内容：abcdefghij12345，执行结果如下： $go run client2.go abcdefghij12345 2015/11/17 13:38:00 begin dial... 2015/11/17 13:38:00 dial ok $go run server2.go 2015/11/17 13:38:00 accept a new connection 2015/11/17 13:38:00 start to read from conn 2015/11/17 13:38:02 read 10 bytes, content is abcdefghij 2015/11/17 13:38:02 start to read from conn 2015/11/17 13:38:02 read 5 bytes, content is 12345 client端发送的内容长度为15个字节，Server端Read buffer的长度为10，因此Server Read第一次返回时只会读取10个字节；Socket中还剩余5个字节数据，Server再次Read时会把剩余数据读出（如：情形2）。 4、Socket关闭如果client端主动关闭了socket，那么Server的Read将会读到什么呢？这里分为“有数据关闭”和“无数据关闭”。 “有数据关闭”是指在client关闭时，socket中还有server端未读取的数据，我们在go-tcpsock/read_write/client3.go和server3.go中模拟这种情况： $go run client3.go hello 2015/11/17 13:50:57 begin dial... 2015/11/17 13:50:57 dial ok $go run server3.go 2015/11/17 13:50:57 accept a new connection 2015/11/17 13:51:07 start to read from conn 2015/11/17 13:51:07 read 5 bytes, content is hello 2015/11/17 13:51:17 start to read from conn 2015/11/17 13:51:17 conn read error: EOF 从输出结果来看，当client端close socket退出后，server3依旧没有开始Read，10s后第一次Read成功读出了5个字节的数据，当第二次Read时，由于client端 socket关闭，Read返回EOF error。 通过上面这个例子，我们也可以猜测出“无数据关闭”情形下的结果，那就是Read直接返回EOF error。 5、读取操作超时有些场合对Read的阻塞时间有严格限制，在这种情况下，Read的行为到底是什么样的呢？在返回超时错误时，是否也同时Read了一部分数据了呢？这个实验比较难于模拟，下面的测试结果也未必能反映出所有可能结果。我们编写了client4.go和server4.go来模拟这一情形。 //go-tcpsock/read_write/client4.go ... ... func main() { log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Println(\"dial error:\", err) return } defer conn.Close() log.Println(\"dial ok\") data := make([]byte, 65536) conn.Write(data) time.Sleep(time.Second * 10000) } //go-tcpsock/read_write/server4.go ... ... func handleConn(c net.Conn) { defer c.Close() for { // read from the connection time.Sleep(10 * time.Second) var buf = make([]byte, 65536) log.Println(\"start to read from conn\") c.SetReadDeadline(time.Now().Add(time.Microsecond * 10)) n, err := c.Read(buf) if err != nil { log.Printf(\"conn read %d bytes, error: %s\", n, err) if nerr, ok := err.(net.Error); ok &amp;&amp; nerr.Timeout() { continue } return } log.Printf(\"read %d bytes, content is %s\\n\", n, string(buf[:n])) } } 在Server端我们通过Conn的SetReadDeadline方法设置了10微秒的读超时时间，Server的执行结果如下： $go run server4.go 2015/11/17 14:21:17 accept a new connection 2015/11/17 14:21:27 start to read from conn 2015/11/17 14:21:27 conn read 0 bytes, error: read tcp 127.0.0.1:8888->127.0.0.1:60970: i/o timeout 2015/11/17 14:21:37 start to read from conn 2015/11/17 14:21:37 read 65536 bytes, content is 虽然每次都是10微秒超时，但结果不同，第一次Read超时，读出数据长度为0；第二次读取所有数据成功，没有超时。反复执行了多次，没能出现“读出部分数据且返回超时错误”的情况。 和读相比，Write遇到的情形一样不少，我们也逐一看一下。 1、成功写前面例子着重于Read，client端在Write时并未判断Write的返回值。所谓“成功写”指的就是Write调用返回的n与预期要写入的数据长度相等，且error = nil。这是我们在调用Write时遇到的最常见的情形，这里不再举例了。 2、写阻塞TCP连接通信两端的OS都会为该连接保留数据缓冲，一端调用Write后，实际上数据是写入到OS的协议栈的数据缓冲的。TCP是全双工通信，因此每个方向都有独立的数据缓冲。当发送方将对方的接收缓冲区以及自身的发送缓冲区写满后，Write就会阻塞。我们来看一个例子：client5.go和server.go。 //go-tcpsock/read_write/client5.go ... ... func main() { log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Println(\"dial error:\", err) return } defer conn.Close() log.Println(\"dial ok\") data := make([]byte, 65536) var total int for { n, err := conn.Write(data) if err != nil { total += n log.Printf(\"write %d bytes, error:%s\\n\", n, err) break } total += n log.Printf(\"write %d bytes this time, %d bytes in total\\n\", n, total) } log.Printf(\"write %d bytes in total\\n\", total) time.Sleep(time.Second * 10000) } //go-tcpsock/read_write/server5.go ... ... func handleConn(c net.Conn) { defer c.Close() time.Sleep(time.Second * 10) for { // read from the connection time.Sleep(5 * time.Second) var buf = make([]byte, 60000) log.Println(\"start to read from conn\") n, err := c.Read(buf) if err != nil { log.Printf(\"conn read %d bytes, error: %s\", n, err) if nerr, ok := err.(net.Error); ok &amp;&amp; nerr.Timeout() { continue } } log.Printf(\"read %d bytes, content is %s\\n\", n, string(buf[:n])) } } ... ... Server5在前10s中并不Read数据，因此当client5一直尝试写入时，写到一定量后就会发生阻塞： $go run client5.go 2015/11/17 14:57:33 begin dial... 2015/11/17 14:57:33 dial ok 2015/11/17 14:57:33 write 65536 bytes this time, 65536 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 131072 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 196608 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 262144 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 327680 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 393216 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 458752 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 524288 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 589824 bytes in total 2015/11/17 14:57:33 write 65536 bytes this time, 655360 bytes in total 在Darwin上，这个size大约在679468bytes。后续当server5每隔5s进行Read时，OS socket缓冲区腾出了空间，client5就又可以写入了： $go run server5.go 2015/11/17 15:07:01 accept a new connection 2015/11/17 15:07:16 start to read from conn 2015/11/17 15:07:16 read 60000 bytes, content is 2015/11/17 15:07:21 start to read from conn 2015/11/17 15:07:21 read 60000 bytes, content is 2015/11/17 15:07:26 start to read from conn 2015/11/17 15:07:26 read 60000 bytes, content is .... client端： 2015/11/17 15:07:01 write 65536 bytes this time, 720896 bytes in total 2015/11/17 15:07:06 write 65536 bytes this time, 786432 bytes in total 2015/11/17 15:07:16 write 65536 bytes this time, 851968 bytes in total 2015/11/17 15:07:16 write 65536 bytes this time, 917504 bytes in total 2015/11/17 15:07:27 write 65536 bytes this time, 983040 bytes in total 2015/11/17 15:07:27 write 65536 bytes this time, 1048576 bytes in total .... ... 3、写入部分数据Write操作存在写入部分数据的情况，比如上面例子中，当client端输出日志停留在“write 65536 bytes this time, 655360 bytes in total”时，我们杀掉server5，这时我们会看到client5输出以下日志： ... 2015/11/17 15:19:14 write 65536 bytes this time, 655360 bytes in total 2015/11/17 15:19:16 write 24108 bytes, error:write tcp 127.0.0.1:62245->127.0.0.1:8888: write: broken pipe 2015/11/17 15:19:16 write 679468 bytes in total 显然Write并非在655360这个地方阻塞的，而是后续又写入24108后发生了阻塞，server端socket关闭后，我们看到Wrote返回er != nil且n = 24108，程序需要对这部分写入的24108字节做特定处理。 4、写入超时如果非要给Write增加一个期限，那我们可以调用SetWriteDeadline方法。我们copy一份client5.go，形成client6.go，在client6.go的Write之前增加一行timeout设置代码： conn.SetWriteDeadline(time.Now().Add(time.Microsecond * 10)) 启动server6.go，启动client6.go，我们可以看到写入超时的情况下，Write的返回结果： $go run client6.go 2015/11/17 15:26:34 begin dial... 2015/11/17 15:26:34 dial ok 2015/11/17 15:26:34 write 65536 bytes this time, 65536 bytes in total ... ... 2015/11/17 15:26:34 write 65536 bytes this time, 655360 bytes in total 2015/11/17 15:26:34 write 24108 bytes, error:write tcp 127.0.0.1:62325->127.0.0.1:8888: i/o timeout 2015/11/17 15:26:34 write 679468 bytes in total 可以看到在写入超时时，依旧存在部分数据写入的情况。 综上例子，虽然Go给我们提供了阻塞I/O的便利，但在调用Read和Write时依旧要综合需要方法返回的n和err的结果，以做出正确处理。net.conn实现了io.Reader和io.Writer接口，因此可以试用一些wrapper包进行socket读写，比如bufio包下面的Writer和Reader、io/ioutil下的函数等。 Goroutine safe基于goroutine的网络架构模型，存在在不同goroutine间共享conn的情况，那么conn的读写是否是goroutine safe的呢？在深入这个问题之前，我们先从应用意义上来看read操作和write操作的goroutine-safe必要性。 对于read操作而言，由于TCP是面向字节流，conn.Read无法正确区分数据的业务边界，因此多个goroutine对同一个conn进行read的意义不大，goroutine读到不完整的业务包反倒是增加了业务处理的难度。对与Write操作而言，倒是有多个goroutine并发写的情况。不过conn读写是否goroutine-safe的测试不是很好做，我们先深入一下runtime代码，先从理论上给这个问题定个性： net.conn只是*netFD的wrapper结构，最终Write和Read都会落在其中的fd上： type conn struct { fd *netFD } netFD在不同平台上有着不同的实现，我们以net/fd_unix.go中的netFD为例： // Network file descriptor. type netFD struct { // locking/lifetime of sysfd + serialize access to Read and Write methods fdmu fdMutex // immutable until Close sysfd int family int sotype int isConnected bool net string laddr Addr raddr Addr // wait server pd pollDesc } 我们看到netFD中包含了一个runtime实现的fdMutex类型字段，从注释上来看，该fdMutex用来串行化对该netFD对应的sysfd的Write和Read操作。从这个注释上来看，所有对conn的Read和Write操作都是有fdMutex互斥的，从netFD的Read和Write方法的实现也证实了这一点： func (fd *netFD) Read(p []byte) (n int, err error) { if err := fd.readLock(); err != nil { return 0, err } defer fd.readUnlock() if err := fd.pd.PrepareRead(); err != nil { return 0, err } for { n, err = syscall.Read(fd.sysfd, p) if err != nil { n = 0 if err == syscall.EAGAIN { if err = fd.pd.WaitRead(); err == nil { continue } } } err = fd.eofError(n, err) break } if _, ok := err.(syscall.Errno); ok { err = os.NewSyscallError(\"read\", err) } return } func (fd *netFD) Write(p []byte) (nn int, err error) { if err := fd.writeLock(); err != nil { return 0, err } defer fd.writeUnlock() if err := fd.pd.PrepareWrite(); err != nil { return 0, err } for { var n int n, err = syscall.Write(fd.sysfd, p[nn:]) if n > 0 { nn += n } if nn == len(p) { break } if err == syscall.EAGAIN { if err = fd.pd.WaitWrite(); err == nil { continue } } if err != nil { break } if n == 0 { err = io.ErrUnexpectedEOF break } } if _, ok := err.(syscall.Errno); ok { err = os.NewSyscallError(\"write\", err) } return nn, err } 每次Write操作都是受lock保护，直到此次数据全部write完。因此在应用层面，要想保证多个goroutine在一个conn上write操作的Safe，需要一次write完整写入一个“业务包”；一旦将业务包的写入拆分为多次write，那就无法保证某个Goroutine的某“业务包”数据在conn发送的连续性。 同时也可以看出即便是Read操作，也是lock保护的。多个Goroutine对同一conn的并发读不会出现读出内容重叠的情况，但内容断点是依 runtime调度来随机确定的。存在一个业务包数据，1/3内容被goroutine-1读走，另外2/3被另外一个goroutine-2读 走的情况。比如一个完整包：world，当goroutine的read slice size &lt; 5时，存在可能：一个goroutine读到 “worl”,另外一个goroutine读出”d”。 四、Socket属性原生Socket API提供了丰富的sockopt设置接口，但Golang有自己的网络架构模型，golang提供的socket options接口也是基于上述模型的必要的属性设置。包括 SetKeepAlive SetKeepAlivePeriod SetLinger SetNoDelay （默认no delay） SetWriteBuffer SetReadBuffer 不过上面的Method是TCPConn的，而不是Conn的，要使用上面的Method的，需要type assertion： tcpConn, ok := c.(*TCPConn) if !ok { //error handle } tcpConn.SetNoDelay(true) 对于listener socket, golang默认采用了 SO_REUSEADDR，这样当你重启 listener程序时，不会因为address in use的错误而启动失败。而listen backlog的默认值是通过获取系统的设置值得到的。不同系统不同：mac 128, linux 512等。 五、关闭连接和前面的方法相比，关闭连接算是最简单的操作了。由于socket是全双工的，client和server端在己方已关闭的socket和对方关闭的socket上操作的结果有不同。看下面例子： //go-tcpsock/conn_close/client1.go ... ... func main() { log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil { log.Println(\"dial error:\", err) return } conn.Close() log.Println(\"close ok\") var buf = make([]byte, 32) n, err := conn.Read(buf) if err != nil { log.Println(\"read error:\", err) } else { log.Printf(\"read % bytes, content is %s\\n\", n, string(buf[:n])) } n, err = conn.Write(buf) if err != nil { log.Println(\"write error:\", err) } else { log.Printf(\"write % bytes, content is %s\\n\", n, string(buf[:n])) } time.Sleep(time.Second * 1000) } //go-tcpsock/conn_close/server1.go ... ... func handleConn(c net.Conn) { defer c.Close() // read from the connection var buf = make([]byte, 10) log.Println(\"start to read from conn\") n, err := c.Read(buf) if err != nil { log.Println(\"conn read error:\", err) } else { log.Printf(\"read %d bytes, content is %s\\n\", n, string(buf[:n])) } n, err = c.Write(buf) if err != nil { log.Println(\"conn write error:\", err) } else { log.Printf(\"write %d bytes, content is %s\\n\", n, string(buf[:n])) } } ... ... 上述例子的执行结果如下： $go run server1.go 2015/11/17 17:00:51 accept a new connection 2015/11/17 17:00:51 start to read from conn 2015/11/17 17:00:51 conn read error: EOF 2015/11/17 17:00:51 write 10 bytes, content is $go run client1.go 2015/11/17 17:00:51 begin dial... 2015/11/17 17:00:51 close ok 2015/11/17 17:00:51 read error: read tcp 127.0.0.1:64195->127.0.0.1:8888: use of closed network connection 2015/11/17 17:00:51 write error: write tcp 127.0.0.1:64195->127.0.0.1:8888: use of closed network connection 从client1的结果来看，在己方已经关闭的socket上再进行read和write操作，会得到”use of closed network connection” error；从server1的执行结果来看，在对方关闭的socket上执行read操作会得到EOF error，但write操作会成功，因为数据会成功写入己方的内核socket缓冲区中，即便最终发不到对方socket缓冲区了，因为己方socket并未关闭。因此当发现对方socket关闭后，己方应该正确合理处理自己的socket，再继续write已经无任何意义了。 六、小结本文比较基础，但却很重要，毕竟golang是面向大规模服务后端的，对通信环节的细节的深入理解会大有裨益。另外Go的goroutine+阻塞通信的网络通信模型降低了开发者心智负担，简化了通信的复杂性，这点尤为重要。 本文代码实验环境：go 1.5.1 on Darwin amd64以及部分在ubuntu 14.04 amd64。 本文demo代码在这里可以找到。 © 2015, bigwhite. 版权所有.","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Docker 的使用","slug":"docker-practice","date":"2017-07-17T07:52:00.000Z","updated":"2017-07-17T07:52:01.000Z","comments":true,"path":"docker-practice.html/","link":"","permalink":"http://yusank.github.io/docker-practice.html/","excerpt":" docker 的基本操作和使用。。。","text":"docker 的基本操作和使用。。。 Docker 的使用基本操作 启动容器 新建并启动所需的命令是 docker run 例如： $ docker run ubuntu:14.04 /bin/echo 'hello, worl' 容器执行后面的命令直接就会终止 . 下面的命令会启动容器并起一个 bash 终端,允许用户进行交互 $ docker run -t -i ubuntu:14.04 /bin/bash 其中 -t 让 Docker 分配一个伪终端 (pseudo-tty) 并绑定到容器的标准输入上, -i 则让容器的标准输入保持打开 . 利用 docker run 来创建容器是, Docker 在后台运行的标准操作包括: 检查本地是否存在指定的镜像,不存在就从共有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统并在只读的镜像层外面挂载一层可读写层 在宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器终止 启动已终止容器可以利用 docker start 命令,直接将一个已经终止的容器启动运行 . 可以通过 docker ps -a 查看所有的容器和其状态 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES aada74689bf7 cockroachdb/cockroach \"/cockroach/cockro...\" 3 weeks ago Exited (137) 3 weeks ago roach_master 2e9eb6cf3f66 owncloud \"/entrypoint.sh ap...\" 3 weeks ago Up 3 weeks 0.0.0.0:80->80/tcp owncloud 91290c737c73 postgres \"docker-entrypoint...\" 3 weeks ago Up 3 weeks 5432/tcp owncloud-postgres 8f546ec65e61 mysql \"docker-entrypoint...\" 3 weeks ago Up 3 weeks 0.0.0.0:3306->3306/tcp mysql 不难发现 name 为 roch_master 的容器已经终止了,想重新启动它,可以执行下面的命令 $ docker start aada74689bf7 参数为容器的 id . 后台( background )运行在很多时候,我们需要让 docker 在后台运行而并不是把执行结果直接输出出来. 这个时候我们可以添加 -d 参数来实现 如果使用 -d 参数运行容器 $ docker run -d mysql:5.7.17 77b2dc01fe0f3f1265df143181e7b9af5e05279a884f4776ee75350ea9d8017a 只会输出运行的容器 id, 而输出结果可以用 docker logs 查看 . $ docker logs [container ID or NAMES] 终止容器可以使用 docker stop 来终止正在运行的容器 . 此外,当 Docker 容器中指定的应用终结时, 容器也自动终止 . 例如运行一个容器时,指定了一个终端后,当退出终端的时候,所创建的容器也会立刻终止 . 终止状态的容器, 可以通过 docker start 来重新启动 . 此外,docker restart 命令会将一个运行态的容器终止,然后重新启动它 . 进入容器在使用 -d 参数时, docker 容器会在后台运行. 有些时候需要进入容器,如运行数据库时,需要进入增删改查库里的内容. 进入容器有很多种办法. attach 命令attach 是 Docker 自带的命令,用法\b&lt;p>但是使用 &lt;code>attach&lt;/code> 命令有个缺陷,即多个窗口同时用 attach 命令到同一个容器的时候,所有的窗口都是同步显示的,如果其中一个窗口阻塞的时候,其他窗口也无法使用 .&lt;/p> &lt;h4 id=\"nsenter-命令\">&lt;a href=\"#nsenter-命令\" class=\"headerlink\" title=\"nsenter 命令\">&lt;/a>nsenter 命令&lt;/h4>&lt;p>这个工具需要用如下命令安装&lt;/p> &lt;pre>&lt;code class=\"shell\">$ docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter 使用方法也比较简单,首先是你要进入的容器的 ID $ PID=$(docker inspect --format {{.State.Pid}} ) 然后通过这个 PID 进入容器 $ nsenter --target $PID --mount --uts --ipc --net --pid 如果无法通过上述的命令连接到容器,有可能是因为宿主的默认 shell 在容器中并不存在,比如 zsh, 可以使用如下命令显示地使用 bash . exec 命令$docker exec -it [container ID or NAMES] -i -t 前面说过为了标准输入输出保持打开 . 导出和导入容器导出容器如果要导出本地某个容器,可以使用 docker export 命令 . $ docker export [container ID or NAMES] > target.tar 这样将导出容器快照到本地文件 . 导入容器快照可以使用 docker import 从容器快照文件导入镜像, $ cat target.tar | docker import - test/mysql:v1.0 $ sudo docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE test/ubuntu v1.0 9d37a6082e97 About a minute ago 171.3 MB 此外,还可以通过指定 URL 或者某个目录来导入 $ docker import http://example.com/exampleimage.tgz example/imagerepo *注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库,也可以使用 docker import 来导入一个容器快照到本地镜像库 .这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态）,而镜像存储文件将保存完整记录,体积也要大 .此外,从容器快照文件导入时可以重新指定标签等元数据信息 . 删除容器单独删除可以使用 docker rm 来删除一个处于终止状态的容器 . $ docker rm [container ID or NAMES] 如果要删除一个运行中的容器,可以添加 -f 参数 .Docker 会发送 SIGKILL 信号给容器 . 清理所有处于终止状态的容器用 docker ps -a 命令可以查看所有已创建的包括终止状态的容器,如果想批量删除多个容器的话(当然是终止状态的容器) ,可以用这个命令 $ docker rm $(docker ps -a -q) *注意：这个命令其实会试图删除所有的包括还在运行中的容器,不过就像上面提过的 docker rm 默认并不会删除运行中的容器 . 访问仓库仓库（Repository）是集中存放镜像的地方 . 一个容易混淆的概念是注册服务器（Registry） .实际上注册服务器是管理仓库的具体服务器,每个服务器上可以有多个仓库,而每个仓库下面有多个镜像 .从这方面来说,仓库可以被认为是一个具体的项目或目录 .例如对于仓库地址dl.dockerpool.com/ubuntu 来说, dl.dockerpool.com 是注册服务器地址, ubuntu 是仓库名 . 大部分时候,并不需要严格区分这两者的概念 . Docker Hub目前 Docker 官方维护了一个公共仓库 Docker Hub, 但是开始把阵地移到 Docker Store 这个平台上,其上能找到几乎所有的能想得到的容器, 不可小觑 . 登录可以通过执行 docker login 命令来输入用户名、密码和邮箱来完成注册和登录 . 注册成功后,本地用户目录的.dockercfg 中将保存用户的认证信息 . 基本操作用户无需登录即可通过 docker search 命令来查找官方仓库中的镜像, 并利用 docker pull 命令来将它下载到本地 . 以搜索 mongo 为关键字搜索: $ docker search mongo NAME DESCRIPTION STARS OFFICIAL AUTOMATED mongo MongoDB document databases provide high av... 3427 [OK] mongo-express Web-based MongoDB admin interface, written... 168 [OK] mvertes/alpine-mongo light MongoDB container 51 [OK] mongoclient/mongoclient Official docker image for Mongoclient, fea... 29 [OK] torusware/speedus-mongo Always updated official MongoDB docker ima... 9 [OK] mongooseim/mongooseim-docker MongooseIM server the latest stable version 9 [OK] ​搜索结果可以看到很多包含关键字的镜像,其中包括镜像名字、描述、星数（表示该镜像的受欢迎程度）、是否官方创建、是否自动创建 . 官方的镜像说明是官方项目组创建和维护的,automated 资源允许用户验证镜像的来源和内容 . ​根据是否为官方提供, 镜像资源可分为两类 . 一类是累类似 mongo这样的基础镜像 . 这些镜像由 Docker 的用户创建、验证、支持、提供 . 这样的镜像往往是使用单个单词作为名字 . 另一种类型,比如mvertes/alpine-mongo 镜像,它是由 Docker 的用户创建并维护的,往往带有用户名称前缀 . 可以通过前缀 user_name/ 来指定使用某个用户提供的镜像 . 另外,在查找的时候通过 -s N 参数可以指定仅显示星数为 N 以上的镜像 （新版本的 Docker 推荐使用 --flter=stars=N 参数） . 下载镜像到本地 $ sudo docker pull centos Pulling repository centos 0b443ba03958: Download complete 539c0211cd76: Download complete 511136ea3c5a: Download complete 7064731afe90: Download complete 用户也可以登录之后通过 docker push 命令来讲镜像推送到 Docker Hub . 自动创建​自动创建（automated builds）功能对于需要经常升级镜像内程序来说,十分方便 .有时候,用户创建了镜像安装了某个软件,如果软件发布新版本则需要手动更新镜像 . .而自动创建允许用户通过 Docker Hub 指定跟踪一个目标网站（目前支持 GitHub或 BitBucket）上的项目,一旦项目发生新的提交,则自动执行创建 . 要配置自动创建,包括如下的步骤： 创建并登录 Docker Hub,以及目标网站； 在目标网站中连接帐户到 Docker Hub； 在 Docker Hub 中 配置一个自动创建； 选取一个目标网站中的项目（需要含 Dockerfile）和分支； 指定 Dockerfile 的位置,并提交创建 . 之后,可以 在Docker Hub 的 自动创建页面 中跟踪每次创建的状态 . 私有仓库有时候使用 Docker Hub 这样的公共仓库由于网络等原因可能不方便,用户可以创建一个本地仓库供私人使用 . 需要用到 docker-registry 工具 . docker-registry 是官方提供的工具,可以用于构建私有的镜像仓库 . 安装运行 docker-registry容器运行在安装了 Docker 后,可以通过获取官方 registry 镜像来运行 . $ docker run -d -p 5000:5000 registry 这将使用官方的 registry 镜像来启动本地的私有仓库 .用户可以通过制定参数来配置私有仓库位置,例如配置镜像存储到 Amazon S3 服务 . $ sudo docker run \\ -e SETTINGS_FLAVOR=s3 \\ -e AWS_BUCKET=acme-docker \\ -e STORAGE_PATH=/registry \\ -e AWS_KEY=AKIAHSHB43HS3J92MXZ \\ -e AWS_SECRET=xdDowwlK7TJajV1Y7EoOZrmuPEJlHYcNP2k4j49T \\ -e SEARCH_BACKEND=sqlalchemy \\ -p 5000:5000 \\ registry 此外,还可以指定本地路径（如/home/user/registry-conf ）下的配置文件 . $ sudo docker run -d -p 5000:5000 -v /home/user/registry-conf:/r egistry-conf -e DOCKER_REGISTRY_CONFIG=/registry-conf/config.yml registry 默认情况下,仓库会被创建在容器的 /var/lib/registry 下 .可以通过 -v 参数来将镜像文件存放在本地的指定路径 . 例如下面的例子将上传的镜像放到 /opt/data/registy 目录 . $ sudo docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib /registry registry 本地安装对于 Ubuntu 或 CentOS 等发行版,可以直接安装 . Ubuntu $ sudo apt-get install -y build-essential python-dev libevent-dev python-pip liblzma-dev $ sudo pip install docker-registry CentOS $ sudo yum install -y python-devel libevent-devel python-pip gcc xz-devel $ sudo python-pip install docker-registry 也可以从 docker-registry 项目下载源码进行安装 . $ sudo apt-get install build-essential python-dev libevent-dev python-pip libssl-dev liblzma-dev libffi-dev $ git clone https://github.com/docker/docker-registry.git $ cd docker-registry $ sudo python setup.py install 然后修改配置文件,主要修改 dev 模板段的 storage_path 到本地的存储仓库的路径 . $ cp config/config_sample.yml config/config.yml 之后启动 web 服务 . $ sudo gunicorn -c contrib/gunicorn.py docker_registry.wsgi:application 或者 $ sudo gunicorn --access-logfile - --error-logfile - -k gevent -b 0.0.0.0:5000 -w 4 --max-requests 100 docker_registry.wsgi:application 此时使用 crul 访问本地的 5000 端口,看到输出 docker-registry 的版本信息说明运行成功 . *注 ： config/config_sample.yml 文件时示例配置文件 在私有仓库上传、下载、搜索镜像创建好私有仓库之后,就可以使用 docker tag 来标记一个镜像,然后推送它到仓库,别的机器上就可以下载了 .如 私有仓库地址为 1192.168.7.26:5000 先在本机上查看已有的镜像 . $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE node latest f93ba6280cbd 3 weeks ago 667MB cockroachdb/cockroach latest 404f7ee26d38 4 weeks ago 163MB postgres latest ca3a55649cfc 7 weeks ago 269MB tomcat latest 0785a1d16826 7 weeks ago 367MB owncloud latest 2327c8d59618 8 weeks ago 572MB mysql latest e799c7f9ae9c 2 months ago 407MB 使用 docker tag 将 tomcat 这个镜像标记为 192.168.7.26：5000/test [root@vultr ~]# docker tag tomcat 192.168.7.26:5000/test [root@vultr ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE node latest f93ba6280cbd 3 weeks ago 667MB cockroachdb/cockroach latest 404f7ee26d38 4 weeks ago 163MB postgres latest ca3a55649cfc 7 weeks ago 269MB 192.168.7.26:5000/test latest 0785a1d16826 7 weeks ago 367MB tomcat latest 0785a1d16826 7 weeks ago 367MB owncloud latest 2327c8d59618 8 weeks ago 572MB mysql latest e799c7f9ae9c 2 months ago 407MB 用 docker push 上传标记的镜像 . $ docker push 192.168.7.26:5000/test The push refers to a repository [192.168.7.26:5000/test] (len: 1) Sending image list Pushing repository 192.168.7.26:5000/test (1 tags) Image 511136ea3c5a already pushed, skipping Image 9bad880da3d2 already pushed, skipping Image 25f11f5fb0cb already pushed, skipping Image ebc34468f71d already pushed, skipping Image 2318d26665ef already pushed, skipping Image ba5877dc9bec already pushed, skipping Pushing tag for rev [ba5877dc9bec] on {http://192.168.7.26:5000/ v1/repositories/test/tags/latest} 用 curl 查看仓库中的镜像 curl http://192.168.7.26:5000/v1/search {\"num_results\": 7, \"query\": \"\", \"results\": [{\"description\": \"\",\"name\": \"library/miaxis_j2ee\"}, {\"description\": \"\", \"name\": \"library/tomcat\"}, {\"description\": \"\", \"name\": \"library/ubuntu\"}, {\"description\": \"\", \"name\": \"library/ubuntu_office\"}, {\"description\": \"\", \"name\": \"library/desktop_ubu\"}, {\"description\": \"\", \"name\": \"dockerfile/ubuntu\"}, {\"description\": \"\", \"name\": \"library/test\"}]} 这里可以看到 {&quot;description&quot;: &quot;&quot;, &quot;name&quot;: &quot;library/test&quot;} ,表面镜像已经上传成功了 . 下载可以用另一台机器去下载这个镜像 . $ docker pull 192.168.7.26:5000/test Pulling repository 192.168.7.26:5000/test ba5877dc9bec: Download complete 511136ea3c5a: Download complete 9bad880da3d2: Download complete 25f11f5fb0cb: Download complete ebc34468f71d: Download complete 2318d26665ef: Download complete $ docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE 192.168.7.26:5000/test latest ba5877dc9bec 6 weeks ago 192.7 MB 仓库配置文件Docker 的 registry 利用配置文件提供 了一些仓库的模板（flavor）,用户可以直接使用它们来进行开发或身产环境 . 模板在 config_sample.yml 文件中,可以看到一些现成的模板段： common ：基础配置 local ：存储数据到本地文件系统 s3 ：存储数据到 AWS S3 中 dev ：使用 local 模板的基本配置 test ：单元测试使用 prod ：生产环境配置（基本上跟s3配置类似） gcs ：存储数据到 Google 的云存储 swift ：存储数据到 OpenStack Swift 服务 glance ：存储数据到 OpenStack Glance 服务,本地文件系统为后备 glance-swift：存储数据到 OpenStack Glance 服务,Swift 为后备 elliptics ：存储数据到 Elliptics key/value 存储 用户可以添加自定义的模板段 . 默认情况下使用的模板是 dev ,要是使用某个模板作为默认值,可以添加 SETTING-FLAVOR 到环境变量中去, export SETTING_FLAVOR=dev 另外,配置文件中支持从环境变量中加载,语法格式为 _env:VARIABLENAME[:DEFAULT] 示例配置common: loglevel: info search_backend: \"_env:SEARCH_BACKEND:\" sqlalchemy_index_database: \"_env:SQLALCHEMY_INDEX_DATABASE:sqlite:////tmp/docker-re gistry.db\" prod: loglevel: warn storage: s3 s3_access_key: _env:AWS_S3_ACCESS_KEY s3_secret_key: _env:AWS_S3_SECRET_KEY s3_bucket: _env:AWS_S3_BUCKET boto_bucket: _env:AWS_S3_BUCKET storage_path: /srv/docker smtp_host: localhost from_addr: docker@myself.com to_addr: my@myself.com dev: loglevel: debug storage: local storage_path: /home/myself/docker test: storage: local storage_path: /tmp/tmpdockertmp Docker 数据管理在容器管理中数据主要有两种方式： 数据卷 （Data volumes） 数据卷容器 （Data volume containers） 数据卷数据卷是一个可提供一个或多个容器使用的特殊目录,它绕过 UFS, 可以提供很多有用的特征： 数据卷可以再荣期间共享和重用 对数据卷的修改立马生效 对数据及的更新,不会影响镜像 数据卷默认会一直存在,即使容器被删除 注：数据卷的使用,类似于Linux 下对目录或文件进行 mount, 镜像中的被指定为挂载点的目录中的文件会隐藏掉,能显示看的是挂载的数据卷 创建一个数据卷​在使用 docker run 命令的时候,使用 -v 参数来创建一个数据卷并挂载到容器里 .在一次 run 中可以挂载多个数据卷 . 下面创建一个名为 web 的容器,并加载一个数据卷到容器的 /webapp 目录 . $ docker run -d -p --name web -v /webapp training/webapp python app.py 注：也可以在 Docker 中使用 volume 来添加一个或多个新的卷到有该镜像创建的任意容器 . 删除数据卷数据卷是被设计用来持久化数据的,它的生命周期独立于容器,Docker 不会在容器被删除后自动删除数据卷,并且也不存在垃圾回收这样的机制来处理没有任何容器引用的数据卷 .日光需要在删除容器的同时移除数据卷,可以再删除容器的时候使用 docker rm -v 这个命令 . 挂载一个主句目录作为数据卷使用 -v 参数也可以指定挂载一个本地主机的目录到容器中去 . $ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py ​ 上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp 目录 .这个功能在进行测试的时候十分方便,比如用户可以放置一些程序到本地目录中,来查看容器是否正常工作 .本地目录的路径必须是绝对路径,如果目录不存在 Docker会自动为你创建它 . 注：Dockerfile 中不支持这种用法,因为 Dockerfile 是为了移植和分享用的 . 然而,不同的操作系统的路径格式不一样,所以目前还不支持 Docker 挂载数据卷的默认权限是读写, 用户也可以通过 :ro 指定为只读 $ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py 加了 :ro 之后,就挂载为只读了 . 查看数据卷的具体信息在主机里使用以下命令可以查看指定容器的信息 $ docker inspect web ... 在输出的内容中找到其中和数据卷相关的部分,可以看到所有的数据卷都是创建在主句的 /var/lib/docker/volumes/ 下面的 \"Volumes\": { \"/webapp\": \"/var/lib/docker/volumes/fac362...80535\" }, \"VolumesRW\": { \"/webapp\": true } ... 注：从 Docker 1.8.0 起,数据卷配置在 “Mounts” Key 下面, 可以看到所有的数据卷都是创建在主机的 /mnt/sda1/var/lib/docker/volumes/... 下面了 . \"Mounts\": [ { \"Name\": \"b53ebd40054dae599faf7c9666acfe205c3e922 fc3e8bc3f2fd178ed788f1c29\", \"Source\": \"/mnt/sda1/var/lib/docker/volumes/b53e bd40054dae599faf7c9666acfe205c3e922fc3e8bc3f2fd178ed788f1c29/_data\", \"Destination\": \"/webapp\", \"Driver\": \"local\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"\" } ] ... 挂载一个本地主机文件作为数据卷-v 参数也可以从主机挂载单个文件到文件到容器中 $ sudo docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash 这样就可以记录在容器输入过得命令了 . 数据卷容器如果你有一些持续更新的数据需要在容器之间共享,最好创建数据卷容器 . 数据卷容器,其实就是一个正常的容器,专门用来提供数据卷供其他容器挂载的 . 首先,创建一个名为 dbdata 的数据卷容器： $ sudo docker run -d -v /dbdata --name dbdata training/postgres echo Data-only container for postgres 然后,在其他容器中使用 --volumes-from 来挂载 dbdata 容器中的数据卷 . $ sudo docker run -d --volumes-form dbdata --name db1 training/postgres $ sudo docker run -d --volumes-form dbdata --name db2 training/postgres 可以使用超过一个的--volumes-from 参数来指定从多个容器挂载不同的数据卷 . 也可以从其他已经挂载了数据卷的容器来级联挂载数据卷 . $ docker run -d --name db3 --volumes-from db1 training/postgres 注：使用 --volumes-from 参数所挂载数据卷的容器自己并不需要保持运行状态 如果删除了挂载的容器（包括 dbdata、db1 和 db2 ）,数据卷并不会被自动删除 .如果删除一个数据卷,必须在删除最后一个还挂着它的容器时使用 docker rm -v 命令来指定同时删除关联的容器 .这可以让用户在容器之间升级和移到数据卷 . 利用数据卷容器来备份、恢复、迁移数据卷可以利用数据卷对其中的数据进行备份、恢复和迁移 . 备份首先使用 --volumes-from 标记来创建一个加载 dbdata 数据卷的容器,并从主机挂载当前目录到容器的 /backup 目录 .命令如下： $ sudo docker run --volumes-from dbdata -v$(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata 容器启动后,使用了 tar 命令来将 dbdata 卷备份为容器中 /backup/backup.tar 文件,也就是主机当前目录下的名为 backup.tar 的文件 . 恢复如果要恢复数据到一个容器,首先创建一个带有空数据卷的容器 dbdata2 . $ docker run -v /dbdata --name dbdata2 ubuntu /bin/bash 然后创建另一个容器,挂载 dbdata2 容器卷中的数据卷,并使用 untar 解压备份文件到挂载的容器卷中 . $ sudo docker run --volumes-form dbdata2 -v $(pwd):/backup busybox tar xvf /backup/backup.tar 为了查看/验证恢复的数据,可以再启动一个容器挂载同样的容器卷来查看 $ docker run --volumes-from dbdata2 busybox /bin/ls dbdata 迁移数据卷代写 . . . Docker 中的网络Docker 允许通过外部访问容器或容器互联的方式来提供网络服务 . 外部访问容器容器中可以与运行一些网络应用,要让外部也可以访问这些应用,可以通过 -P 或 -p 参数来指定端口映射 . 当使用 -P 参数时,Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口 . 使用 docker ps 可以看到,本地主机的49155 被映射到了容器的5000 端口 . 此时访问本机的49155 端口即可访问容器内 web 应用提供的界面 . $ sudo docker run -d -P training/webapp python app.py $ sudo docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES bc533791f3f5 training/webapp:latest python app.py 5 seconds ag o Up 2 seconds 0.0.0.0:49155->5000/tcp nostalgic_morse -P （小写）则可以指定要映射的端口,并且在一个指定端口上只可以绑定一个容器 .支持的格式有 ip:HostPort:containerPort ip::containerPort hostPort:containerPort 映射所有接口地址使用 hostPort ：containerPort 格式本地的5000端口映射到容器的5000端口,可以执行 $ docker run -d -p 5000:5000 training/webapp python app.py 此时默认会绑定本地所有接口上的所有接口 . 映射到指定地址的指定端口可以使用 ip:hostPort:containerPort 格式指定映射使用一个特定地址,比如 localhost 地址 127.0.0.1 $ sudo docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py 查看映射端口配置使用 docker port 来查看当前映射的端口配置,也可以查看到绑定的地址 $ docker port gogs 22/tcp -> 0.0.0.0:10022 3000/tcp -> 0.0.0.0:10080 可以看到 gogs 有两个容器内的端口 22, 3000 分别映射主机的10022,10080 端口 . 注： -p 可以多次使用来绑定多个端口,也就是说一条命令可以有多个 -p ,如：上面👆的 gogs 容器就绑定了俩端口 容器互联容器的连接（linking）系统是除了端口映射外,另一种跟容器中应用交互的方式 .该系统会在源和接受容器之间创建一个通道,接受容器可以看到源容器指定的信息 . 自定义容器命名连接系统依据容器的名称来执行 .因此,首先需要自定义一个好记的容器命名 . 虽然创建容器的时候,系统默认会分配给一个名字 .但是自定义命名容器的话,第一,好记,第二,可以作为有用的参考的 . 使用 --name 参数可以为容器自定义命名 . $ docker run -d -p 8181:4040 --name own-cloud owncloud 使用 docker ps 来查看正运行的容器 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2c2e766e86fd owncloud \"/entrypoint.sh ap...\" 23 hours ago Up 23 hours 80/tcp, 0.0.0.0:8181->4040/tcp own-cloud 使用 docker inspect 命令来查看容器名字 $ docker inspect -f \"{{.Name}}\" 2c2e766e86fd /own-cloud 注：容器的名称是唯一的 .如果已经命名了一个叫 own-cloud 的容器,当你再次使用这个名词的时候,需要先把之前的的同名容器删除 tips：在执行 docker run 的时候可以添加 —rm 参数,这样容器在终止后立刻删除 .注意,—rm 和 -d 参数不能同时使用 . 容器互联使用 --link 参数可以让容器之间安全的进行交互 . 下面是,运行 Nginx 容器的时候把 gogs 这个容器连接上 docker run -d --name my_nginx --link gogs:app --link own-cloud:app2 -p 80:80 -v /root/nginx/config:/etc/nginx/conf.d nginx 此时,gogs 容器和 my_nginx 容器建立互联关系 --link 参数的格式为 --link name:alias ,其中 name 是要连接的容器名称, alias 是这个连接的别名 . 可以通过 docker inspect 命令查看 my_nginx 容器信息,就会发现有这么一段信息 \"Links\": [ \"/gogs:/trusting_brown/app\", \"/own-cloud:/trusting_brown/app2\" ], 表面此容器已经连上两个容器, gogs 和 own-cloud,trusting_brown 是系统分配给 Nginx 的名称,连接名称分别是 app 和 app2 . Docker 在两个互联的容器之间创建了一个安全的隧道,而且不用映射到它们的端口到主机上 .在启动被连接的容器的时候不用添加 -p 或 -P 参数,从而避免暴露端口到外部网络上 . 连接之后,在 Nginx 容器里,就会发生两个变化 . 一是环境变量 .在 Nginx 容器中会出现6个新增的环境变量,这些环境变量的名称分贝时由被连接的服务别名、端口等拼接而成的 . 由于起得 gogs 容器有两个端口,所以其中 APP_PORT、APP_NAME、APP_ENV_GOGS_CUSTOM 是公用的,其它8个变量每四个的分别对应22, 3000 端口 # env | grep APP APP_PORT_3000_TCP=tcp://172.17.0.2:3000 APP_PORT_22_TCP_PROTO=tcp APP_ENV_GOGS_CUSTOM=/data/gogs APP_PORT_3000_TCP_ADDR=172.17.0.2 APP_PORT_3000_TCP_PROTO=tcp APP_PORT_22_TCP_PORT=22 APP_PORT_3000_TCP_PORT=3000 APP_PORT=tcp://172.17.0.2:22 APP_NAME=/my_nginx/app APP_PORT_22_TCP=tcp://172.17.0.2:22 APP_PORT_22_TCP_ADDR=172.17.0.2 二是 hosts 文件 .在 Nginx 容器的 hosts 文件看到下面的记录 .这就是说,一切访问 连接别名（app）、容器 ID（ac4c0cf35adf）和容器名（gogs）的请求都会被重新导向到实时实际的 app 的 ip 地址上 . # cat /etc/hosts | grep app 172.17.0.2 app ac4c0cf35adf gogs 高级网络配置当 Docker 启动时,会自动的主机上创建一个 docker0 虚拟网桥,实际上是 Linux 的一个 bridge,可以理解为一个软件交换机 .它会挂载到它的网口之间进行转发 . $ ip addr | grep docker0 docker0: mtu 1500 qdisc noqueue state UP link/ether 02:42:23:c6:3f:1c brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:23ff:fec6:3f1c/64 scope link valid_lft forever preferred_lft forever 同时,Docker 随机分一个本地未占用的私有网段（在 RFC1919 中定义）中的一个地址给 docker0 接口 .比如我的主机上的 docker0 ip 为 172.17.0.1 ,掩码为 255.255.0.0 .此后启动的容器内的网口也会自动分配有个一个同一网段（172.17.0.0/16）的地址 . 当创建一个 Docker 容器的时候,同时会创建一对 vath pair 接口（当数据包发送到一个接口,另一个接口也可以收到相同的数据包） .这对接口一段在容器内,即 eth0 ；另一端在本地并挂载到 docker0 网桥,名称以 veth 开头 .通过这种方式,主机可以跟容器通信,容器之间也可以相互通信 . Docker 就创建了在主机和所有容器之间一个虚拟共享网络 . ​ 图 i.i docker 网络 接下来部分将介绍在一些场景中,Docker 所有的网络定制配置 .以及通过 Linux 命令来调整、补充、甚至替换 Docker 默认的网络配置 . 快速配置下面是一个跟 Docker 网络相关的命令列表 . 其中有些命令选项只有在 Docker 服务启动的时候才能配置,而且不能马上生效 . -b BRIDGE or --bridge==BRIDGE –指定容器挂载的网桥 --bip=CIDR — 定制 docker0 的掩码 -H SOCKET... or --host=SOCKET… —Docker 服务端接受命令的通道 --icc=true|false –是否支持容器之间进行通信 --ip-forward=true|false —容器是否能访问外网（详细解析请看下文的容器通信） --iptables=true|false –是否允许 Docker 添加 iptables 规则 --mtu=BYTES —容器网络中的 MTU 下面的两个命令既可以在服务启动时指定,也可以 Docker 容器启动（docker run ）时候指定 . 在 Docker 服务启动的时候指定则会成为默认值,后面执行docker run时可以覆盖设置的默认值 . --dns=IP_ADDRESS… —使用指定的 DNS 服务器 --dns-search=DOMAIN... 指定 DNS 搜索域 最后这些选项只有在 docker run 执行时使用,因为它是针对容器的特性内容 . -h HOSTNAME or --hostname=HOSTNAME –配置容器主机名 --link=CONRATAINER_NAME:ALIAS —添加到另一个容器的连接","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://yusank.github.io/categories/技术/"}],"tags":[]},{"title":"docker-portainer","slug":"portainer","date":"2017-07-08T04:18:00.000Z","updated":"2017-07-08T05:27:01.000Z","comments":true,"path":"portainer.html/","link":"","permalink":"http://yusank.github.io/portainer.html/","excerpt":"安利一款很好用的工具","text":"安利一款很好用的工具 管理 docker为什么管理随着用的 docker 镜像种类增多，在一台机器上起得 docker 容器数量有时候会非常的多，管理起来也比较困难，而且有时候一些 docker 命令一时半会想不起来，更不用说命令行的枯燥性，所以有没有一直简单一点\b办法去管理 docker 镜像和容器呢？ 今天主角该登场了！ Portainer 这也是一个 docker 镜像，是可视化管理 docker 镜像和容器的镜像。 效果说的比较绕，不说废话，先上图： Dashboard: 其前端是网页，容器启动以后，在浏览器输入主机名:端口号后，第一打开此页面需要设置管理员密码，设置完毕之后，登录进入后，会看到上面的页面。 左边是选择菜单，右半部是显示你主机的基本信息和 docker 的基本信息，有多少个镜像，运行着几个容器等。 下面，从上到下一个个点击左边的菜单。 App Templates 可以搜索查看并能一键下载（pull）镜像 Containers 显示所有的容器，并支持多个容器同时启动、停止、重启、删除，容器添加等操作。是所有的容器都可以点开查看更详细的信息。 Images 可以查看本机所有的镜像。支持批量删除镜像，根据名字下载镜像，选择镜像仓库。点击任意镜像，可以查看进行详细信息。 Networks 查看 docker 内部网络情况。支持添加和删除网络连接。 Volums 数据卷。支持查看所有的数据卷，批量删除，添加新数据卷，查看详细信息。 Events 事件。这是类似于日志系统，记录容器和镜像的启动、停止删除等操作。 Docker 查看 docker 有关的详细信息，类似于命令行上的 docker info命令的结果。 EndPoint 查看管理的节点。可以添加多个节点，从而可以同时管理多个机器上的 docker。通过左上角的下拉框，选择要管理的 docker 节点即可。 安装首先通过 docker 命令 pull 此镜像： docker pull portainer/portainer 下载完成之后，通过以下名可以启动容器了： docker run -d -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer 注：-v 选项只对 Linux 环境有效 现在你可以在浏览器输入 localhost:9000 就能访问 portainer 去管理你的 docker了。 关于如何远程管理 docker，请看官方文档，在这儿不做详述。 portaner github：https://github.com/portainer/portainer","raw":null,"content":null,"categories":[],"tags":[]},{"title":"GO interface","slug":"Go_interface","date":"2017-06-08T07:07:00.000Z","updated":"2017-06-08T07:07:01.000Z","comments":true,"path":"Go_interface.html/","link":"","permalink":"http://yusank.github.io/Go_interface.html/","excerpt":"","text":"Go interfaceinterface在 Golang 中 interface 是一个很重要的概念和特性。 什么是 interface？ In object-oriented programming, a protocol or interface is a common means for unrelated objects) to communicate with each other. These are definitions of methods) and values which the objects agree upon in order to co-operate. — wikipedia 这是 wikipedia 关于 protocal 的定义，将 interface 类比如 protocal 是一种非常助于理解的方式。protocol，中文一般叫做协议，比如网络传输中的 TCP 协议。protocol 可以认为是一种双方为了交流而做出的约定，interface 可以类比如此。 在 Golang 中，interface 是一种抽象类型，相对于抽象类型的是具体类型（concrete type）：int，string。如下是 io 包里面的例子。 // Writer is the interface that wraps the basic Write method. // // Write writes len(p) bytes from p to the underlying data stream. // It returns the number of bytes written from p (0 &lt;= n &lt;= len(p)) // and any error encountered that caused the write to stop early. // Write must return a non-nil error if it returns n &lt; len(p). // Write must not modify the slice data, even temporarily. // // Implementations must not retain p. type Writer interface { Write(p []byte) (n int, err error) } // Closer is the interface that wraps the basic Close method. // // The behavior of Close after the first call is undefined. // Specific implementations may document their own behavior. type Closer interface { Close() error } 在 Golang 中，interface 是一组 method 的集合，是 duck-type programming (鸭子类型)的一种体现。不关心属性（数据），只关心行为（方法）。具体使用中你可以自定义自己的 struct，并提供特定的 interface 里面的 method 就可以把它当成 interface 来使用。下面是一种 interface 的典型用法，定义函数的时候参数定义成 interface，调用函数的时候就可以做到非常的灵活。 type MyInterface interface{ Print() } func TestFunc(x MyInterface) {} type MyStruct struct {} func (me MyStruct) Print() {} func main() { var me MyStruct TestFunc(me) } 为什么 interfaceGopher China 上给出了下面的三个理由： writing generic algorithm （泛型编程） hiding implementation detail （隐藏具体实现） providing interception points （提供监听点/拦截点？） write generic algorithm严格来说，在 Golang 中并不支持泛型编程。在 C++ 等高级语言中使用泛型编程非常的简单，所以泛型编程一直是 Golang 诟病最多的地方。但是使用 interface 我们可以实现泛型编程，我这里简单说一下，具体可以参考我前面给出来的那篇文章。比如我们现在要写一个泛型算法，形参定义采用 interface 就可以了，以标准库的 sort 为例。 package sort // A type, typically a collection, that satisfies sort.Interface can be // sorted by the routines in this package. The methods require that the // elements of the collection be enumerated by an integer index. type Interface interface { // Len is the number of elements in the collection. Len() int // Less reports whether the element with // index i should sort before the element with index j. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int) } ... // Sort sorts data. // It makes one call to data.Len to determine n, and O(n*log(n)) calls to // data.Less and data.Swap. The sort is not guaranteed to be stable. func Sort(data Interface) { // Switch to heapsort if depth of 2*ceil(lg(n+1)) is reached. n := data.Len() maxDepth := 0 for i := n; i > 0; i >>= 1 { maxDepth++ } maxDepth *= 2 quickSort(data, 0, n, maxDepth) } Sort 函数的形参是一个 interface，包含了三个方法：Len()，Less(i,j int)，Swap(i, j int)。使用的时候不管数组的元素类型是什么类型（int, float, string…），只要我们实现了这三个方法就可以使用 Sort 函数，这样就实现了“泛型编程”。有一点比较麻烦的是，我们需要将数组自定义一下。下面是一个例子。 type Person struct { Name string Age int } func (p Person) String() string { return fmt.Sprintf(\"%s: %d\", p.Name, p.Age) } // ByAge implements sort.Interface for []Person based on // the Age field. type ByAge []Person //自定义 func (a ByAge) Len() int { return len(a) } func (a ByAge) Swap(i, j int) { a[i], a[j] = a[j], a[i] } func (a ByAge) Less(i, j int) bool { return a[i].Age &lt; a[j].Age } func main() { people := []Person{ {\"Bob\", 31}, {\"John\", 42}, {\"Michael\", 17}, {\"Jenny\", 26}, } fmt.Println(people) sort.Sort(ByAge(people)) fmt.Println(people) } 另外 Gopher China 上还提到了一个比较有趣的东西和大家分享一下。在我们设计函数的时候，下面是一个比较好的准则。 Be conservative in what you send, be liberal in what you accept. — Robustness Principle 对应到 Golang 就是： Return concrete types, receive interfaces as parameter. — Robustness Principle applied to Go 话说这么说，但是当我们翻阅 Golang 源码的时候，有些函数的返回值也是 interface。 hiding implement detail隐藏具体实现，这个很好理解。比如我设计一个函数给你返回一个 interface，那么你只能通过 interface 里面的方法来做一些操作，但是内部的具体实现是完全不知道的。Francesc 举了个 context 的例子。 context 最先由 google 提供，现在已经纳入了标准库，而且在原有 context 的基础上增加了：cancelCtx，timerCtx，valueCtx。语言的表达有时候略显苍白无力，看一下 context 包的代码吧。 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { c := newCancelCtx(parent) propagateCancel(parent, &amp;c) return &amp;c, func() { c.cancel(true, Canceled) } } 表明上 WithCancel 函数返回的还是一个 Context interface，但是这个 interface 的具体实现是 cancelCtx struct。 // newCancelCtx returns an initialized cancelCtx. func newCancelCtx(parent Context) cancelCtx { return cancelCtx{ Context: parent, done: make(chan struct{}), } } // A cancelCtx can be canceled. When canceled, it also cancels any children // that implement canceler. type cancelCtx struct { Context //注意一下这个地方 done chan struct{} // closed by the first cancel call. mu sync.Mutex children map[canceler]struct{} // set to nil by the first cancel call err error // set to non-nil by the first cancel call } func (c *cancelCtx) Done() &lt;-chan struct{} { return c.done } func (c *cancelCtx) Err() error { c.mu.Lock() defer c.mu.Unlock() return c.err } func (c *cancelCtx) String() string { return fmt.Sprintf(\"%v.WithCancel\", c.Context) } 尽管内部实现上下面三个函数返回的具体 struct （都实现了 Context interface）不同，但是对于使用者来说是完全无感知的。 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) //返回 cancelCtx func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) //返回 timerCtx func WithValue(parent Context, key, val interface{}) Context //返回 valueCtx providing interception points这里的 interception 想表达的意思应该是 wrapper 或者装饰器，他给出了一个例子如下： type header struct { rt http.RoundTripper v map[string]string } func (h header) RoundTrip(r *http.Request) *http.Response { for k, v := range h.v { r.Header.Set(k,v) } return h.rt.RoundTrip(r) } 通过 interface，我们可以通过类似这种方式实现动态分配 (dynamic dispatch)。 非侵入式什么是侵入式呢？比如 Java 的 interface 实现需要显示的声明。 public class MyWriter implements io.Writer {} 这样就意味着如果要实现多个 interface 需要显示地写很多遍，同时 package 的依赖还需要进行管理。Dependency is evil。比如我要实现 io 包里面的 Reader，Writer，ReadWriter 接口，代码可以像下面这样写。 type MyIO struct {} func (io *MyIO) Read(p []byte) (n int, err error) {...} func (io *MyIO) Write(p []byte) (n int, err error) {...} // io package type Reader interface { Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) } type ReadWriter interface { Reader Writer } 这种写法真的很方便，而且不用去显示的 import io package，interface 底层实现的时候会动态的检测。这样也会引入一些问题： 性能下降。使用 interface 作为函数参数，runtime 的时候会动态的确定行为。而使用 struct 作为参数，编译期间就可以确定了。 不知道 struct 实现哪些 interface。这个问题可以使用 guru 工具来解决。 综上，Golang interface 的这种非侵入实现真的很难说它是好，还是坏。但是可以肯定的一点是，对开发人员来说代码写起来更简单了。 interface type assertioninterface 像其他类型转换的时候一般我们称作断言，举个例子。 func do(v interface{}) { n := v.(int) // might panic } 这样写的坏处在于：一旦断言失败，程序将会 panic。一种避免 panic 的写法是使用 type assertion。 func do(v interface{}) { n, ok := v.(int) if !ok { // 断言失败处理 } } 对于 interface 的操作可以使用 reflect 包来处理，关于 reflect 包的原理和使用可以参考我的文章。 总结interface 是 Golang 的一种重要的特性，但是这是以 runtime 为代价的，也就意味着性能的损失（关于 interface 的底层实现之后有时间再写）。抛开性能不谈，interface 对于如何设计我们的代码确实给了一个很好的思考。 参考 Golang “泛型编程” 谈一谈 Golang 的 interface 和 reflect understanding golang interface(Gopher China) — youtube understanding golang interface(Gopher China) — slide","raw":null,"content":null,"categories":[],"tags":[]},{"title":"GO test","slug":"go-test","date":"2017-06-01T07:07:00.000Z","updated":"2017-06-01T07:07:01.000Z","comments":true,"path":"go-test.html/","link":"","permalink":"http://yusank.github.io/go-test.html/","excerpt":"","text":"Go 测试用例开发程序其中很重要的一点是测试，我们如何保证代码的质量，如何保证每个函数是可运行，运行结果是正确的，又如何保证写出来的代码性能是好的，我们知道单元测试的重点在于发现程序设计或实现的逻辑错误，使问题及早暴露，便于问题的定位解决，而性能测试的重点在于发现程序设计上的一些问题，让线上的程序能够在高并发的情况下还能保持稳定。本小节将带着这一连串的问题来讲解Go语言中如何来实现单元测试和性能测试。 Go语言中自带有一个轻量级的测试框架testing和自带的go test命令来实现单元测试和性能测试，testing框架和其他语言中的测试框架类似，你可以基于这个框架写针对相应函数的测试用例，也可以基于该框架写相应的压力测试用例，那么接下来让我们一一来看一下怎么写。 另外建议安装gotests插件自动生成测试代码: go get -u -v github.com/cweill/gotests/... 如何编写测试用例由于go test命令只能在一个相应的目录下执行所有文件，所以我们接下来新建一个项目目录gotest,这样我们所有的代码和测试代码都在这个目录下。 接下来我们在该目录下面创建两个文件：gotest.go和gotest_test.go gotest.go:这个文件里面我们是创建了一个包，里面有一个函数实现了除法运算: ```Gopackage gotest import ( “errors”) func Division(a, b float64) (float64, error) { if b == 0 { return 0, errors.New(“除数不能为0”) } return a / b, nil } 2. gotest_test.go:这是我们的单元测试文件，但是记住下面的这些原则： - 文件名必须是`_test.go`结尾的，这样在执行`go test`的时候才会执行到相应的代码 - 你必须import `testing`这个包 - 所有的测试用例函数必须是`Test`开头 - 测试用例会按照源代码中写的顺序依次执行 - 测试函数`TestXxx()`的参数是`testing.T`，我们可以使用该类型来记录错误或者是测试状态 - 测试格式：`func TestXxx (t *testing.T)`,`Xxx`部分可以为任意的字母数字的组合，但是首字母不能是小写字母[a-z]，例如`Testintdiv`是错误的函数名。 - 函数中通过调用`testing.T`的`Error`, `Errorf`, `FailNow`, `Fatal`, `FatalIf`方法，说明测试不通过，调用`Log`方法用来记录测试的信息。 下面是我们的测试用例的代码： ```Go package gotest import ( &quot;testing&quot; ) func Test_Division_1(t *testing.T) { if i, e := Division(6, 2); i != 3 || e != nil { //try a unit test on function t.Error(&quot;除法函数测试没通过&quot;) // 如果不是如预期的那么就报错 } else { t.Log(&quot;第一个测试通过了&quot;) //记录一些你期望记录的信息 } } func Test_Division_2(t *testing.T) { t.Error(&quot;就是不通过&quot;) } 我们在项目目录下面执行go test,就会显示如下信息： --- FAIL: Test_Division_2 (0.00 seconds) gotest_test.go:16: 就是不通过 FAIL exit status 1 FAIL gotest 0.013s 从这个结果显示测试没有通过，因为在第二个测试函数中我们写死了测试不通过的代码t.Error，那么我们的第一个函数执行的情况怎么样呢？默认情况下执行go test是不会显示测试通过的信息的，我们需要带上参数go test -v，这样就会显示如下信息： === RUN Test_Division_1 --- PASS: Test_Division_1 (0.00 seconds) gotest_test.go:11: 第一个测试通过了 === RUN Test_Division_2 --- FAIL: Test_Division_2 (0.00 seconds) gotest_test.go:16: 就是不通过 FAIL exit status 1 FAIL gotest 0.012s 上面的输出详细的展示了这个测试的过程，我们看到测试函数1Test_Division_1测试通过，而测试函数2Test_Division_2测试失败了，最后得出结论测试不通过。接下来我们把测试函数2修改成如下代码： func Test_Division_2(t *testing.T) { if _, e := Division(6, 0); e == nil { //try a unit test on function t.Error(\"Division did not work as expected.\") // 如果不是如预期的那么就报错 } else { t.Log(\"one test passed.\", e) //记录一些你期望记录的信息 } } 然后我们执行go test -v，就显示如下信息，测试通过了： === RUN Test_Division_1 --- PASS: Test_Division_1 (0.00 seconds) gotest_test.go:11: 第一个测试通过了 === RUN Test_Division_2 --- PASS: Test_Division_2 (0.00 seconds) gotest_test.go:20: one test passed. 除数不能为0 PASS ok gotest 0.013s 如何编写压力测试压力测试用来检测函数(方法）的性能，和编写单元功能测试的方法类似,此处不再赘述，但需要注意以下几点： 压力测试用例必须遵循如下格式，其中XXX可以是任意字母数字的组合，但是首字母不能是小写字母 func BenchmarkXXX(b *testing.B) { ... } go test不会默认执行压力测试的函数，如果要执行压力测试需要带上参数-test.bench，语法:-test.bench=&quot;test_name_regex&quot;,例如go test -test.bench=&quot;.*&quot;表示测试全部的压力测试函数 在压力测试用例中,请记得在循环体内使用testing.B.N,以使测试可以正常的运行 文件名也必须以_test.go结尾 下面我们新建一个压力测试文件webbench_test.go，代码如下所示： package gotest import ( \"testing\" ) func Benchmark_Division(b *testing.B) { for i := 0; i 我们执行命令go test -file webbench_test.go -test.bench=&quot;.*&quot;，可以看到如下结果： PASS Benchmark_Division 500000000 7.76 ns/op Benchmark_TimeConsumingFunction 500000000 7.80 ns/op ok gotest 9.364s 上面的结果显示我们没有执行任何TestXXX的单元测试函数，显示的结果只执行了压力测试函数，第一条显示了Benchmark_Division执行了500000000次，每次的执行平均时间是7.76纳秒，第二条显示了Benchmark_TimeConsumingFunction执行了500000000，每次的平均执行时间是7.80纳秒。最后一条显示总共的执行时间。 小结通过上面对单元测试和压力测试的学习，我们可以看到testing包很轻量，编写单元测试和压力测试用例非常简单，配合内置的go test命令就可以非常方便的进行测试，这样在我们每次修改完代码,执行一下go test就可以简单的完成回归测试了。","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Unix 网络编程","slug":"Unix-Network","date":"2017-04-22T08:52:00.000Z","updated":"2017-04-22T08:52:01.000Z","comments":true,"path":"Unix-Network.html/","link":"","permalink":"http://yusank.github.io/Unix-Network.html/","excerpt":"","text":"Unix 网络编程​ 卷II - 进程间通信 IPC是进程间通信（interprocess communication）的简称。传统上该术语描述的是运行在某个操作系统之上的不同进程间各种消息传递（message passing）的方式。 进程间的通信一般是一下四种形式： 消息传递（管道、FIFO和消息队列）； 同步（互斥量、条件变量、读写锁、文件和记录锁、信号量）； 共享内存（匿名的和具名的）； 远程过程调用（Solaris 门和 Sun RPC）。 消息队列消息传递： 管道和FIFO； Posix 消息队列； System V消息队列。 管道和FIFO管道是最初的Unix IPC 形式。由于管道没有名字，所以它只能用于有亲缘关系的进程间的通信。 实现机制： 管道是由内核管理的一个缓冲区，相当于我们放入内存中的一个纸条。管道的一端连接一个进程的输出。这个进程会向管道中放入信息。管道的另一端连接一个进程的输入，这个进程取出被放入管道的信息。一个缓冲区不需要很大，它被设计成为环形的数据结构，以便管道可以被循环利用。当管道中没有信息的话，从管道中读取的进程会等待，直到另一端的进程放入信息。当管道被放满信息的时候，尝试放入信息的进程会等待，直到另一端的进程取出信息。当两个进程都终结的时候，管道也自动消失。 #include &lt;unistd.h> int pipe (int fd[2]) //返回：若成功返回0，若出错返回-1 该函数返回两个文件描述符：fd[0] 和 fd[1]。前者打开来读，后者打开来写。 管道尽管是单个进程创建，但是管道的典型用途是为两个不同的进程（一个父进程，一个子进程）提供进程间的通信手段。 ​ 数据流 &gt;&gt;&gt;&gt;&gt;&gt; 首先是，由一个进程（它将成为父进程）创建一个 pipe 后调用 fork 派生一个自身的副本，接着关闭着个 pipe 的读成端，子进程关闭同一个 pipe 的写入端。这就是进程间提供了一个单向数据流，如下图。 int main(void) { int n; int fd[2]; pid_t pid; char line[MAXLINE]; if(pipe(fd) === 0){ // 先建立管道得到一对文件描述符 exit(0); } if((pid = fork()) == 0) // 父进程把文件描述符复制给子进程 exit(1); else if(pid > 0){ // 父进程写 close(fd[0]); // 关闭读描述符 write(fd[1], \"\\nhello world\\n\", 14); } else{ // 子进程读 close(fd[1]); // 关闭写端 n = read(fd[0], line, MAXLINE); write(STDOUT_FILENO, line, n); } exit(0); } technically，自从可以在进程间传递描述符后，管道也能用于无亲缘关系的进程间，而现实中管道通常用于具有共同祖先的进程间。 FIFO：命名管道(named PIPE) 管道尽管对很多操作来说是很有用的，但是它的根本局限性在于没有名字，从而只能由亲缘关系的进程（父子进程）使用。为了解决这一问题，Linux提供了FIFO方式连接进程。有了FIFO之后这一缺点得以改正。FIFO有时也称之为有名管道（named pipe）。FIFO除了有管道的功能外，它还允许无亲缘关系的进程的通信。pipe 和 FIFO 都是使用通常的 read 和 write 函数访问的。 FIFO (First in, First out)为一种特殊的文件类型，它在文件系统中有对应的路径。当一个进程以读(r)的方式打开该文件，而另一个进程以写(w)的方式打开该文件，那么内核就会在这两个进程之间建立管道，所以FIFO实际上也由内核管理，不与硬盘打交道。之所以叫FIFO，是因为管道本质上是一个先进先出的队列数据结构，最早放入的数据被最先读出来，从而保证信息交流的顺序。FIFO只是借用了文件系统(file system,命名管道是一种特殊类型的文件，因为Linux中所有事物都是文件，它在文件系统中以文件名的形式存在。)来为管道命名。写模式的进程向FIFO文件中写入，而读模式的进程从FIFO文件中读出。当删除FIFO文件时，管道连接也随之消失。FIFO的好处在于我们可以通过文件的路径来识别管道，从而让没有亲缘关系的进程之间建立连接 #include &lt;sys/types.h> #include &lt;sys/stat.h> int mkfifo (const char *pathname, mode_t mode); // 返回： 成功返回0，出错返回 -1 其中 pathname 是一个普通的 Unix 路径名，它是该 FIFO 的名字。 mkfifo 函数中参数 mode 指定 FIFO 的读写权限。 mkfifo 函数是要么创建一个新的 FIFO ，要么返回一个 EEXIST 错误（如果该 FIFO 已存在），如果不希望创建一个新的 FIFO 那就用 open 函数就可以。 FIFO 不能打开既写又读。 如果一个 FIFO 只读不写，只写不读都会形成阻塞。 下边是一个简单地例子： #include &lt;stdio.h> #include &lt;stdlib.h> #include &lt;sys/types.h> #include &lt;sys/stat.h> # define FIFO1 \"/tmp/my_fifo\" int main() { int res = mkfifo(\"/tmp/my_fifo\", 0777); if (res == 0) { printf(\"FIFO created/n\"); } // 打开FIFO //writefd = Open(FIFO1, O_WRONLY | O_NONBLOCK, 0) //readfd = Open(FIFO1, O_RDONLY, 0) exit(EXIT_SUCCESS); } open 第二个参数中的选项O_NONBLOCK，选项O_NONBLOCK表示非阻塞，加上这个选项后，表示open调用是非阻塞的，如果没有这个选项，则表示open调用是阻塞的。 对于以只读方式（O_RDONLY）打开的FIFO文件，如果open调用是阻塞的（即第二个参数为O_RDONLY），除非有一个进程以写方式打开同一个FIFO，否则它不会返回；如果open调用是非阻塞的的（即第二个参数为O_RDONLY|O_NONBLOCK），则即使没有其他进程以写方式打开同一个FIFO文件，open调用将成功并立即返回。 对于以只写方式（O_WRONLY）打开的FIFO文件，如果open调用是阻塞的（即第二个参数为O_WRONLY），open调用将被阻塞，直到有一个进程以只读方式打开同一个FIFO文件为止；如果open调用是非阻塞的（即第二个参数为O_WRONLY|O_NONBLOCK），open总会立即返回，但如果没有其他进程以只读方式打开同一个FIFO文件，open调用将返回-1，并且FIFO也不会被打开。 关于管道或 FIFO 的读写的若干规则： 如果请求读出的数据量多于管道或 FIFO 中当前的可用数据量，那么只会返回这些可用的数据。 如果请求你写入的数据的字节数小于或等于 PIPE_BUF (可原子地写入往一个管道或 FIFO 的最大数据量， Posix 要求至少为512)，那么 write 操作保证是原子的。这意味着，如果两个进程差不多同时往同一个管道或 FIFO 写，那么不管是先写入来自第一个进程的所有数据再写第二个，还是顺序颠倒过来。系统都不会相互混杂来自两个进程的数据。然而如果数据的字节数大于 PIPE_BUF ，那么 write 操作不能保证是原子的。 不止以上这些。。。 小结： FIFO 与管道类似，但是它用 mkfifo 创建，之后需要open 打开。打开管道必须小心，因为许多规则（read 只写管道、write 只读管道、从空的管道或FIFO read 等的情况的返回结果。）制约着 open 的阻塞与否。 Posix IPCPosix–可移植性操作系统接口（Protable operating system interface） 有关Unix标准化的大多数活动是由 Posix 和 Open Group 做的。 Posix 不是单一的标准，是一系列的标准。 以下三种类型的IPC合成为“Posix IPC” Posix 消息队列 Posix 信号量 Posix 共享内存区 Posix 消息队列消息队列可认为是个消息链表。有足够写权限的进程可往队列放置信息，有足够读权限的进程可从队列读取信息。每一个信息都是一条记录，它是由发送者赋予一个优先级。在某个进程往一个队列写入消息之前，并不需要另一个进程在该队列上等待消息的到达。这根管道和 FIFO 是相反的。 一个进程可以往某些队列写入一些信息，然后终止，再让另外一个进程在以后的某个时刻读取这些信息。 Posix 消息队列和下面讲的System V 消息队列有许多的相似性。以下是主要的差别： 对 Posix 消息队列的读总是返回最高优先级的最早消息，对 System V 消息队列的读则可以返回任意指定优先级的消息； 当往一个空队列放置一个信息时，Posix 消息队列允许产生一个信号或启动一个线程，System V消息队列则是不提供类似的机制。 队列中的每一个消息都有如下属性： 一个无符号整数优先级（Posix）或 一个长整数类型（system V）； 消息的数据部分长度（可以为0）； 数据本身（如果长度大于0）。 一个消息队列的可能布局。 我们所设想的是一个链表，该链表的有中含有当前队列的两个属性：队列中允许的最大开销数以及每一个消息的最大大小。 mq_open ,mq_close 和 mq_unlink 函数 ： mq_open 函数创建一个新的消息队列或打开一个已存在的消息队列。 # include &lt;mqueue.h> mqd_t mq_open (const char *name, int oflag, ... /* mode_t mode, struct mq_attr *attr */); //返回： 成功返回消息对列描述符，出错返回-1 其中 name 有自己的一套命名规则，因为 Posix IPC 使用“Posix IPC 名字”进行标识。为方便于移植起见，Posix IPC 名字必须以斜杠符开头并且不能再包含任何斜杠符。 oflag 是O_RDONLY、O_WRONLY 或 O_RDWR 之一， 可能按位或上O_CREATE(若不存在则创建)、O_EXCL(与O_CREATE一起，若已存在返回EEXIST 错误)或 O_NONBLOCK（非阻塞标识符）。 当实际操作创建一个新的消息队列时（指定O_CREATE标志，且请求的队列不存在），mode 和 attr 参数是需要的。mode上面介绍过。attr参数用于给新队列指定某些属性。 mq_open 返回值称为消息队列描述符（message queue descriptor），这个值用作其他消息队列函数的第一参数。 已打开的消息队列是由 mq_close 关闭的。 #include &lt;mqueue.h> int mq_close(mqd_t mqdes) //返回： 成功返回0，出错返回-1 关闭之后调用进程不再使用该描述符，但其消息队列并不从系统中删除。一个进程终止时，它打开着的消息队列都关闭，就像调用mq_close 一样。 要从系统中删除消息队列则用mq_unlink 函数，其第一参数为 mq_open 的第一参数 name。 # include &lt;mqueue.h> int mq_unlink(const char *name) //返回： 成功返回0，出错返回-1 mq_getattr 和 mq_setattr 函数 消息队列有四个属性，这两个函数是获取和修改这些属性。 mq_flags //队列阻塞标志位 mq_maxmsg //队列最大允许消息数 mq_msgsize //队列消息最大字节数 mq_curmsgs //队列当前消息条数 #include &lt;mqueue.h> int mq_getattr(mqd_t mqdes,struct mq_attr *attr); int mq_setattr(mqd_t mqdes,const struct mq_attr *attr, struct mq_attr *oattr); //返回：均成功返回0，出错返回-1 mq_send 和 mq_receive 函数 ​ 这两个函数分别往一个队列放置一个信息和从一个队列取走一个消息。每一个消息都有优先级，它是一个小于MQ_PRIO_MAX 的无符号整数。Posix要求这个上限至少为32. ​ mq_receive 总是返回所指定队列中优先级最高的的最早消息，而且该优先级能随该消息的内容及其长度一同返回。 #include &lt;mqueue.h> int mq_send(mqd_t mqdes, const char *ptr, size_t len, unsigned int prio); //返回： 成功返回0，出错返回-1 ssize_t mq_reccevie(mqd_t mqdes, char *ptr, size_t len, unsigned int *priop); //返回： 成功返回消息中的字节数，出错返回-1 mq_receive 的 len 参数的值不能小于能加到所指定队列中的最大大小（该队列 mq_attr 结构的 mq_msgsize ）。要是 len 小于该值， mq_receive立即返回 EMSGSIZE 错误。 mq_send 的 prio 参数是待发信息的优先级，其值必须小于 MQ_PRIO_MAX 。如果 mq_receive 的 priop 参数是一个非空指针，所返回消息的优先级就通过该指针存放。如果应用不必使用优先级不同的消息，那就给mq_send 指针值为0的优先级，给 mq_receive 指定一个空指针作为其最后一个参数。 往某个队列中增加一个消息 #include &lt;mqueue.h> int main(int argc, char **argv) { mqd_t mqd; //描述符 void *ptr; //指向缓冲区的指针 size_t len; //长度 uint_t prio; //优先度 if (argc != 4) err_quit(\"usage: mqsend &lt;name> &lt;#bytes> &lt;priority>\"); len = atoi(argv[2]); prio = atoi(argv[3]); mqd = Mq_open(argv[1], O_WRONLY); // 创建一个消息队列 ptr = Calloc(len, sizeof(char));// 所用的缓冲区用colloc分配，该函数会把该缓冲区初始化为0 Mq_send(mqd, ptr, len, prio); exit(0); } 待发消息的大小和优先级必须作为命令行参数指定。 从某队列读出下一个信息 #include \"unpipc.h\" int main(int argc, char **argv) { int c,flags; mqd_t maq; ssize_t n; uint_t prio; void *buff; struct mq_attr attr; flags = O_RDONLY; while ( (c = Getopt(argc, argv, \"n\")) != -1) { switch (c) { case 'n': flags |= O_NONBLOCK; break; } } if (optind != argc - 1) err_quit(\"usage: mqreceive [-n] &lt;name>\"); mqd =Mq_open(argv[optind], flags); Mq_getattr(mqd, &amp;attr); buff = Malloc(attr.mq_msgsize); n = Mq_receive(mqd, buff, attr.mq_msgsize, &amp;prio); printf(\"read %ld bytes, priority = %u\\n\", (long) n, prio); exit(0); } 命令行选项 -n 指定非阻塞属性，这样如果所指定的队列中没有消息， 则返回一个错误。 调用 mq_getattr 打开队列并取得属性。需要确定最大消息大小，因为必须为调用的 mq_receive 分配一个这样大小的缓冲区。最后输出所读出消息的大小及其属性。 solaris %mqcreate /test1 创建并获取属性 solaris %mqgetattr /test1 max solaris % mqsend /test1 100 9999 以无效的优先级发送 mq_send error: Invalid argument solaris % mqsend /test1 100 6 100字节，优先级6 solaris % mqsend /test1 50 18 50字节，优先级18 solaris % mqsend /test1 33 18 33字节，优先级18 solaris % mqreceive /test1 read 50 bytes, priority = 18 返回优先级最高的最早消息 solaris % mqreceive /test1 read 33 bytes, priority = 18 solaris % mqreceive /test1 read 100 bytes, priority = 6 solaris % mqreceive /test1 指定非阻塞属性，队列为空 mq_recevie error: Resource temporarily unavalibale 消息队列限制： mq_mqxmsg 队列的最大消息数 mq_msgsize 给定消息的最大字节数 MQ_OPEN_MAX 一个进程能够同时拥有的打开着消息队列的组大数目（Posix要求至少为8） MQ_PRIO_MAX 任意消息的最大优先级值加1（Posix要求至少为32） mq_notify 函数 Posix 消息队列允许异步事件通知（ asynchronous event notifiction），以告知何时有一个消息放置到了某个空消息队列中。 System V 消息队列以下三种类型的IPC称为 System V IPC： System V 消息队列； System V 信号量； System V 共享内存区。 这个称为作为这三个IPC机制的通称是因为它们源自 System V Unix 。这三种IPC最先出现在AT&amp;T System v UNIX上面，并遵循XSI标准，有时候也被称为XSI IPC。 System V 消息队列使用消息队列标识符（message queue identifier） 标识。有足够权限的任何进程可往队列放置信息，有足够权限的任何进程可从队列读取信息。跟 Posix 一样，在某个进程往一个队列写入消息之前，不求另外某个进程正在等待该队列上一个消息的到达。 对于系统的每个消息队列，内核维护一个定义在 &lt;sys/msg.h&gt; 头文件中的信息结构. struct msqid_ds { struct ipc_perm msg_perm //operation permission structure struct msg *msg_frist //ptr to frist message on queue struct msg *msg_last //ptr to last message on queue msglen_t msg_cbytes //current #bytes on queue msgqnum_t msg_qnum //number of messages currently on queue msglen_t msg_qbytes //maximum number of bytes allowed on queue pid_t msg_lspid //process ID of last msgsnd() pid_t msg_lrpid //process ID of last msgrcv() time_t msg_stime //time of last msgsnd() time_t msg_rtime //time of last msgrcv() time_t msg_ctime //time of last change } Unix 98 不要求有 msg_frist、msg_last 和 msg_cbytes 成员。然而普通的源自 System V 的实现中可以找到这三个成员。就算提供了这两个指针，那么它们指向的是内核内存空间，对于应用来说基本没有作用的。 我们可以将内核中某个特定的消息队列画为一个消息链表，如图。 msgget 函数 msgget 函数用于创建一个新的消息队列或访问一个已存在的消息队列。 #include &lt;sys/msg.h> int msgget (key_t key, int oflag) //返回： 成功返回非负标识符，出错返回-1 返回值是一个整数标识符，其他三个msg函数就用它来指代该队列。 oflag是读写权限的组合。（稍微复杂。。。） 当创建一个新的消息队列的时，msqid_ds 结构的如下成员被初始化。 msg_perm 结构的 uid 和 cuid 成员被设置成当前进程的有效用户ID，gid 和 cgid 成员被设置成当前的进程的有效组ID。 oflag 中的读写权限位存放在msg_perm.mode 中。 msg_qnum、msg_lspid，msg_lrpid、msg_stime 和 msg_rtime 被设置为0. msg_ctime 被设置为当前时间。 msg_qbytes 被设置成系统限制值。 struct ipc_perm { key_t key; /*调用shmget()时给出的关键字*/ uid_t uid; /*共享内存所有者的有效用户ID */ gid_t gid; /* 共享内存所有者所属组的有效组ID*/ uid_t cuid; /* 共享内存创建 者的有效用户ID*/ gid_t cgid; /* 共享内存创建者所属组的有效组ID*/ mode_t mode; /* Permissions + SHM_DEST和SHM_LOCKED标志*/ ulong_t seq; /* 序列号*/ }; ​ msgsnd 函数 使用 msgget 函数打开一个消息队列后，使用 msgsnd 函数往其上放置一个消息。 # include &lt;sys/msg.h> int msgsnd(int msqid, const void *ptr,size_t length, int flag); 其中msqid 是由msgget 函数返回的标识符。ptr 是一个结构指针，该结构具有如下的模板： struct msgbuf { long mtype; // message type ,must be > 0 char mtext[1] // message data }; 消息类型必须大于0，因为对于 msgrcv 函数来说，非正的消息类型用作特殊的指示器。 mtext虽然起名是 text ，但是消息类型并不局限于文本。任何形式的数据都是允许的。内核根本不解释消 息数据的内容。ptr 所指向的是一个含有消息类型的长整数，消息本身则紧跟着它之后。 msgsnd 的 length 参数以字节为单位指定待发送消息的长度。是用户自定义的，可以是0. flag 参数既可以是0，也可以是IPC_NOWAIT 。IPC_NOWAIT 标志使得 msgsnd 调用非阻塞：如果没有存放新消息的可用空间，该函数马上返回。这个条件可能发生的情况包括： 在指定的队列中已有太多的字节（对应 该队列的msqid_ds 结构中的msg_qbytes 值）； 在系统范围存在太多的消息。 如果两个条件一个存在，而且IPC_NOWAIT标志已指定，msgsnd 就返回一个EAGAIN 错误。如果两个条件一个存在，标志未指定，那么调用线程就被投入睡眠，直到： 具备存放新消息的空间； 由 msqgid 标识的消息队列从系统中删除（这个情况下回返回一个EIDRM 错误）； 调用线程被某个捕获的信息所中断。","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Hexo 添加歌单","slug":"testlist","date":"2017-04-09T07:13:11.000Z","updated":"2017-04-09T07:13:11.000Z","comments":true,"path":"testlist.html/","link":"","permalink":"http://yusank.github.io/testlist.html/","excerpt":"测试添加歌单。。。。","text":"测试添加歌单。。。。 测试歌单 var options = {\"narrow\":false,\"autoplay\":false,\"showlrc\":1,\"mode\":\"random\",\"mutex\":true,\"theme\":\"#e6d0b2\",\"preload\":\"metadata\",\"listmaxheight\":\"513px\",\"music\":[{\"title\":\"匆匆那年\",\"author\":\"王菲\",\"url\":\"http://oid1xlj7h.bkt.clouddn.com/%E7%8E%8B%E8%8F%B2%20-%20%E5%8C%86%E5%8C%86%E9%82%A3%E5%B9%B4.mp3\",\"lrc\":\"http://oid1xlj7h.bkt.clouddn.com/ccnn.txt\"},{\"title\":\"Toca Toca\",\"author\":\"Fly project\",\"url\":\"http://oid1xlj7h.bkt.clouddn.com/Fly%20Project%20-%20Toca%20Toca.mp3\"},{\"title\":\"Danzo Kuduro\",\"author\":\"Don Omar\",\"url\":\"http://oid1xlj7h.bkt.clouddn.com/Don%20Omar,Lucenzo%20-%20Danza%20Kuduro%20-%20Album%20Version.mp3\"},{\"title\":\"难忘的一天\",\"author\":\"许巍\",\"url\":\"http://oid1xlj7h.bkt.clouddn.com/%E8%AE%B8%E5%B7%8D%20-%20%E9%9A%BE%E5%BF%98%E7%9A%84%E4%B8%80%E5%A4%A9.mp3\",\"lrc\":\"http://oid1xlj7h.bkt.clouddn.com/nwdyt.txt\"},{\"title\":\"Counting Stars\",\"author\":\"OneRepublic\",\"url\":\"http://oid1xlj7h.bkt.clouddn.com/OneRepublic%20-%20Counting%20Stars.mp3\"},{\"title\":\"Zoobi Doobi\",\"author\":\"Sonu Nigam,Shreya Ghoshal\",\"url\":\"http://oid1xlj7h.bkt.clouddn.com/Sonu%20Nigam,Shreya%20Ghoshal%20-%20Zoobi%20Doobi.mp3\",\"lrc\":\"http://oid1xlj7h.bkt.clouddn.com/tidoit.txt\"}]}; options.element = document.getElementById(\"aplayer2\"); new APlayer(options);","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Hexo 博客添加视频和音乐","slug":"HexoMedia","date":"2017-04-09T05:13:11.000Z","updated":"2017-04-09T05:13:11.000Z","comments":true,"path":"HexoMedia.html/","link":"","permalink":"http://yusank.github.io/HexoMedia.html/","excerpt":"找到一个炒鸡流弊的东西。。。","text":"找到一个炒鸡流弊的东西。。。 Hexo 博客中插入视频/音乐博客中插入音乐/视频，可以让博客的逼格瞬间提高。作为优秀的静态博客，Hexo 当然也少不了这些高大上的功能。 Markdown 通用音乐/视频插入方法Markdown 作为轻量级的标记语言，兼容 html 语法，所以可以直接在 Markdown 文档中使用 html 语法。 vedio 标签 &lt;video width=\"480\" height=\"320\" controls> &lt;source src=\"movie.mp4\"> &lt;/video> 其中在 src 后面需要替换自己的音乐/视频链接 效果: ​ ​ ​ embed标签&lt;embed src=\"http://player.youku.com/player.php/Type/Folder/Fid/27690810/Ob/1/sid/XMTY1MTI3NjMyNA==/v.swf\" quality=\"high\" width=\"480\" height=\"400\" align=\"middle\" allowScriptAccess=\"always\" allowFullScreen=\"true\" mode=\"transparent\" type=\"application/x-shockwave-flash\">&lt;/embed> ifreame标签&lt;iframe height=498 width=510 src=\"http://player.youku.com/embed/XMTY1MTI3NjMyNA==\" frameborder=0 allowfullscreen>&lt;/iframe> 网易云音乐网页版提供生成 iframe 标签。 &lt;script type=\"text/javascript\" src=\"http://www.xiami.com/widget/player-single?uid=32329501&amp;sid=1776238762&amp;mode=js\">&lt;/script> 除了 vedio 标签外，大部分音乐/视频网站都可以直接生成播放代码，直接粘贴在 Markdown 文档即可。 不过有些标签不支持 HTTPS。 通过 Hexo 插件插入音频/视频这里需要两个播放器插件 hexo-tag-aplayer:https://github.com/grzhan/hexo-tag-aplayer#upstream-issue hexo-tag-dplayer:https://github.com/NextMoe/hexo-tag-dplayer 这两款插件基于 DIYgod 编写的 html5 播放器 APlayer 和 DPlayer 开发。 首先安装两款插件 打开 shell，切换到 Hexo 目录下，运行两条目录 npm install hexo-tag-dplayer --save npm install hexo-tag-aplayer --save 安装成功后，在 Markdown 文档中添加 APlayer 和 DPlayer 标签即可。 {% aplayer \"Caffeine\" \"Jeff Williams\" \"http://7xq131.com1.z0.glb.clouddn.com/Preparation.mp3\" \"autoplay\" %} {% dplayer \"url=http://devtest.qiniudn.com/若能绽放光芒.mp4\" \"api=http://dplayer.daoapp.io\" \"pic=http://devtest.qiniudn.com/若能绽放光芒.png\" \"id=9E2E3368B56CDBB4\" \"loop=yes\" \"theme=#FADFA3\" \"autoplay=false\" \"token=tokendemo\" %} APlayer 和 DPlayer 具体参数设置可以到 GitHub 项目主页，不过默认参数足够了。 '[00:00.00]Zoobi Doobi [00:00.38]Sonu Nigam & Shreya Ghoshal [00:00.53]LRC：Meselson (QQ 445942376) [00:01.18] [00:03.50]Gungunati hain yeh hawayein [00:12.73]Gungunata hai gagan [00:19.91]Gaa raha hai yeh saara aalam [00:26.90]Zoobi do… param pum… [00:37.35]Zoobi doobi zoobi doobi pum paara Zoobi doobi param pum [00:42.67]Zoobi doobi zoobi doobi naache kyun Paagal stupid mann [00:47.99]Zoobi doobi zoobi doobi pum paara Zoobi doobi param pum [00:53.30]Zoobi doobi zoobi doobi naache kyun Paagal stupid mann [00:58.34]Shaakhon pe pattey gaa rahe hain Phoolon pe bhanvre gaa rahe [01:03.69]Deewani kirine gaa rahi hain Yeh panchhi gaa rahe [01:08.38]Ohhh Bagiya mein do phoolon ki Ho rahi hai guft-gu [01:14.02]Jaisa filmon mein hota hai Ho raha hai hu-bahoo [01:19.18]I iiii iii.. [01:20.11]Zoobi doobi zoobi doobi pum paara Zoobi doobi param pum [01:25.21]Zoobi doobi zoobi doobi naache kyun Paagal stupid mann [01:30.52] [01:30.81]Zoobi doobi zoobi doobi pum paara Zoobi doobi param pum [01:35.98]Zoobi doobi zoobi doobi naache kyun Paagal stupid mann [01:40.68] [02:02.67]Rimjhim rimjhim rimjhim San san san san hawaa [02:07.63]Tip tip tip tip boondein Gurrati bijliyaan [02:13.00]Bheegi bheegi saree mein Yun thumke lagati tu [02:18.24]Ho raha hai hu bahoo [02:23.58]I iiii iii.. [02:24.23]Zoobi doobi zoobi doobi pum paara Zoobi doobi param pum [02:29.16]Zoobi doobi zoobi doobi naache kyun Paagal stupid mann [02:32.50] [02:34.30]Zoobi doobi zoobi doobi pum paara Zoobi doobi param pum [02:39.58]Zoobi doobi zoobi doobi naache kyun Paagal stupid mann [02:45.70] [03:06.55]Amber ka chand zameen par Itra ke gaa raha [03:12.02]Ek tim tim toota tara Ithla ka gaa raha [03:17.29]Hai raat akeli tanha Mujhe choo le aake tu [03:22.47]Jaisa filmon mein hota hai Ho raha hai hubahoo [03:27.24]I iiii iii.. [03:27.78]Zoobi doobi zoobi doobi pum paara Zoobi doobi param pum [03:33.28]Zoobi doobi zoobi doobi naache kyun Paagal stupid mann [03:38.57]Zoobi doobi zoobi doobi pum paara Zoobi doobi param pum [03:43.79]Zoobi doobi zoobi doobi naache kyun Paagal stupid mann [03:48.58]LRC：Meselson (QQ 445942376) [03:50.47]THE END new APlayer({ element: document.getElementById(\"aplayer1\"), narrow: false, autoplay: 1, showlrc: 2, music: { title: \"Zoobi Doobi\", author: \"Three ediot\", url: \"http://oid1xlj7h.bkt.clouddn.com/Sonu%20Nigam,Shreya%20Ghoshal%20-%20Zoobi%20Doobi.mp3\", pic: \"http://oid1xlj7h.bkt.clouddn.com/3_idiots_wallpaper.jpg\", } }); var dplayer0 = new DPlayer({\"element\":document.getElementById(\"dplayer0\"),\"autoplay\":false,\"theme\":\"#FADFA3\",\"loop\":true,\"video\":{\"url\":\"http://oid1xlj7h.bkt.clouddn.com/WeChatSight72.mp4\"},\"danmaku\":{\"api\":\"http://dplayer.daoapp.io\",\"id\":\"9E2E3368B56CDBB4\",\"token\":\"tokendemo\"}}); APlayer 和 DPlayer 均支持 HTTPS。 上述两种方法都有优缺点，选择一种适合自己的方法，打造自己专属的博客吧。 转载：【login926】login926.github.io","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Vim 快捷键","slug":"Vimkyboard","date":"2017-04-07T07:07:00.000Z","updated":"2017-04-07T07:07:01.000Z","comments":true,"path":"Vimkyboard.html/","link":"","permalink":"http://yusank.github.io/Vimkyboard.html/","excerpt":"Vim 快捷键一. 移动：h,j,k,l: 左，下，上，右。\nw: 下一个词的词首。\ne:下一个词的词尾。\n​    b:上一个词的词首。\n&lt;&gt;: v 模式选中后进行缩进。\n","text":"Vim 快捷键一. 移动：h,j,k,l: 左，下，上，右。 w: 下一个词的词首。 e:下一个词的词尾。 ​ b:上一个词的词首。 &lt;&gt;: v 模式选中后进行缩进。 new APlayer({ element: document.getElementById(\"aplayer0\"), narrow: false, autoplay: true, showlrc: 0, music: { title: \"Wadilar Keni\", author: \"from nobody\", url: \"http://oid1xlj7h.bkt.clouddn.com/elyarr%20-%20wadilar%C2%A0keni%EF%BC%88%E5%90%AC%E4%BA%86%E5%B0%B1%E6%B2%A1%E9%94%99%EF%BC%89.mp3\", pic: \"\", } }); 二. 跳转：%: 可以匹配{},&quot;&quot;,(),[]之间跳转。 H、M、L：直接跳转到当前屏幕的顶部、中部、底部。 “#H”：跳转到当前屏的第#行。 // 由于markdown语法原因，加上了双引号，实际用的时候没有双引号的, 以下所有加引号的雷同。 “#L”：跳转到当前屏的倒数第#行。 zt: 当前编辑行置为屏顶。 zz: 当前编辑行置为屏中。 zb: 当前编辑行置为屏底。 G：直接跳转到文件的底部。 gg: 跳转到文件首。 ():跳转到当前的行首、行尾。 {}：向上、向下跳转到最近的空行。 [{：跳转到目前区块开头。 ]}：跳转到目前区块结尾。 0: 跳转到行首。 $: 跳转到行尾。 2$: 跳转到下一行的行尾。 “#”：跳转到该行的第#个位置。 “#G”: 15G,跳转到15行。 :#：跳转到#行。 f&#39;n&#39;：跳转到下一个&quot;n&quot;字母后。 ctrl+b: 向后翻一页。 ctrl+f：向前翻一页。 ctrl+u: 向后翻半页。 ctrl+d: 向前翻半页。 ctry+e: 下滚一行。 三. 选择：1.V: 选择一行。 2.^V: 矩形选择。 3.v3w: 选择三个字符。 四. 编辑： 新增：i: 光标前插入。 I: 在当前行首插入。 a: 光标后插入。 A: 当前行尾插入。 O: 在当前行之前插入新行。 o: 在当前行之后插入新行。 修改 c(change) 为主： r: 替换光标所在处的字符。 R：替换光标所到之处的字符。 cw: 更改光标所在处的字到字尾处。 c#w: c3w 修改3个字符。 C：修改到行尾。 ci&#39;：修改配对标点符号中的文本内容。 di&#39;：删除配对标点符号中的文本内容。 yi&#39;：复制配对标点符号中的文本内容。 vi&#39;：选中配对标点符号中的文本内容。 s：替换当前一个光标所处字符。 ​ “#S”：删除 # 行，并以新文本代替。 删除 d(delete) 为主：D：删除到行尾。 X: 每按一次，删除光标所在位置的前面一个字符。 x: 每按一次，删除光标所在位置的后面一个字符。 ​ “#x”: 删除光标所在位置后面6个字符。 d^: 删至行首。 d$: 删至行尾。 dd:(剪切)删除光标所在行。 dw: 删除一个单词/光标之后的单词剩余部分。 d4w: 删除4个word。 ​”#dd”: 从光标所在行开始删除#行。 daB: 删除{}及其内的内容。 diB: 删除{}中的内容。 n1,n2 d：将n1,n2行之间的内容删除。 查找：/： 输入关键字，发现不是要找的，直接在按n，向后查找直到找到为止。 ?： 输入关键字，发现不是要找的，直接在按n，向前查找直到找到为止。 *: 在当前页向后查找同一字。 ​ “#”: 在当前页向前查找同一字。 复制 y(yank)为主： yw: 将光标所在之处到字尾的字符复制到缓冲区中。 “#yw”: 复制#个字到缓冲区。 Y：相当于yy, 复制整行。 ​ “#yy”:表示复制从光标所在的该行往下数#行文字。 p: 粘贴。所有与y相关的操作必用p来结合粘贴。 n1,n2 co n3：复制第n1行到第n2行之间的内容到第n3行后面。 6. 大小写转换： gUU: 将当前行的字母改为大写。 guu: 将当前行的字母改为小写。 gUw: 将当前光标下的单词改为大写。 guw: 将当前光标下的单词改为小写。 a. 整篇大写: ggguG gg: 光标到文件第一个字符。 gu: 把选择范围全部小写。 G: 到文件结束。 b. 整篇小写：gggUG 7. 其它： J：当前行和下一行合并成一行。 8. 移动： n1,n2 m n3：将n1行到n2行之间的内容移至n3行下。 五.退出： 1. w filename: 保存正在编辑的文件filename 2. wq filename: 保存后退出正在编辑的文件filename 3. q：退出不保存。 六.窗口操作： 1. ctrl+w p: 在两个分割窗口之间来回切换。 2. ctrl+w j: 跳到下面的分割窗 3. ctrl+w h: 跳到左边的分割窗。 4. ctrl+w k: 跳到上面的分割窗。 5. ctrl+w l: 跳到右边的分割窗。","raw":null,"content":null,"categories":[],"tags":[]},{"title":"跨域资源共享 CORS 详解","slug":"CORS","date":"2017-01-30T07:07:00.000Z","updated":"2017-01-30T07:07:01.000Z","comments":true,"path":"CORS.html/","link":"","permalink":"http://yusank.github.io/CORS.html/","excerpt":"跨域资源共享 CORS 详解CORS是一个W3C标准，全称是”跨域资源共享”（Cross-origin resource sharing）。它允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。本文详细介绍CORS的内部机制。","text":"跨域资源共享 CORS 详解CORS是一个W3C标准，全称是”跨域资源共享”（Cross-origin resource sharing）。它允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。本文详细介绍CORS的内部机制。 一、简介CORS需要浏览器和服务器同时支持。目前，所有浏览器都支持该功能，IE浏览器不能低于IE10。 整个CORS通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS通信与同源的AJAX通信没有差别，代码完全一样。浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。 因此，实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信。 二、两种请求浏览器将CORS请求分成两类：简单请求（simple request）和非简单请求（not-so-simple request）。 只要同时满足以下两大条件，就属于简单请求。 1) 请求方法是以下三种方法之一： HEAD GET POST （2）HTTP的头信息不超出以下几种字段： Accept Accept-Language Content-Language Last-Event-ID Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain 凡是不同时满足上面两个条件，就属于非简单请求。 浏览器对这两种请求的处理，是不一样的。 三、简单请求3.1 基本流程对于简单请求，浏览器直接发出CORS请求。具体来说，就是在头信息之中，增加一个Origin字段。 下面是一个例子，浏览器发现这次跨源AJAX请求是简单请求，就自动在头信息之中，添加一个Origin字段。 GET /cors HTTP/1.1 Origin: http://api.bob.com Host: api.alice.com Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... 上面的头信息中，Origin字段用来说明，本次请求来自哪个源（协议 + 域名 + 端口）。服务器根据这个值，决定是否同意这次请求。 如果Origin指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应。浏览器发现，这个回应的头信息没有包含Access-Control-Allow-Origin字段（详见下文），就知道出错了，从而抛出一个错误，被XMLHttpRequest的onerror回调函数捕获。注意，这种错误无法通过状态码识别，因为HTTP回应的状态码有可能是200。 如果Origin指定的域名在许可范围内，服务器返回的响应，会多出几个头信息字段。 Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Credentials: true Access-Control-Expose-Headers: FooBar Content-Type: text/html; charset=utf-8 上面的头信息之中，有三个与CORS请求相关的字段，都以Access-Control-开头。 （1）Access-Control-Allow-Origin 该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。 （2）Access-Control-Allow-Credentials 该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。 （3）Access-Control-Expose-Headers 该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。上面的例子指定，getResponseHeader(&#39;FooBar&#39;)可以返回FooBar字段的值。 3.2 withCredentials 属性上面说到，CORS请求默认不发送Cookie和HTTP认证信息。如果要把Cookie发到服务器，一方面要服务器同意，指定Access-Control-Allow-Credentials字段。 Access-Control-Allow-Credentials: true 另一方面，开发者必须在AJAX请求中打开withCredentials属性。 var xhr = new XMLHttpRequest(); xhr.withCredentials = true; 否则，即使服务器同意发送Cookie，浏览器也不会发送。或者，服务器要求设置Cookie，浏览器也不会处理。 但是，如果省略withCredentials设置，有的浏览器还是会一起发送Cookie。这时，可以显式关闭withCredentials。 xhr.withCredentials = false; 需要注意的是，如果要发送Cookie，Access-Control-Allow-Origin就不能设为星号，必须指定明确的、与请求网页一致的域名。同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传，其他域名的Cookie并不会上传，且（跨源）原网页代码中的document.cookie也无法读取服务器域名下的Cookie。 四、非简单请求4.1 预检请求非简单请求是那种对服务器有特殊要求的请求，比如请求方法是PUT或DELETE，或者Content-Type字段的类型是application/json。 非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为”预检”请求（preflight）。 浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。 下面是一段浏览器的JavaScript脚本。 var url = 'http://api.alice.com/cors'; var xhr = new XMLHttpRequest(); xhr.open('PUT', url, true); xhr.setRequestHeader('X-Custom-Header', 'value'); xhr.send(); 上面代码中，HTTP请求的方法是PUT，并且发送一个自定义头信息X-Custom-Header。 浏览器发现，这是一个非简单请求，就自动发出一个”预检”请求，要求服务器确认可以这样请求。下面是这个”预检”请求的HTTP头信息。 OPTIONS /cors HTTP/1.1 Origin: http://api.bob.com Access-Control-Request-Method: PUT Access-Control-Request-Headers: X-Custom-Header Host: api.alice.com Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... “预检”请求用的请求方法是OPTIONS，表示这个请求是用来询问的。头信息里面，关键字段是Origin，表示请求来自哪个源。 除了Origin字段，”预检”请求的头信息包括两个特殊字段。 （1）Access-Control-Request-Method 该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法，上例是PUT。 （2）Access-Control-Request-Headers 该字段是一个逗号分隔的字符串，指定浏览器CORS请求会额外发送的头信息字段，上例是X-Custom-Header。 4.2 预检请求的回应服务器收到”预检”请求以后，检查了Origin、Access-Control-Request-Method和Access-Control-Request-Headers字段以后，确认允许跨源请求，就可以做出回应。 HTTP/1.1 200 OK Date: Mon, 01 Dec 2008 01:15:39 GMT Server: Apache/2.0.61 (Unix) Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Methods: GET, POST, PUT Access-Control-Allow-Headers: X-Custom-Header Content-Type: text/html; charset=utf-8 Content-Encoding: gzip Content-Length: 0 Keep-Alive: timeout=2, max=100 Connection: Keep-Alive Content-Type: text/plain 上面的HTTP回应中，关键的是Access-Control-Allow-Origin字段，表示http://api.bob.com可以请求数据。该字段也可以设为星号，表示同意任意跨源请求。 Access-Control-Allow-Origin: * 如果浏览器否定了”预检”请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段。这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被XMLHttpRequest对象的onerror回调函数捕获。控制台会打印出如下的报错信息。 XMLHttpRequest cannot load http://api.alice.com. Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin. 服务器回应的其他CORS相关字段如下。 Access-Control-Allow-Methods: GET, POST, PUT Access-Control-Allow-Headers: X-Custom-Header Access-Control-Allow-Credentials: true Access-Control-Max-Age: 1728000 （1）Access-Control-Allow-Methods 该字段必需，它的值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。注意，返回的是所有支持的方法，而不单是浏览器请求的那个方法。这是为了避免多次”预检”请求。 （2）Access-Control-Allow-Headers 如果浏览器请求包括Access-Control-Request-Headers字段，则Access-Control-Allow-Headers字段是必需的。它也是一个逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在”预检”中请求的字段。 （3）Access-Control-Allow-Credentials 该字段与简单请求时的含义相同。 （4）Access-Control-Max-Age 该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是20天（1728000秒），即允许缓存该条回应1728000秒（即20天），在此期间，不用发出另一条预检请求。 4.3 浏览器的正常请求和回应一旦服务器通过了”预检”请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。 下面是”预检”请求之后，浏览器的正常CORS请求。 PUT /cors HTTP/1.1 Origin: http://api.bob.com Host: api.alice.com X-Custom-Header: value Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... 上面头信息的Origin字段是浏览器自动添加的。 下面是服务器正常的回应。 Access-Control-Allow-Origin: http://api.bob.com Content-Type: text/html; charset=utf-8 上面头信息中，Access-Control-Allow-Origin字段是每次回应都必定包含的。 五、与JSONP的比较CORS与JSONP的使用目的相同，但是比JSONP更强大。 JSONP只支持GET请求，CORS支持所有类型的HTTP请求。JSONP的优势在于支持老式浏览器，以及可以向不支持CORS的网站请求数据。 （完）","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Go Channel","slug":"Go Channel","date":"2017-01-07T04:20:00.000Z","updated":"2017-08-14T06:06:53.000Z","comments":true,"path":"Go Channel.html/","link":"","permalink":"http://yusank.github.io/Go Channel.html/","excerpt":"","text":"讲解 Golang 的 channel（通道），学 go 语言的有必要看一下。以下正文。。。 Go Channel 详解Channel是Go中的一个核心类型，你可以把它看成一个管道，通过它并发核心单元就可以发送或者接收数据进行通讯(communication)。 它的操作符是箭头 &lt;- 。 ch &lt;- v v := &lt;-ch (箭头的指向就是数据的流向) 就像 map 和 slice 数据类型一样, channel必须先创建再使用: ch := make(chan int) Channel 类型Channel类型的定义格式如下： ChannelType = ( \"chan\" | \"chan\" \"&lt;-\" | \"&lt;-\" \"chan\" ) ElementType . 它包括三种类型的定义。可选的&lt;-代表channel的方向。如果没有指定方向，那么Channel就是双向的，既可以接收数据，也可以发送数据。 chan T // 可以接收和发送类型为 T 的数据 chan&lt;- float64 // 只可以用来发送 float64 类型的数据 &lt;-chan int // 只可以用来接收 int 类型的数据 &lt;-总是优先和最左边的类型结合。(The &lt;- operator associates with the leftmost chan possible) chan&lt;- chan int // 等价 chan&lt;- (chan int) chan&lt;- &lt;-chan int // 等价 chan&lt;- (&lt;-chan int) &lt;-chan &lt;-chan int // 等价 &lt;-chan (&lt;-chan int) chan (&lt;-chan int) 使用make初始化Channel,并且可以设置容量: make(chan int, 100) 容量(capacity)代表Channel容纳的最多的元素的数量，代表Channel的缓存的大小。如果没有设置容量，或者容量设置为0, 说明Channel没有缓存，只有sender和receiver都准备好了后它们的通讯(communication)才会发生(Blocking)。如果设置了缓存，就有可能不发生阻塞， 只有buffer满了后 send才会阻塞， 而只有缓存空了后receive才会阻塞。一个nil channel不会通信。 可以通过内建的close方法可以关闭Channel。 你可以在多个goroutine从/往 一个channel 中 receive/send 数据, 不必考虑额外的同步措施。 Channel可以作为一个先入先出(FIFO)的队列，接收的数据和发送的数据的顺序是一致的。 channel的 receive支持 multi-valued assignment，如 v, ok := &lt;-ch 它可以用来检查Channel是否已经被关闭了。 send语句send语句用来往Channel中发送数据， 如ch &lt;- 3。它的定义如下: SendStmt = Channel \"&lt;-\" Expression . Channel = Expression . 在通讯(communication)开始前channel和expression必选先求值出来(evaluated)，比如下面的(3+4)先计算出7然后再发送给channel。 c := make(chan int) defer close(c) go func() { c &lt;- 3 + 4 }() i := &lt;-c fmt.Println(i) send被执行前(proceed)通讯(communication)一直被阻塞着。如前所言，无缓存的channel只有在receiver准备好后send才被执行。如果有缓存，并且缓存未满，则send会被执行。 往一个已经被close的channel中继续发送数据会导致run-time panic。 往nil channel中发送数据会一致被阻塞着。 receive 操作符&lt;-ch用来从channel ch中接收数据，这个表达式会一直被block,直到有数据可以接收。 从一个nil channel中接收数据会一直被block。 从一个被close的channel中接收数据不会被阻塞，而是立即返回，接收完已发送的数据后会返回元素类型的零值(zero value)。 如前所述，你可以使用一个额外的返回参数来检查channel是否关闭。 x, ok := &lt;-ch x, ok = &lt;-ch var x, ok = &lt;-ch blocking缺省情况下，发送和接收会一直阻塞着，知道另一方准备好。这种方式可以用来在gororutine中进行同步，而不必使用显示的锁或者条件变量。 如官方的例子中x, y := &lt;-c, &lt;-c这句会一直等待计算结果发送到channel中。 import \"fmt\" func sum(s []int, c chan int) { sum := 0 for _, v := range s { sum += v } c &lt;- sum } func main() { s := []int{7, 2, 8, -9, 4, 0} c := make(chan int) go sum(s[:len(s)/2], c) go sum(s[len(s)/2:], c) x, y := &lt;-c, &lt;-c // receive from c fmt.Println(x, y, x+y) } Buffered Channelsmake的第二个参数指定缓存的大小：ch := make(chan int, 100)。 通过缓存的使用，可以尽量避免阻塞，提供应用的性能。 Rangefor …… range语句可以处理Channel。 func main() { go func() { time.Sleep(1 * time.Hour) }() c := make(chan int) go func() { for i := 0; i &lt; 10; i = i + 1 { c &lt;- i } close(c) }() for i := range c { fmt.Println(i) } fmt.Println(\"Finished\") } range c产生的迭代值为Channel中发送的值，它会一直迭代知道channel被关闭。上面的例子中如果把close(c)注释掉，程序会一直阻塞在for …… range那一行。 selectselect语句选择一组可能的send操作和receive操作去处理。它类似switch,但是只是用来处理通讯(communication)操作。它的case可以是send语句，也可以是receive语句，亦或者default。 receive语句可以将值赋值给一个或者两个变量。它必须是一个receive操作。 最多允许有一个default case,它可以放在case列表的任何位置，尽管我们大部分会将它放在最后。 import \"fmt\" func fibonacci(c, quit chan int) { x, y := 0, 1 for { select { case c &lt;- x: x, y = y, x+y case &lt;-quit: fmt.Println(\"quit\") return } } } func main() { c := make(chan int) quit := make(chan int) go func() { for i := 0; i &lt; 10; i++ { fmt.Println(&lt;-c) } quit &lt;- 0 }() fibonacci(c, quit) } 如果有同时多个case去处理,比如同时有多个channel可以接收数据，那么Go会伪随机的选择一个case处理(pseudo-random)。如果没有case需要处理，则会选择default去处理，如果default case存在的情况下。如果没有default case，则select语句会阻塞，直到某个case需要处理。 需要注意的是，nil channel上的操作会一直被阻塞，如果没有default case,只有nil channel的select会一直被阻塞。 select语句和switch语句一样，它不是循环，它只会选择一个case来处理，如果想一直处理channel，你可以在外面加一个无限的for循环： for { select { case c &lt;- x: x, y = y, x+y case &lt;-quit: fmt.Println(\"quit\") return } } timeoutselect有很重要的一个应用就是超时处理。 因为上面我们提到，如果没有case需要处理，select语句就会一直阻塞着。这时候我们可能就需要一个超时操作，用来处理超时的情况。下面这个例子我们会在2秒后往channel c1中发送一个数据，但是select设置为1秒超时,因此我们会打印出timeout 1,而不是result 1。 import \"time\" import \"fmt\" func main() { c1 := make(chan string, 1) go func() { time.Sleep(time.Second * 2) c1 &lt;- \"result 1\" }() select { case res := &lt;-c1: fmt.Println(res) case &lt;-time.After(time.Second * 1): fmt.Println(\"timeout 1\") } } 其实它利用的是time.After方法，它返回一个类型为&lt;-chan Time的单向的channel，在指定的时间发送一个当前时间给返回的channel中。 Timer 和 Ticker我们看一下关于时间的两个Channel。timer是一个定时器，代表未来的一个单一事件，你可以告诉timer你要等待多长时间，它提供一个Channel，在将来的那个时间那个Channel提供了一个时间值。下面的例子中第二行会阻塞2秒钟左右的时间，直到时间到了才会继续执行。 timer1 := time.NewTimer(time.Second * 2) &lt;-timer1.C fmt.Println(\"Timer 1 expired\") 当然如果你只是想单纯的等待的话，可以使用time.Sleep来实现。 你还可以使用timer.Stop来停止计时器。 timer2 := time.NewTimer(time.Second) go func() { &lt;-timer2.C fmt.Println(\"Timer 2 expired\") }() stop2 := timer2.Stop() if stop2 { fmt.Println(\"Timer 2 stopped\") } ticker是一个定时触发的计时器，它会以一个间隔(interval)往Channel发送一个事件(当前时间)，而Channel的接收者可以以固定的时间间隔从Channel中读取事件。下面的例子中ticker每500毫秒触发一次，你可以观察输出的时间。 ticker := time.NewTicker(time.Millisecond * 500) go func() { for t := range ticker.C { fmt.Println(\"Tick at\", t) } }() 类似timer, ticker也可以通过Stop方法来停止。一旦它停止，接收者不再会从channel中接收数据了。 close内建的close方法可以用来关闭channel。 总结一下channel关闭后sender的receiver操作。如果channel c已经被关闭,继续往它发送数据会导致panic: send on closed channel: import \"time\" func main() { go func() { time.Sleep(time.Hour) }() c := make(chan int, 10) c &lt;- 1 c &lt;- 2 close(c) c &lt;- 3 } 但是从这个关闭的channel中不但可以读取出已发送的数据，还可以不断的读取零值: c := make(chan int, 10) c &lt;- 1 c &lt;- 2 close(c) fmt.Println(&lt;-c) //1 fmt.Println(&lt;-c) //2 fmt.Println(&lt;-c) //0 fmt.Println(&lt;-c) //0 但是如果通过range读取，channel关闭后for循环会跳出： c := make(chan int, 10) c &lt;- 1 c &lt;- 2 close(c) for i := range c { fmt.Println(i) } 通过i, ok := &lt;-c可以查看Channel的状态，判断值是零值还是正常读取的值。 c := make(chan int, 10) close(c) i, ok := &lt;-c fmt.Printf(\"%d, %t\", i, ok) //0, false 同步channel可以用在goroutine之间的同步。下面的例子中main goroutine通过done channel等待worker完成任务。 worker做完任务后只需往channel发送一个数据就可以通知main goroutine任务完成。 import ( \"fmt\" \"time\" ) func worker(done chan bool) { time.Sleep(time.Second) // 通知任务已完成 done &lt;- true } func main() { done := make(chan bool, 1) go worker(done) // 等待任务完成 &lt;-done } [参考资料]： https://gobyexample.com/channels https://tour.golang.org/concurrency/2 https://golang.org/ref/spec#Select_statements https://github.com/a8m/go-lang-cheat-sheet http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Docker 进阶与实践（第一讲）","slug":"Docker","date":"2017-01-03T10:11:00.000Z","updated":"2017-01-04T06:12:00.000Z","comments":true,"path":"Docker.html/","link":"","permalink":"http://yusank.github.io/Docker.html/","excerpt":"学习 Docker 技术，每看完一章或够写一篇文章的时候就上传一次. 这一篇讲容器技术。以下正文。。。","text":"学习 Docker 技术，每看完一章或够写一篇文章的时候就上传一次. 这一篇讲容器技术。以下正文。。。 Docker容器技术 对于容器，目前并没有一个严格的定义，但是普遍被认可的说法是，它首先必须是一个相对独立的环境，在这一点上有点类似虚拟机，但是没有虚拟机那么彻底。另外，在一个容器环境中，应该最小化其对外界的影响，比如不能在容器中吧host上的资源耗尽，这就是资源的控制。 容器技术之所以受欢迎，一个重要的原因是它已经集成到了 Linux 内核中，已经被当作 Linux 内核原生提供的特征。当然其他平台也有相应的容器技术，但是我们讨论的以及Docker涉及的都是指 Linux 平台上的容器技术。 一般来说，容器技术主要包括Namespace和Cgroup两个内核特征。 Namespace 命名空间，它主要做的是访问隔离。其原理是对一类资源进行抽象，并将其封装在一起提供给容器使用，对于这类资源，因为每个容器都有自己的抽象，而他们彼此之间是不可见的，所以就做到访问隔离。 Cgroup是 control group 的简称，又称为控制组，它主要是控制资源控制。其原理是将一组进程放在一个控制组里，通过给这个控制组分配指定的可用资源，达到控制这一组进程可用资源的目的。 容器最核心技术是 Namespace+Cgroup，但是光有这两个抽象的技术概念是无法组成一个完整的容器的。对于 linux 容器的最小组成，是由一下四个部分构成： Cgroup： 资源控制。 Namespace： 访问隔离。 rootfs： 系统文件隔离。 容器引擎： 生命周期控制。 容器的创建原理代码一 pid = clone(fun, stack, flags, clone_arg); (flags: CLONE_NEWPID | CLONE_NEWNS | CLONE_NEWUSER | CLONE_NEWNET | CLONE_NEWIPC | CLONE_NEWUTS | ...) 对于以上代码，通过clone系统调用，并传入各个Namespace对应的clone flag，创建了一个新的子进程，该进程拥有自己的Namespace。从上面的代码可以看出，该进程拥有自己的pid,mount,user,net,ipc,uts namespace 。 代码二： echo $pid > /sys/fs/cgroup/cpu/tasks echo $pid > /sys/fs/cgroup/cpuset/tasks echo $pid > /sys/fs/cgroup/blkio/tasks echo $pid > /sys/fs/cgroup/memory/tasks echo $pid > /sys/fs/cgroup/devices/tasks echo $pid > /sys/fs/cgroup/freezer/tasks 对于代码二，将代码一中的pid写入各个Cgroup子系统中，这样该进程就可以受到相应Cgroup子系统的控制。 代码三： fun () { ... pivot_root(\"path_of_rootfs/\", path); ... exec(\"/bin/bash\"); ... } 对于代码三，该fun函数由上面生成的新进程执行，在fun函数中，通过pivot_root系统调用，使进程进入新的rootfs，之后通过exec系统调用，在新的Namespace,Cgroup,rootfs中执行&quot;/bin/bash&quot;程序。 通过以上操作，成功在一个“容器”中运行了一个bash程序。对于Cgroup和Namespace的技术细节，我们下一节详细描述 CgroupCgroup 是什么Cgroup是control group 的简写，属于 Linux 内核提供的一个特性，用于限制和隔离一组进程对系统资源的使用。这些资源主要包括 CPU， 内存， block I/O（数据块 I/O） 和网络宽带。Cgroup 从 2.6.24版本进入内核主线，目前各大发行版linux都默认打开了 Cgroup 特性 从实现的角度来看，Cgroup 实现了一个通用的进程分组的框架，而不同资源的具体管理则是由各个 Cgroup 子系统实现的。截止内核4.1版本，Cgroup 中实现的子系统的及其作用如下： devices： 设备权限控制 cpuset： 分配指定的CPU和内存节点 cpu： 控制 CPU 占用率 cpuacct： 统计 CPU 使用情况 memory： 限制内存的使用上限 freezer： 冻结（暂停）Cgroup 中的进程 net_cls： 配合tc（traffic controller）限制网络宽带 net_prio： 设置进程的网络流量优先级 huge_tlb： 限制HugeTLB（块表缓冲区）的使用 perf_event： 允许 Perf 工具基于Cgroup分组做性能测试 NamespaceNamespace 是什么Namespace 是将内核的全局资源做封装，使得每个Namespace都有有一份独立的资源，因此不同的进程各自的 Namespace 内对同一个资源的使用不会互相干扰。举个例子，执行 sethostname 这个系统调用时，可以改变系统的主机名，这个主机名就是一个内核的全局资源。内核通过实现 UTS Namespace，可以将不同的进程分隔在不同的 UTS Namespace 中，在某个 Namespace 修改主机名时，另一个 Namespace 的主机名还是保持不变。 目前 Linux 内核总共实现了6种 Namespace： IPC： 隔离 System V IPC 和 POSIX 消息队列 Network： 隔离网络资源 Mount： 隔离文件系统挂载点 PID： 隔离进程 ID UTS： 隔离主机名和域名 User： 隔离用户 ID 和 组 ID Namespace 和 Cgroup 的使用是灵活的，同时也有不少需要注意的地方，因此直接操作 Namespace 和 Cgroup 并不是很容易。正是因为这些原因，Docker 通过 Libcontainer 来处理这些底层的事情。这样一来，Docker 只需简单地调用 Libcontainer 的 API ，就能将完整的容器搭建起来。而作为 Docker 的用户，就更不用操心这些事情了。 容器造就 Docker关于容器是否是 Docker 的技术核心技术，业界一直存在着争议。 在理解了容器，理解了容器的核心技术 Cgroup 和 Namespace，理解了容器技术如何巧妙且轻量地实现“容器”本身的资源控制和访问隔离之后，可以看到 Docker 和容器是一种完美的融合和辅助相成的关系，它们不是唯一的搭配，但一定是最完美的结合（目前来说）。与其说是容器造就了 Docker ， 不如说是它们造就了彼此，容器技术让 Docker 得到更多的应用和推广，Docker 也使得容器技术被更多人熟知。[须知]：转载请标明出处，请尊重笔者和作者的功劳，O(∩_∩)O谢谢！[参考]:Docker 进阶与实践 华为Docker实践小组 著（机械工业出版社）","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Goddbye 2016 and Hello 2017","slug":"再见了2016，你好2017","date":"2016-12-31T09:07:55.000Z","updated":"2016-12-31T09:07:56.000Z","comments":true,"path":"再见了2016，你好2017.html/","link":"","permalink":"http://yusank.github.io/再见了2016，你好2017.html/","excerpt":"突然想写一篇文章纪念一下我的2016，语文水平不是很好，要是写的不好，就不要在意太多的细节了，以下正文。。。。","text":"突然想写一篇文章纪念一下我的2016，语文水平不是很好，要是写的不好，就不要在意太多的细节了，以下正文。。。。 再见了2016，你好2017来点音乐吧， ​ 纵观过去的这一年，发生了很多我没有预料的到时事儿，不管是感情还是学习工作方面。 ​ 去年的今天我做了不少的计划，许了不少的愿，但是实现了几个没做到几个，现在我是真想不出来。从我现在的情况来看，2016过得并不是很糟糕，也许可以用过得还不错的这句话来形容。 ​ 寒假跟每年的寒假没有任何区别，玩儿吃喝，非要说有区别的话，我还是想不起来任何的区别【微笑】。3月份回学校，做了我人生第一次烫发，自我感觉还可以。生活还是一如既往，学习吃饭周末出去通宵。就这样，2016年也快一半了，6月初的出去旅游，给我们每个人一次难忘的回忆，那回忆如此的美好，甜蜜。然而好梦总是不长的，6月末，我听到了一个我最不想听的一个消息。以前一直以为如果真有这么一天，我会怎么怎么样。但是真的碰到了这个情况的时候，我不知道该干嘛了，不知道该为自己伤心还是为她开心，但是我不认为这就是最终结果。一个对我来说是一个不是很正常的暑假的开始了，除了一个月帮老爸跑腿开车以为，我脑子里只有一个人，也许这就是爱吧。但是我一直都只动嘴皮子不干实际性的，到目前我都很后悔这事儿。 ​ 暑假结束回到学校不到两个月，我遇到了思异，遇到了我的人生转折点。大学两年荒废过去的我终于见到一丁点曙光在远处向我招手，我不能再荒废下去了，我得努力，我得为以后找出路。就这样，我的几乎每一天都是要么在实习要么在去实习的路上度过，一直到现在，2016的最后一天。 ​ 这几个月，跟她关系越来越好，感觉已经离不开她了。每次见到到都是一种幸福满，遇到她是我大学生活发生的最幸运最幸福的事情，绝对没有之一。 ​ 时间总是过得很快，一年时间说长很长说短很短，依然记得去年的今天，但是又觉得是很久之前的事儿。再过几个小时，就得送2016了，在送它之前，我还是要好好的感谢2016，给我这么多的快乐的时光，给我了配家人配爱人的时间，谢谢你！！！ ​ 在这儿我不会许什么愿做什么计划，我只是静静的等2017的到来，静静地欢迎它，不管是到来的是哪一年，我只是希望陪我欢迎新一年的人，依然是她！ 再见了2016， ​ 你好2017.","raw":null,"content":null,"categories":[],"tags":[]},{"title":"linux命令","slug":"linux命令","date":"2016-12-28T05:13:13.000Z","updated":"2016-12-28T05:13:13.000Z","comments":true,"path":"linux命令.html/","link":"","permalink":"http://yusank.github.io/linux命令.html/","excerpt":"welcome to learn terminal command!!!","text":"welcome to learn terminal command!!! linux命令永！远！不！要！执！行！你！不！清！楚！在！干！啥！的！命！令！实用性$ ls -l | sed '1d' | sort -n -k5 | awk '{printf \"%15s %10s\\n\", $9,$5}' 按文件大小增序打印出当前目录下的文件名及其文件大小(单位字节） $ history | awk '{print $2}' | sort | uniq -c | sort -rn | head -10 输出你最常用的十条命令 $ http POST http://localhost:4000/ 做测试的时候很有用的一个命令，需要下载http $ brew install http $ lsof -n -P -i TCP -s TCP:LISTEN COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME QQ 290 smartestee 33u IPv4 0x2f3beaa58a62d73b 0t0 TCP 127.0.0.1:4300 (LISTEN) QQ 290 smartestee 34u IPv4 0x2f3beaa58c69673b 0t0 TCP 127.0.0.1:4301 (LISTEN) idea 3257 smartestee 164u IPv4 0x2f3beaa588d11e43 0t0 TCP 127.0.0.1:6942 (LISTEN) idea 3257 smartestee 385u IPv4 0x2f3beaa58c69316b 0t0 TCP 127.0.0.1:63342 (LISTEN) 查看端口的使用情况 $ ps -ef 查看进程 $ kill xxxx 端口冲突时，用此命令，关闭某个端口。用PID替换xxxx $ history 查看历史命令记录 $ pwd 当前位置 $ which xx path位置，搭建环境的时候肯定会用得到 Linux 文件系统命令修改问价拥有者 $ chgrp -R 组名 文件 / 目录 $ chown -R 账户名 文件 / 目录 修改文件权限 $ chmod 使用数字 r：4, w：2, x：1 每种身份的权限的累加的。 $ chmod 777 test 使用符号修改 u: user, g: group, o: others, a: all 添加权限用+， 除去用-， 设置用= $ chmod u=rwx, g=rw, o=r test $ chmod a-x test $ chmod go+r test ​ $ sudo !! 以root权限执行上一条命令（注意上一条命令的内容，以免发生意外） 例如：在Ubuntu 安装软件或插件的时候需要用到这个命令 $ sudo apt-get install nginx 查看和修改： $ cat $ more $ less $ head $ tail $ vi $ vim $ mkdir $ touch git$ git 先给出比较常用的 $ git add $ git commit -m \"注释\" 本地提交 $ git checkout &lt;分支名或master> 切换分支与master $ git branch 新开一个分支 $ git merge 主分支与分支的合并 $ git push origin master 提交到github上 $ fuck 纠正命令行输入的错误，比手动改快，实用。 安装： $ brew install thefuck 娱乐$ cmatrix $ telnet towel.blinkenlights.nl telnet是基于Telnet协议的远程登录客户端程序,经常用来远程登录服务器.除此还可以用它来观看星球大战 $ fortune 随机输出名言或者笑话， 还有很多，有兴趣的可以通过这个链接去看：知乎 个人博客 yusank 比较牛逼的一个查找命令的网站：http://www.commandlinefu.com/commands/browse/sort-by-votes 每天都有更新各种命令组合","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Material 的配置","slug":" Material 原质","date":"2016-12-18T06:14:14.000Z","updated":"2016-12-19T06:14:14.000Z","comments":true,"path":" Material 原质.html/","link":"","permalink":"http://yusank.github.io/ Material 原质.html/","excerpt":"","text":"Material 原质Material Theme Nature, Source stay with light`s Contents 目录 General 概括 Demo 演示 Quick start 快速开始 Docs 文档 Contributing 贡献 License 许可证 Render 渲染 Changelog 开发日志 General 概括 Demo 演示Viosey’s Blog Quick start 快速开始Install Material 安装 Material Docs 文档Material Theme Docs Material 主题文档 Docs Markdown Files Contributing 贡献All kinds of contributions (enhancements, new features, documentation &amp; code improvements, issues &amp; bugs reporting) are welcome. 欢迎各种形式的贡献，包括但不限于优化，添加功能，文档 &amp; 代码的改进，问题和 bugs 的报告。期待您的 Pull Request。 License 许可证 Open sourced under the GPL v3.0 license. 根据 GPL V3.0 许可证开源。 Render 渲染","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Python 资源大全","slug":"awesomepython","date":"2016-12-17T12:55:55.000Z","updated":"2016-12-16T12:48:35.000Z","comments":true,"path":"awesomepython.html/","link":"","permalink":"http://yusank.github.io/awesomepython.html/","excerpt":"Python 资源大全中文版","text":"Python 资源大全中文版 我想很多程序员应该记得 GitHub 上有一个 Awesome - XXX 系列的资源整理。awesome-python 是 vinta 发起维护的 Python 资源列表，内容包括：Web框架、网络爬虫、网络内容提取、模板引擎、数据库、数据可视化、图片处理、文本处理、自然语言处理、机器学习、日志、代码分析等。由伯乐在线持续更新。 Awesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。 我们要做什么？ 基于 awesome-python 列表，我们将对其中的各个资源项进行编译整理。此外还将从其他来源补充好资源。 整理后的内容，将收录在伯乐在线资源频道。可参考已整理的内容： 《Scrapy：Python的爬虫框架》 《Flask：一个使用Python编写的轻量级Web应用框架》 如何参与本项目？从下面的目录来看，本项目的工作量小不了，所以非常期待能有更多程序员一起来参与。 不过加入前，有几个小要求： 英文还不错，能读懂英文并用自己的话复述； 在用 Python； 如有兴趣，请加 QQ：50872495。加 Q 时请注明「Python大全」 如何为列表贡献新资源？欢迎大家为列表贡献高质量的新资源，提交PR时请参照以下要求： 请确保推荐的资源自己使用过 提交PR时请注明推荐理由 资源列表管理收到PR请求后，会定期（每周）在微博转发本周提交的PR列表，并在微博上面听取使用过这些资源的意见。确认通过后，会加入资源大全。 感谢您的贡献！ 本项目的参与者 维护者： 贡献者：艾凌风、Namco、Daetalus、黄利民、atupal、rainbow、木头lbj、beyondwu、cissoid、李广胜、polyval、冰斌、赵叶宇、л stalgic、硕恩 注：名单不分排名，不定期补充更新 奖励计划虽然奖励可能并不是你加入的主要原因，但还是有必要提一下： 整理超过 20 个资源后，可在伯乐在线上开通打赏； 每整理 20 个资源，有机会获得技术书籍或各种有意思的创意、极客产品； 奖励详情 环境管理管理 Python 版本和环境的工具 p：非常简单的交互式 python 版本管理工具。官网 pyenv：简单的 Python 版本管理工具。官网 Vex：可以在虚拟环境中执行命令。官网 virtualenv：创建独立 Python 环境的工具。官网 virtualenvwrapper：virtualenv 的一组扩展。官网 包管理管理包和依赖的工具。 pip：Python 包和依赖关系管理工具。官网 pip-tools：保证 Python 包依赖关系更新的一组工具。官网 conda：跨平台，Python 二进制包管理工具。官网 Curdling：管理 Python 包的命令行工具。官网 wheel：Python 分发的新标准，意在取代 eggs。官网 包仓库本地 PyPI 仓库服务和代理。 warehouse：下一代 PyPI。官网 Warehouse：PyPA 提供的 PyPI 镜像工具。官网 bandersnatch devpi：PyPI 服务和打包/测试/分发工具。官网 localshop：本地 PyPI 服务（自定义包并且自动对 PyPI 镜像）。官网 分发打包为可执行文件以便分发。 PyInstaller：将 Python 程序转换成独立的执行文件（跨平台）。官网 dh-virtualenv：构建并将 virtualenv 虚拟环境作为一个 Debian 包来发布。官网 Nuitka：将脚本、模块、包编译成可执行文件或扩展模块。官网 py2app：将 Python 脚本变为独立软件包（Mac OS X）。官网 py2exe：将 Python 脚本变为独立软件包（Windows）。官网 pynsist：一个用来创建 Windows 安装程序的工具，可以在安装程序中打包 Python本身。官网 构建工具将源码编译成软件。 buildout：一个构建系统，从多个组件来创建，组装和部署应用。官网 BitBake：针对嵌入式 Linux 的类似 make 的构建工具。官网 fabricate：对任何语言自动找到依赖关系的构建工具。官网 PlatformIO：多平台命令行构建工具。官网 PyBuilder：纯 Python 实现的持续化构建工具。官网 SCons：软件构建工具。官网 交互式解析器交互式 Python 解析器。 IPython：功能丰富的工具，非常有效的使用交互式 Python。官网 bpython：界面丰富的 Python 解析器。官网 ptpython：高级交互式Python解析器， 构建于python-prompt-toolkit 之上。官网 文件文件管理和 MIME（多用途的网际邮件扩充协议）类型检测。 imghdr：（Python 标准库）检测图片类型。官网 mimetypes：（Python 标准库）将文件名映射为 MIME 类型。官网 path.py：对 os.path 进行封装的模块。官网 pathlib：（Python3.4+ 标准库）跨平台的、面向对象的路径操作库。官网 python-magic：文件类型检测的第三方库 libmagic 的 Python 接口。官网 Unipath：用面向对象的方式操作文件和目录。官网 watchdog：管理文件系统事件的 API 和 shell 工具官网 日期和时间操作日期和时间的类库。 arrow：更好的 Python 日期时间操作类库。官网 Chronyk：Python 3 的类库，用于解析手写格式的时间和日期。官网 dateutil：Python datetime 模块的扩展。官网 delorean：解决 Python 中有关日期处理的棘手问题的库。官网 moment：一个用来处理时间和日期的Python库。灵感来自于Moment.js。官网 PyTime：一个简单易用的Python模块，用于通过字符串来操作日期/时间。官网 pytz：现代以及历史版本的世界时区定义。将时区数据库引入Python。官网 when.py：提供用户友好的函数来帮助用户进行常用的日期和时间操作。官网 文本处理用于解析和操作文本的库。 通用 chardet：字符编码检测器，兼容 Python2 和 Python3。官网 difflib：(Python 标准库)帮助我们进行差异化比较。官网 ftfy：让Unicode文本更完整更连贯。官网 fuzzywuzzy：模糊字符串匹配。官网 Levenshtein：快速计算编辑距离以及字符串的相似度。官网 pangu.py：在中日韩语字符和数字字母之间添加空格。官网 yfiglet-figlet：pyfiglet -figlet 的 Python实现。 shortuuid：一个生成器库，用以生成简洁的，明白的，URL 安全的 UUID。官网 unidecode：Unicode 文本的 ASCII 转换形式 。官网 uniout：打印可读的字符，而不是转义的字符串。官网 xpinyin：一个用于把汉字转换为拼音的库。官网 simplejson：Python的JSON编码、解码器。官网、GitHub Slug化 awesome-slugify：一个 Python slug 化库，可以保持 Unicode。官网 python-slugify：Python slug 化库，可以把 unicode 转化为 ASCII。官网 unicode-slugify：一个 slug 工具，可以生成 unicode slugs ,需要依赖 Django 。官网 解析器 phonenumbers：解析，格式化，储存，验证电话号码。官网 PLY：lex 和 yacc 解析工具的 Python 实现。官网 Pygments：通用语法高亮工具。官网 pyparsing：生成通用解析器的框架。官网 python-nameparser：把一个人名分解为几个独立的部分。官网 python-user-agents：浏览器 user agent 解析器。官网 sqlparse：一个无验证的 SQL 解析器。官网 特殊文本格式处理一些用来解析和操作特殊文本格式的库。 通用 tablib：一个用来处理中表格数据的模块。官网 Office Marmir：把输入的Python 数据结构转换为电子表单。官网 openpyxl：一个用来读写 Excel 2010 xlsx/xlsm/xltx/xltm 文件的库。官网 python-docx：读取，查询以及修改 Microsoft Word 2007/2008 docx 文件。官网 unoconv：在 LibreOffice/OpenOffice 支持的任意文件格式之间进行转换。官网 XlsxWriter：一个用于创建 Excel .xlsx 文件的 Python 模块。官网 xlwings：一个使得在 Excel 中方便调用 Python 的库（反之亦然），基于 BSD 协议。官网 xlwt：读写 Excel 文件的数据和格式信息。官网 / xlrd relatorio：模板化OpenDocument 文件。官网 PDF PDFMiner：一个用于从PDF文档中抽取信息的工具。官网 PyPDF2：一个可以分割，合并和转换 PDF 页面的库。官网 ReportLab：快速创建富文本 PDF 文档。官网 Markdown Mistune：快速并且功能齐全的纯 Python 实现的 Markdown 解析器。官网 Python-Markdown：John Gruber’s Markdown 的 Python 版实现。官网 Python-Markdiwn2：纯 Python 实现的 Markdown 解析器，比 Python-Markdown 更快，更准确，可扩展。官网 YAML PyYAML：Python 版本的 YAML 解析器。官网 CSV csvkit：用于转换和操作 CSV 的工具。官网 Archive unp：一个用来方便解包归档文件的命令行工具。官网 自然语言处理用来处理人类语言的库。 NLTK：一个先进的平台，用以构建处理人类语言数据的 Python 程序。官网 jieba：中文分词工具。官网 langid.py：独立的语言识别系统。官网 Pattern：Python 网络信息挖掘模块。官网 SnowNLP：一个用来处理中文文本的库。官网 TextBlob：为进行普通自然语言处理任务提供一致的 API。官网 TextGrocery：一简单高效的短文本分类工具，基于 LibLinear 和 Jieba。官网 文档用以生成项目文档的库。 Sphinx：Python 文档生成器。官网 awesome-sphinxdoc：官网 MkDocs：对 Markdown 友好的文档生成器。官网 pdoc：一个可以替换Epydoc 的库，可以自动生成 Python 库的 API 文档。官网 Pycco：文学编程（literate-programming）风格的文档生成器。官网 配置用来保存和解析配置的库。 config：logging 模块作者写的分级配置模块。官网 ConfigObj：INI 文件解析器，带验证功能。官网 ConfigParser：(Python 标准库) INI 文件解析器。官网 profig：通过多种格式进行配置，具有数值转换功能。官网 python-decouple：将设置和代码完全隔离。官网 命令行工具用于创建命令行程序的库。 命令行程序开发 cement：Python 的命令行程序框架。官网 click：一个通过组合的方式来创建精美命令行界面的包。官网 cliff：一个用于创建命令行程序的框架，可以创建具有多层命令的命令行程序。官网 clint：Python 命令行程序工具。官网 colorama：跨平台彩色终端文本。官网 docopt：Python 风格的命令行参数解析器。官网 Gooey：一条命令，将命令行程序变成一个 GUI 程序。官网 python-prompt-toolkit：一个用于构建强大的交互式命令行程序的库。官网 Pythonpy：在命令行中直接执行任何Python指令。官网 生产力工具 aws-cli：Amazon Web Services 的通用命令行界面。官网 bashplotlib：在终端中进行基本绘图。官网 caniusepython3：判断是哪个项目妨碍你你移植到 Python 3。官网 cookiecutter：从 cookiecutters（项目模板）创建项目的一个命令行工具。官网 doitlive：一个用来在终端中进行现场演示的工具。官网 howdoi：通过命令行获取即时的编程问题解答。官网 httpie：一个命令行HTTP 客户端，cURL 的替代品，易用性更好。官网 PathPicker：从bash输出中选出文件。官网 percol：向UNIX shell 传统管道概念中加入交互式选择功能。官网 SAWS：一个加强版的 AWS 命令行。官网 thefuck：修正你之前的命令行指令。官网 mycli：一个 MySQL 命令行客户端，具有自动补全和语法高亮功能。官网 pgcli：Postgres 命令行工具，具有自动补全和语法高亮功能。官网 下载器用来进行下载的库. s3cmd：一个用来管理Amazon S3 和 CloudFront 的命令行工具。官网 s4cmd：超级 S3 命令行工具，性能更加强劲。官网 you-get：一个 YouTube/Youku/Niconico 视频下载器，使用 Python3 编写。官网 youtube-dl：一个小巧的命令行程序，用来下载 YouTube 视频。官网 图像处理用来操作图像的库. pillow：Pillow 是一个更加易用版的 PIL。官网 hmap：图像直方图映射。官网 imgSeek：一个使用视觉相似性搜索一组图片集合的项目。官网 nude.py：裸体检测。官网 pyBarcode：不借助 PIL 库在 Python 程序中生成条形码。官网 pygram：类似 Instagram 的图像滤镜。官网 python-qrcode：一个纯 Python 实现的二维码生成器。官网 Quads：基于四叉树的计算机艺术。官网 scikit-image：一个用于（科学）图像处理的 Python 库。官网 thumbor：一个小型图像服务，具有剪裁，尺寸重设和翻转功能。官网 wand：MagickWand的Python 绑定。MagickWand 是 ImageMagick的 C API 。官网 OCR光学字符识别库。 pyocr：Tesseract 和 Cuneiform 的一个封装(wrapper)。官网 pytesseract：Google Tesseract OCR 的另一个封装(wrapper)。官网 python-tesseract - Google Tesseract OCR 的一个包装类。 音频用来操作音频的库 audiolazy：Python 的数字信号处理包。官网 audioread：交叉库 (GStreamer + Core Audio + MAD + FFmpeg) 音频解码。官网 beets：一个音乐库管理工具及 MusicBrainz 标签添加工具官网 dejavu：音频指纹提取和识别官网 django-elastic-transcoder：Django + Amazon Elastic Transcoder。官网 eyeD3：一个用来操作音频文件的工具，具体来讲就是包含 ID3 元信息的 MP3 文件。官网 id3reader：一个用来读取 MP3 元数据的 Python 模块。官网 m3u8：一个用来解析 m3u8 文件的模块。官网 mutagen：一个用来处理音频元数据的 Python 模块。官网 pydub：通过简单、简洁的高层接口来操作音频文件。官网 pyechonest：Echo Nest API 的 Python 客户端官网 talkbox：一个用来处理演讲/信号的 Python 库官网 TimeSide：开源 web 音频处理框架。官网 tinytag：一个用来读取MP3, OGG, FLAC 以及 Wave 文件音乐元数据的库。官网 mingus：一个高级音乐理论和曲谱包，支持 MIDI 文件和回放功能。官网 Video用来操作视频和GIF的库。 moviepy：一个用来进行基于脚本的视频编辑模块，适用于多种格式，包括动图 GIFs。官网 scikit-video：SciPy 视频处理常用程序。官网 地理位置地理编码地址以及用来处理经纬度的库。 GeoDjango：世界级地理图形 web 框架。官网 GeoIP：MaxMind GeoIP Legacy 数据库的 Python API。官网 geojson：GeoJSON 的 Python 绑定及工具。官网 geopy：Python 地址编码工具箱。官网 pygeoip：纯 Python GeoIP API。官网 django-countries：一个 Django 应用程序，提供用于表格的国家选择功能，国旗图标静态文件以及模型中的国家字段。官网 HTTP使用HTTP的库。 requests：人性化的HTTP请求库。官网 grequests：requests 库 + gevent ，用于异步 HTTP 请求.官网 httplib2：全面的 HTTP 客户端库。官网 treq：类似 requests 的Python API 构建于 Twisted HTTP 客户端之上。官网 urllib3：一个具有线程安全连接池，支持文件 post，清晰友好的 HTTP 库。官网 数据库Python实现的数据库。 pickleDB：一个简单，轻量级键值储存数据库。官网 PipelineDB：流式 SQL 数据库。官网 TinyDB：一个微型的，面向文档型数据库。官网 ZODB：一个 Python 原生对象数据库。一个键值和对象图数据库。官网 数据库驱动用来连接和操作数据库的库。 MySQL：awesome-mysql系列 mysql-python：Python 的 MySQL 数据库连接器。官网 ysqlclient：mysql-python 分支，支持 Python 3。 oursql：一个更好的 MySQL 连接器，支持原生预编译指令和 BLOBs.官网 PyMySQL：纯 Python MySQL 驱动，兼容 mysql-python。官网 PostgreSQL psycopg2：Python 中最流行的 PostgreSQL 适配器。官网 queries：psycopg2 库的封装，用来和 PostgreSQL 进行交互。官网 txpostgres：基于 Twisted 的异步 PostgreSQL 驱动。官网 其他关系型数据库 apsw：另一个 Python SQLite封装。官网 dataset：在数据库中存储Python字典 pymssql：一个简单的Microsoft SQL Server数据库接口。官网 NoSQL 数据库 cassandra-python-driver：Cassandra 的 Python 驱动。官网 HappyBase：一个为 Apache HBase 设计的，对开发者友好的库。官网 Plyvel：一个快速且功能丰富的 LevelDB 的 Python 接口。官网 py2neo：Neo4j restful 接口的Python 封装客户端。官网 pycassa：Cassandra 的 Python Thrift 驱动。官网 PyMongo：MongoDB 的官方 Python 客户端。官网 redis-py：Redis 的 Python 客户端。官网 telephus：基于 Twisted 的 Cassandra 客户端。官网 txRedis：基于 Twisted 的 Redis 客户端。官网 ORM实现对象关系映射或数据映射技术的库。 关系型数据库 Django Models：Django 的一部分。官网 SQLAlchemy：Python SQL 工具以及对象关系映射工具。官网 awesome-sqlalchemy系列 Peewee：一个小巧，富有表达力的 ORM。官网 PonyORM：提供面向生成器的 SQL 接口的 ORM。官网 python-sql：编写 Python 风格的 SQL 查询。官网 NoSQL 数据库 django-mongodb-engine：Django MongoDB 后端。官网 PynamoDB：Amazon DynamoDB 的一个 Python 风格接口。官网 flywheel：Amazon DynamoDB 的对象映射工具。官网 MongoEngine：一个Python 对象文档映射工具，用于 MongoDB。官网 hot-redis：为 Redis 提供 Python 丰富的数据类型。官网 redisco：一个 Python 库，提供可以持续存在在 Redis 中的简单模型和容器。官网 其他 butterdb：Google Drive 电子表格的 Python ORM。官网 Web 框架全栈 Web 框架。 Django：Python 界最流行的 web 框架。官网 awesome-django系列 Flask：一个 Python 微型框架。官网 awesome-flask系列 pyramid：一个小巧，快速，接地气的开源Python web 框架。 awesome-pyramid系列 Bottle：一个快速小巧，轻量级的 WSGI 微型 web 框架。官网 CherryPy：一个极简的 Python web 框架，服从 HTTP/1.1 协议且具有WSGI 线程池。官网 TurboGears：一个可以扩展为全栈解决方案的微型框架。官网 web.py：一个 Python 的 web 框架，既简单，又强大。官网 web2py：一个全栈 web 框架和平台，专注于简单易用。官网 Tornado：一个web 框架和异步网络库。官网 权限允许或拒绝用户访问数据或功能的库。 Carteblanche：Module to align code with thoughts of users and designers. Also magically handles navigation and permissions.官网 django-guardian：Django 1.2+ 实现了单个对象权限。官网 django-rules：一个小巧但是强大的应用，提供对象级别的权限管理，且不需要使用数据库。官网 CMS内容管理系统 odoo-cms: 一个开源的，企业级 CMS，基于odoo。官网 django-cms：一个开源的，企业级 CMS，基于 Django。官网 djedi-cms：一个轻量级但却非常强大的 Django CMS ，考虑到了插件，内联编辑以及性能。官网 FeinCMS：基于 Django 构建的最先进的内容管理系统之一。官网 Kotti：一个高级的，Python 范的 web 应用框架，基于 Pyramid 构建。官网 Mezzanine：一个强大的，持续的，灵活的内容管理平台。官网 Opps：一个为杂志，报纸网站以及大流量门户网站设计的 CMS 平台，基于 Django。官网 Plone：一个构建于开源应用服务器 Zope 之上的 CMS。官网 Quokka：灵活，可扩展的小型 CMS，基于 Flask 和 MongoDB。官网 Wagtail：一个 Django 内容管理系统。官网 Widgy：最新的 CMS 框架，基于 Django。官网 电子商务用于电子商务以及支付的框架和库。 django-oscar：一个用于 Django 的开源的电子商务框架。官网 django-shop：一个基于 Django 的店铺系统。官网 Cartridge：一个基于 Mezzanine 构建的购物车应用。官网 shoop：一个基于 Django 的开源电子商务平台。官网 alipay：非官方的 Python 支付宝 API。官网 merchant：一个可以接收来自多种支付平台支付的 Django 应用。官网 money：货币类库with optional CLDR-backed locale-aware formatting and an extensible currency exchange solution.官网 python-currencies：显示货币格式以及它的数值。官网 RESTful API用来开发RESTful APIs的库 Django django-rest-framework：一个强大灵活的工具，用来构建 web API。官网 django-tastypie：为Django 应用开发API。官网 django-formapi：为 Django 的表单验证，创建 JSON APIs 。官网 Flask flask-api：为 flask 开发的，可浏览 Web APIs 。官网 flask-restful：为 flask 快速创建REST APIs 。官网 flask-restless：为 SQLAlchemy 定义的数据库模型创建 RESTful APIs 。官网 flask-api-utils：为 Flask 处理 API 表示和验证。官网 eve：REST API 框架，由 Flask, MongoDB 等驱动。官网 Pyramid cornice：一个Pyramid 的 REST 框架 。官网 与框架无关的 falcon：一个用来建立云 API 和 web app 后端的高性能框架。官网 sandman：为现存的数据库驱动系统自动创建 REST APIs 。官网 restless：框架无关的 REST 框架 ，基于从 Tastypie 学到的知识。官网 ripozo：快速创建 REST/HATEOAS/Hypermedia APIs。官网 验证实现验证方案的库。 OAuth Authomatic：简单但是强大的框架，身份验证/授权客户端。官网 django-allauth：Django 的验证应用。官网 django-oauth-toolkit：为 Django 用户准备的 OAuth2。官网 django-oauth2-provider：为 Django 应用提供 OAuth2 接入。官网 Flask-OAuthlib：OAuth 1.0/a, 2.0 客户端实现，供 Flask 使用。官网 OAuthLib：一个 OAuth 请求-签名逻辑通用、 完整的实现。官网 python-oauth2：一个完全测试的抽象接口。用来创建 OAuth 客户端和服务端。官网 python-social-auth：一个设置简单的社会化验证方式。官网 rauth：OAuth 1.0/a, 2.0, 和 Ofly 的 Python 库。官网 sanction：一个超级简单的OAuth2 客户端实现。官网 其他 jose：JavaScript 对象签名和加密草案的实现。官网 PyJWT：JSON Web 令牌草案 01。官网 python-jws：JSON Web 签名草案 02 的实现。官网 python-jwt：一个用来生成和验证 JSON Web 令牌的模块。官网 模板引擎模板生成和词法解析的库和工具。 Jinja2：一个现代的，对设计师友好的模板引擎。官网 Chameleon：一个 HTML/XML 模板引擎。 模仿了 ZPT（Zope Page Templates）, 进行了速度上的优化。官网 Genshi：Python 模板工具，用以生成 web 感知的结果。官网 Mako：Python 平台的超高速轻量级模板。官网 Queue处理事件以及任务队列的库。 celery：一个异步任务队列/作业队列，基于分布式消息传递。官网 huey：小型多线程任务队列。官网 mrq：Mr. Queue -一个 Python 的分布式 worker 任务队列， 使用 Redis 和 gevent。官网 rq：简单的 Python 作业队列。官网 simpleq：一个简单的，可无限扩张的，基于亚马逊 SQS 的队列。官网 搜索对数据进行索引和执行搜索查询的库和软件。 django-haystack：Django 模块化搜索。官网 elasticsearch-py：Elasticsearch 的官方底层 Python 客户端。官网 elasticsearch-dsl-py：Elasticsearch 的官方高级 Python 客户端。官网 solrpy：solr的 Python 客户端。官网 Whoosh：一个快速的纯 Python 搜索引擎库。官网 动态消息用来创建用户活动的库。 django-activity-stream：从你的站点行为中生成通用活动信息流。官网 Stream-Framework：使用 Cassandra 和 Redis 创建动态消息和通知系统。官网 资源管理管理、压缩、缩小网站资源的工具。 django-compressor：将链接和内联的 JavaScript 或 CSS 压缩到一个单独的缓存文件中。官网 django-storages：一个针对 Django 的自定义存储后端的工具集合。官网 fanstatic：打包、优化，并且把静态文件依赖作为 Python 的包来提供。官网 File Conveyor：一个后台驻留的程序，用来发现和同步文件到 CDNs, S3 和 FTP。官网 Flask-Assets：帮你将 web 资源整合到你的 Flask app 中。官网 jinja-assets-compressor：一个 Jinja 扩展，用来编译和压缩你的资源。官网 webassets：为你的静态资源打包、优化和管理生成独一无二的缓存 URL。官网 缓存缓存数据的库。 Beaker：一个缓存和会话库，可以用在 web 应用和独立 Python脚本和应用上。官网 django-cache-machine：Django 模型的自动缓存和失效。官网 django-cacheops：具有自动颗粒化事件驱动失效功能的 ORM。官网 django-viewlet：渲染模板，同时具有额外的缓存控制功能。官网 dogpile.cache：dogpile.cache 是 Beaker 的下一代替代品，由同一作者开发。官网 HermesCache：Python 缓存库，具有基于标签的失效和 dogpile effect 保护功能。官网 johnny-cache：django应用缓存框架。官网 pylibmc：libmemcached 接口的 Python 封装。官网 电子邮件用来发送和解析电子邮件的库。 django-celery-ses：带有 AWS SES 和 Celery 的 Django email 后端。官网 envelopes：供人类使用的电子邮件库。官网 flanker：一个 email 地址和 Mime 解析库。官网 imbox：Python IMAP 库官网 inbox.py：Python SMTP 服务器。官网 inbox：一个开源电子邮件工具箱。官网 lamson：Python 风格的 SMTP 应用服务器。官网 mailjet：Mailjet API 实现，用来提供批量发送邮件，统计等功能。官网 marrow.mailer：高性能可扩展邮件分发框架。官网 modoboa：一个邮件托管和管理平台，具有现代的、简约的 Web UI。官网 pyzmail：创建，发送和解析电子邮件。官网 Talon：Mailgun 库，用来抽取信息和签名。官网 国际化用来进行国际化的库。 Babel：一个Python 的国际化库。官网 Korean：一个韩语词态库。官网 URL处理解析URLs的库 furl：一个让处理 URL 更简单小型 Python 库。官网 purl：一个简单的，不可变的URL类，具有简洁的 API 来进行询问和处理。官网 pyshorteners：一个纯 Python URL 缩短库。官网 shorturl：生成短小 URL 和类似 bit.ly 短链的Python 实现。官网 webargs：一个解析 HTTP 请求参数的库，内置对流行 web 框架的支持，包括 Flask, Django, Bottle, Tornado和 Pyramid。官网 HTML处理处理 HTML和XML的库。 BeautifulSoup：以 Python 风格的方式来对 HTML 或 XML 进行迭代，搜索和修改。官网 bleach：一个基于白名单的 HTML 清理和文本链接库。官网 cssutils：一个 Python 的 CSS 库。官网 html5lib：一个兼容标准的 HTML 文档和片段解析及序列化库。官网 lxml：一个非常快速，简单易用，功能齐全的库，用来处理 HTML 和 XML。官网 MarkupSafe：为Python 实现 XML/HTML/XHTML 标记安全字符串。官网 pyquery：一个解析 HTML 的库，类似 jQuery。官网 untangle：将XML文档转换为Python对象，使其可以方便的访问。官网 xhtml2pdf：HTML/CSS 转 PDF 工具。官网 xmltodict：像处理 JSON 一样处理 XML。官网 爬取网络站点的库 Scrapy：一个快速高级的屏幕爬取及网页采集框架。官网 cola：一个分布式爬虫框架。官网 Demiurge：基于PyQuery 的爬虫微型框架。官网 feedparser：通用 feed 解析器。官网 Grab：站点爬取框架。官网 MechanicalSoup：用于自动和网络站点交互的 Python 库。官网 portia：Scrapy 可视化爬取。官网 pyspider：一个强大的爬虫系统。官网 RoboBrowser：一个简单的，Python 风格的库，用来浏览网站，而不需要一个独立安装的浏览器。官网 网页内容提取用于进行网页内容提取的库。 Haul：一个可以扩展的图像爬取工具。官网 html2text：将 HTML 转换为 Markdown 格式文本官网 lassie：人性化的网页内容检索库。官网 micawber：一个小型网页内容提取库，用来从 URLs 提取富内容。官网 newspaper：使用 Python 进行新闻提取，文章提取以及内容策展。官网 opengraph：一个用来解析开放内容协议(Open Graph Protocol)的 Python模块。官网 python-goose：HTML内容/文章提取器。官网 python-readability：arc90 公司 readability 工具的 Python 高速端口。官网 sanitize：为杂乱的数据世界带来调理性。官网 sumy：一个为文本文件和 HTML 页面进行自动摘要的模块。官网 textract：从任何格式的文档中提取文本，Word，PowerPoint，PDFs 等等。官网 表单进行表单操作的库。 Deform：Python HTML 表单生成库，受到了 formish 表单生成库的启发。官网 django-bootstrap3：集成了 Bootstrap 3 的 Django。官网 django-crispy-forms：一个 Django 应用，他可以让你以一种非常优雅且 DRY（Don’t repeat yourself） 的方式来创建美观的表单。官网 django-remote-forms：一个平台独立的 Django 表单序列化工具。官网 WTForms：一个灵活的表单验证和呈现库。官网 WTForms-JSON：一个 WTForms 扩展，用来处理 JSON 数据。官网 数据验证数据验证库。多用于表单验证。 Cerberus：A mappings-validator with a variety of rules, normalization-features and simple customization that uses a pythonic schema-definition.官网 colander：一个用于对从 XML, JSON，HTML 表单获取的数据或其他同样简单的序列化数据进行验证和反序列化的系统。官网 kmatch：一种用于匹配/验证/筛选 Python 字典的语言。官网 schema：一个用于对 Python 数据结构进行验证的库。官网 Schematics：数据结构验证。官网 valideer：轻量级可扩展的数据验证和适配库。官网 voluptuous：一个 Python 数据验证库。主要是为了验证传入 Python的 JSON，YAML 等数据。官网 反垃圾技术帮助你和电子垃圾进行战斗的库。 django-simple-captcha：一个简单、高度可定制的Django 应用，可以为任何Django表单添加验证码。官网 django-simple-spam-blocker：一个用于Django的简单的电子垃圾屏蔽工具。官网 标记用来进行标记的库。 django-taggit：简单的 Django 标记工具。官网 管理面板管理界面库。 Ajenti：一个你的服务器值得拥有的管理面板。官网 django-suit：Django 管理界面的一个替代品 (仅对于非商业用途是免费的)。官网 django-xadmin：Django admin 的一个替代品，具有很多不错的功能。官网 flask-admin：一个用于 Flask 的简单可扩展的管理界面框架。官网 flower：一个对 Celery 集群进行实时监控和提供 web 管理界面的工具。官网 Grappelli：Django 管理界面的一个漂亮的皮肤。官网 Wooey：一个 Django 应用，可以为 Python 脚本创建 web 用户界面。官网 静态站点生成器静态站点生成器是一个软件，它把文本和模板作为输入，然后输出HTML文件。 Pelican：使用 Markdown 或 ReST 来处理内容， Jinja 2 来制作主题。支持 DVCS, Disqus.。AGPL 许可。官网 Cactus：为设计师设计的静态站点生成器。官网 Hyde：基于 Jinja2 的静态站点生成器。官网 Nikola：一个静态网站和博客生成器。官网 Tinkerer：Tinkerer 是一个博客引擎/静态站点生成器，由Sphinx驱动。官网 Lektor：一个简单易用的静态 CMS 和博客引擎。官网 进程操作系统进程启动及通信库。 envoy：比 Python subprocess 模块更人性化。官网 sarge：另一 种 subprocess 模块的封装。官网 sh：一个完备的 subprocess 替代库。官网 并发和并行用以进行并发和并行操作的库。 multiprocessing：(Python 标准库) 基于进程的“线程”接口。官网 threading：(Python 标准库)更高层的线程接口。官网 eventlet：支持 WSGI 的异步框架。官网 gevent：一个基于协程的 Python 网络库，使用greenlet。官网 Tomorrow：用于产生异步代码的神奇的装饰器语法实现。官网 网络用于网络编程的库。 asyncio：(Python 标准库) 异步 I/O, 事件循环, 协程以及任务。官网 Twisted：一个事件驱动的网络引擎。官网 pulsar：事件驱动的并发框架。官网 diesel：基于Greenlet 的事件 I/O 框架。官网 pyzmq：一个 ZeroMQ 消息库的 Python 封装。官网 txZMQ：基于 Twisted 的 ZeroMQ 消息库的 Python 封装。官网 WebSocket帮助使用WebSocket的库。 AutobahnPython：给 Python 、使用的 WebSocket &amp; WAMP 基于 Twisted 和 asyncio。官网 Crossbar：开源统一应用路由(Websocket &amp; WAMP for Python on Autobahn).官网 django-socketio：给 Django 用的 WebSockets。官网 WebSocket-for-Python：为Python2/3 以及 PyPy 编写的 WebSocket 客户端和服务器库。官网 WSGI 服务器兼容 WSGI 的 web 服务器 gunicorn：Pre-forked, 部分是由 C 语言编写的。官网 uwsgi：uwsgi 项目的目的是开发一组全栈工具，用来建立托管服务， 由 C 语言编写。官网 bjoern：异步，非常快速，由 C 语言编写。官网 fapws3：异步 (仅对于网络端)，由 C 语言编写。官网 meinheld：异步，部分是由 C 语言编写的。官网 netius：异步，非常快速。官网 paste：多线程，稳定，久经考验。官网 rocket：多线程。官网 waitress：多线程, 是它驱动着 Pyramid 框架。官网 Werkzeug：一个 WSGI 工具库，驱动着 Flask ，而且可以很方便大嵌入到你的项目中去。官网 RPC 服务器兼容 RPC 的服务器。 SimpleJSONRPCServer：这个库是 JSON-RPC 规范的一个实现。官网 SimpleXMLRPCServer：(Python 标准库) 简单的 XML-RPC 服务器实现，单线程。官网 zeroRPC：zerorpc 是一个灵活的 RPC 实现，基于 ZeroMQ 和 MessagePack。官网 密码学 cryptography：这个软件包意在提供密码学基本内容和方法提供给 Python 开发者。官网 hashids：在 Python 中实现 hashids 。官网 Paramiko：SSHv2 协议的 Python (2.6+, 3.3+) ，提供客户端和服务端的功能。官网 Passlib：安全密码存储／哈希库，官网 PyCrypto：Python 密码学工具箱。官网 PyNacl：网络和密码学(NaCl) 库的 Python 绑定。官网 图形用户界面用来创建图形用户界面程序的库。 curses：内建的 ncurses 封装，用来创建终端图形用户界面。官网 enaml：使用类似 QML 的Declaratic语法来创建美观的用户界面。官网 kivy：一个用来创建自然用户交互（NUI）应用程序的库，可以运行在 Windows, Linux, Mac OS X, Android 以及 iOS平台上。官网 pyglet：一个Python 的跨平台窗口及多媒体库。官网 PyQt：跨平台用户界面框架 Qt 的 Python 绑定 ，支持Qt v4 和 Qt v5。官网 PySide：P跨平台用户界面框架 Qt 的 Python 绑定 ，支持Qt v4。官网 Tkinter：Tkinter 是 Python GUI 的一个事实标准库。官网 Toga：一个 Python 原生的, 操作系统原生的 GUI 工具包。官网 urwid：一个用来创建终端 GUI 应用的库，支持组件，事件和丰富的色彩等。官网 wxPython：wxPython 是 wxWidgets C++ 类库和 Python 语言混合的产物。官网 PyGObject：GLib/GObject/GIO/GTK+ (GTK+3) 的 Python 绑定官网 Flexx：Flexx 是一个纯 Python 语言编写的用来创建 GUI 程序的工具集，它使用 web 技术进行界面的展示。官网 游戏开发超赞的游戏开发库。 Cocos2d：cocos2d 是一个用来开发 2D 游戏， 示例和其他图形/交互应用的框架。基于 pyglet。官网 Panda3D：由迪士尼开发的 3D 游戏引擎，并由卡内基梅陇娱乐技术中心负责维护。使用C++编写, 针对 Python 进行了完全的封装。官网 Pygame：Pygame 是一组 Python 模块，用来编写游戏。官网 PyOgre：Ogre 3D 渲染引擎的 Python 绑定，可以用来开发游戏和仿真程序等任何 3D 应用。官网 PyOpenGL：OpenGL 的 Python 绑定及其相关 APIs。官网 PySDL2：SDL2 库的封装，基于 ctypes。官网 RenPy：一个视觉小说（visual novel）引擎。官网 日志用来生成和操作日志的库。 logging：(Python 标准库) 为 Python 提供日志功能。官网 logbook：Logging 库的替代品。官网 Eliot：为复杂的和分布式系统创建日志。官网 Raven：Sentry的 Python 客户端。官网 Sentry：实时记录和收集日志的服务器。官网 Testing进行代码库测试和生成测试数据的库。 测试框架 unittest：(Python 标准库) 单元测试框架。官网 nose：nose 扩展了 unittest 的功能。官网 contexts：一个 Python 3.3+ 的 BDD 框架。受到C# – Machine.Specifications的启发。官网 hypothesis：Hypothesis 是一个基于先进的 Quickcheck 风格特性的测试库。官网 mamba：Python 的终极测试工具， 拥护BDD。官网 PyAutoGUI：PyAutoGUI 是一个人性化的跨平台 GUI 自动测试模块。官网 pyshould：Should 风格的断言，基于 PyHamcrest。官网 pytest：一个成熟的全功能 Python 测试工具。官网 green：干净，多彩的测试工具。官网 pyvows：BDD 风格的测试工具，受Vows.js的启发。官网- Robot Framework：一个通用的自动化测试框架。官网 Web 测试 Selenium：Selenium WebDriver 的 Python 绑定。官网 locust：使用 Python 编写的，可扩展的用户加载测试工具。官网 sixpack：一个和语言无关的 A/B 测试框架。官网 splinter：开源的 web 应用测试工具。官网 Mock测试 mock：(Python 标准库) 一个用于伪造测试的库。官网 doublex：Python 的一个功能强大的 doubles 测试框架。官网 freezegun：通过伪造日期模块来生成不同的时间。官网 httmock：针对 Python 2.6+ 和 3.2+ 生成 伪造请求的库。官网 httpretty：Python 的 HTTP 请求 mock 工具。官网 responses：伪造 Python 中的 requests 库的一个通用库。官网 VCR.py：在你的测试中记录和重放 HTTP 交互。官网 对象工厂 factoryboy：一个 Python 用的测试固件 (test fixtures) 替代库。官网 mixer：另外一个测试固件 (test fixtures) 替代库，支持 Django, Flask, SQLAlchemy, Peewee 等。官网 modelmommy：为 Django 测试创建随机固件官网 代码覆盖率 coverage：代码覆盖率测量。官网 伪数据 faker：一个 Python 库，用来生成伪数据。官网 fake2db：伪数据库生成器。官网 radar：生成随机的日期/时间。官网 错误处理 FuckIt.py：FuckIt.py 使用最先进的技术来保证你的 Python 代码无论对错都能继续运行。官网 代码分析和Lint工具进行代码分析，解析和操作代码库的库和工具。 代码分析 code2flow：把你的 Python 和 JavaScript 代码转换为流程图。官网 pycallgraph：这个库可以把你的Python 应用的流程(调用图)进行可视化。官网 pysonar2：Python 类型推断和检索工具。官网 Lint工具 Flake8：模块化源码检查工具: pep8, pyflakes 以及 co。官网 Pylint：一个完全可定制的源码分析器。官网 pylama：Python 和 JavaScript 的代码审查工具。官网 代码格式化 autopep8：自动格式化 Python 代码，以使其符合 PEP8 规范。官网 Debugging Tools用来进行代码调试的库。 调试器 ipdb：IPython 启用的 pdb。官网 pudb：全屏，基于控制台的 Python 调试器。官网 pyringe：可以在 Python 进程中附加和注入代码的调试器。官网 wdb：一个奇异的 web 调试器，通过 WebSockets 工作。官网 winpdb：一个具有图形用户界面的 Python 调试器，可以进行远程调试，基于 rpdb2。官网 django-debug-toolbar：为 Django 显示各种调试信息。官网 django-devserver：一个 Django 运行服务器的替代品。官网 flask-debugtoolbar：django-debug-toolbar 的 flask 版。官网 性能分析器 lineprofiler：逐行性能分析。官网 Memory Profiler：监控 Python 代码的内存使用。官网、内存 profiling：一个交互式 Python 性能分析工具。官网 其他 pyelftools：解析和分析 ELF 文件以及 DWARF 调试信息。官网 python-statsd：statsd 服务器的 Python 客户端。官网 Science and Data Analysis用来进行科学计算和数据分析的库。 astropy：一个天文学 Python 库。官网 bcbio-nextgen：这个工具箱为全自动高通量测序分析提供符合最佳实践的处理流程。官网 bccb：生物分析相关代码集合官网 Biopython：Biopython 是一组可以免费使用的用来进行生物计算的工具。官网 blaze：NumPy 和 Pandas 的大数据接口。官网 cclib：一个用来解析和解释计算化学软件包输出结果的库。官网 NetworkX：一个为复杂网络设计的高性能软件。官网 Neupy：执行和测试各种不同的人工神经网络算法。官网 Numba：Python JIT (just in time) 编译器，针对科学用的 Python ，由Cython 和 NumPy 的开发者开发。官网 NumPy：使用 Python 进行科学计算的基础包。官网 Open Babel：一个化学工具箱，用来描述多种化学数据。官网 Open Mining：使用 Python 挖掘商业情报 (BI) (Pandas web 接口)。官网 orange：通过可视化编程或 Python 脚本进行数据挖掘，数据可视化，分析和机器学习。官网 Pandas：提供高性能，易用的数据结构和数据分析工具。官网 PyDy：PyDy 是 Python Dynamics 的缩写，用来为动力学运动建模工作流程提供帮助， 基于 NumPy, SciPy, IPython 和 matplotlib。官网 PyMC：马尔科夫链蒙特卡洛采样工具。官网 RDKit：化学信息学和机器学习软件。官网 SciPy：由一些基于 Python ，用于数学，科学和工程的开源软件构成的生态系统。官网 statsmodels：统计建模和计量经济学。官网 SymPy：一个用于符号数学的 Python 库。官网 zipline：一个 Python 算法交易库。官网 Bayesian-belief-networks：优雅的贝叶斯信念网络框架。官网 数据可视化进行数据可视化的库。 参见: awesome-javascript。 matplotlib：一个 Python 2D 绘图库。官网 bokeh：用 Python 进行交互式 web 绘图。官网 ggplot：ggplot2 给 R 提供的 API 的 Python 版本。官网 plotly：协同 Python 和 matplotlib 工作的 web 绘图库。官网 pygal：一个 Python SVG 图表创建工具。官网 pygraphviz：Graphviz 的 Python 接口。官网 PyQtGraph：交互式实时2D/3D/图像绘制及科学/工程学组件。官网 SnakeViz：一个基于浏览器的 Python’s cProfile 模块输出结果查看工具。官网 vincent：把 Python 转换为 Vega 语法的转换工具。官网 VisPy：基于 OpenGL 的高性能科学可视化工具。官网 计算机视觉计算机视觉库。 OpenCV：开源计算机视觉库。官网 SimpleCV：一个用来创建计算机视觉应用的开源框架。官网 机器学习机器学习库。 参见: awesome-machine-learning. Crab：灵活、快速的推荐引擎。官网 gensim：人性化的话题建模库。官网 hebel：GPU 加速的深度学习库。官网 NuPIC：智能计算 Numenta 平台。官网 pattern：Python 网络挖掘模块。官网 PyBrain：另一个 Python 机器学习库。官网 Pylearn2：一个基于 Theano 的机器学习库。官网 python-recsys：一个用来实现推荐系统的 Python 库。官网 scikit-learn：基于 SciPy 构建的机器学习 Python 模块。官网 pydeep：Python 深度学习库。官网 vowpalporpoise：轻量级 Vowpal Wabbit 的 Python 封装。官网 skflow：一个 TensorFlow 的简化接口(模仿 scikit-learn)。官网 MapReduceMapReduce 框架和库。 dpark：Spark 的 Python 克隆版，一个类似 MapReduce 的框架。官网 dumbo：这个 Python 模块可以让人轻松的编写和运行 Hadoop 程序。官网 luigi：这个模块帮你构建批处理作业的复杂流水线。官网 mrjob：在 Hadoop 或 Amazon Web Services 上运行 MapReduce 任务。官网 PySpark：Spark 的 Python API 。官网 streamparse：运行针对事实数据流的 Python 代码。集成了Apache Storm。官网 函数式编程使用 Python 进行函数式编程。 CyToolz：Toolz 的 Cython 实现 : 高性能函数式工具。官网 fn.py：在 Python 中进行函数式编程 : 实现了一些享受函数式编程缺失的功能。官网 funcy：炫酷又实用的函数式工具。官网 Toolz：一组用于迭代器，函数和字典的函数式编程工具。官网 第三方 API用来访问第三方 API的库。 参见： List of Python API Wrappers and Libraries。 apache-libcloud：一个为各种云设计的 Python 库。官网 boto：Amazon Web Services 的 Python 接口。官网 django-wordpress：WordPress models and views for Django.官网 facebook-sdk：Facebook 平台的 Python SDK.官网 facepy：Facepy 让和 Facebook’s Graph API 的交互变得更容易。官网 gmail：Gmail 的 Python 接口。官网 google-api-python-client：Python 用的 Google APIs 客户端库。官网 gspread：Google 电子表格的 Python API.官网 twython：Twitter API 的封装。官网 DevOps 工具用于 DevOps 的软件和库。 Ansible：一个非常简单的 IT 自动化平台。官网 SaltStack：基础设施自动化和管理系统。官网 OpenStack：用于构建私有和公有云的开源软件。官网 Docker Compose：快速，分离的开发环境，使用 Docker。官网 Fabric：一个简单的，Python 风格的工具，用来进行远程执行和部署。官网 cuisine：为 Fabric 提供一系列高级函数。官网 Fabtools：一个用来编写超赞的 Fabric 文件的工具。官网 gitapi：Git 的纯 Python API。官网 hgapi：Mercurial 的纯 Python API。官网 honcho：Foreman的 Python 克隆版，用来管理基于Procfile的应用。官网 pexpect：Controlling interactive programs in a pseudo-terminal like 在一个伪终端中控制交互程序，就像 GNU expect 一样。官网 psutil：一个跨平台进程和系统工具模块。官网 supervisor：UNIX 的进程控制系统。官网 任务调度任务调度库。 APScheduler：轻巧但强大的进程内任务调度，使你可以调度函数。官网 django-schedule：一个 Django 排程应用。官网 doit：一个任务执行和构建工具。官网 gunnery：分布式系统使用的多用途任务执行工具 ，具有 web 交互界面。官网 Joblib：一组为 Python 提供轻量级作业流水线的工具。官网 Plan：如有神助地编写 crontab 文件。官网 schedule：人性化的 Python 任务调度库。官网 Spiff：使用纯 Python 实现的强大的工作流引擎。官网 TaskFlow：一个可以让你方便执行任务的 Python 库，一致并且可靠。官网 外来函数接口使用外来函数接口的库。 cffi：用来调用 C 代码的外来函数接口。官网 ctypes：(Python 标准库) 用来调用 C 代码的外来函数接口。官网 PyCUDA：Nvidia CUDA API 的封装。官网 SWIG：简化的封装和接口生成器。官网 高性能让 Python 更快的库。 Cython：优化的 Python 静态编译器。使用类型混合使 Python 编译成 C 或 C++ 模块来获得性能的极大提升。官网 PeachPy：嵌入 Python 的 x86-64 汇编器。可以被用作 Python 内联的汇编器或者是独立的汇编器，用于 Windows, Linux, OS X, Native Client 或者 Go 。官网 PyPy：使用 Python 实现的 Python。解释器使用黑魔法加快 Python 运行速度且不需要加入额外的类型信息。官网 Pyston：使用 LLVM 和现代 JIT 技术构建的 Python 实现，目标是为了获得很好的性能。官网 Stackless Python：一个强化版的 Python。官网 微软的 Windows平台在 Windows 平台上进行 Python 编程。 Python(x,y)：面向科学应用的 Python 发行版，基于 Qt 和 Spyder。官网 pythonlibs：非官方的 Windows 平台 Python 扩展二进制包。官网 PythonNet：Python 与 .NET 公共语言运行库 (CLR)的集成。官网 PyWin32：针对 Windows 的Python 扩展。官网 WinPython：Windows 7/8 系统下便携式开发环境。官网 网络可视化和SDN用来进行网络可视化和SDN(软件定义网络)的工具和库。 Mininet：一款流行的网络模拟器以及用 Python 编写的 API。官网 POX：一个针对基于 Python 的软件定义网络应用（例如 OpenFlow SDN 控制器）的开源开发平台。官网 Pyretic：火热的 SDN 编程语言中的一员，为网络交换机和模拟器提供强大的抽象能力。官网 SDX Platform：基于 SDN 的 IXP 实现，影响了 Mininet, POX 和 Pyretic。官网 硬件用来对硬件进行编程的库。 ino：操作Arduino的命令行工具。官网 Pyro：Python 机器人编程库。官网 PyUserInput：跨平台的，控制鼠标和键盘的模块。官网 scapy：一个非常棒的操作数据包的库。官网 wifi：一个 Python 库和命令行工具用来在 Linux 平台上操作WiFi。官网 Pingo：Pingo 为类似Raspberry Pi，pcDuino， Intel Galileo等设备提供统一的API用以编程。官网 兼容性帮助从 Python 2 向 Python 3迁移的库。 Python-Future：这就是 Python 2 和 Python 3 之间丢失的那个兼容性层。官网 Python-Modernize：使 Python 代码更加现代化以便最终迁移到 Python 3。官网 Six：Python 2 和 3 的兼容性工具。官网 杂项不属于上面任何一个类别，但是非常有用的库。 blinker：一个快速的 Python 进程内信号/事件分发系统。官网 itsdangerous：一系列辅助工具用来将可信的数据传入不可信的环境。官网 pluginbase：一个简单但是非常灵活的 Python 插件系统。官网 Pychievements：一个用来创建和追踪成就的 Python 框架。官网 Tryton：一个通用商务框架。官网 算法和设计模式Python 实现的算法和设计模式。 algorithms：一个 Python 算法模块。官网 python-patterns：Python 设计模式的集合。官网 sortedcontainers：快速，纯 Python 实现的SortedList，SortedDict 和 SortedSet 类型。官网 编辑器插件编辑器和 IDE 的插件 Emacs Elpy：Emacs Python 开发环境。官网 Sublime Text SublimeJEDI：一个 Sublime Text 插件，用来使用超赞的自动补全库 Jedi。官网 Anaconda：Anaconda 把你的 Sublime Text 3 变成一个功能齐全的 Python IDE。官网 Vim YouCompleteMe：引入基于 Jedi 的 Python 自动补全引擎。官网 Jedi-vim：绑定 Vim 和 Jedi 自动补全库对 Python 进行自动补全。官网 Python-mode：将 Vim 变成 Python IDE 的一款多合一插件。官网 Visual Studio PTVS：Visual Studio 的 Python 工具官网 集成开发环境流行的 Python 集成开发环境。 PyCharm：商业化的 Python IDE ，由 JetBrains 开发。也有免费的社区版提供。官网 LiClipse：基于 Eclipse 的免费多语言 IDE 。使用 PyDev 来支持 Python 。官网 Spyder：开源 Python IDE。官网 服务在线工具和简化开发的 API 。 持续集成参见: awesome-CIandCD. Travis CI：一个流行的工具，为你的开源和私人项目提供持续集成服务。(仅支持 GitHub)官网 CircleCI：一个持续集成工具，可以非常快速的进行并行测试。 (仅支持 GitHub)官网 Vexor CI：一个为私人 app 提供持续集成的工具，支持按分钟付费。官网 Wercker：基于 Docker 平台，用来构建和部署微服务。官网 代码质量 Codacy：自动化代码审查，更加快速的发布高质量代码。对于开源项目是免费的。官网 QuantifiedCode：一个数据驱动、自动、持续的代码审查工具。官网 资源在这里可以找到新的 Python 库。 网站 r/Python CoolGithubProjects Django Packages Full Stack Python Python 3 Wall of Superpowers Python Hackers Python ZEEF Trending Python repositories on GitHub today PyPI Ranking 周刊 Import Python Newsletter Pycoder’s Weekly Python Weekly Twitter @codetengu @getpy @planetpython @pycoders @pypi @pythontrending @PythonWeekly 学习指南 Scipy-lecture-notes：如何用Python来做学术？官网 SScientific-python-lectures：Python科学计算的资料。官网 Mario-Level-1：用Python和Pygame写的超级马里奥第一关。官网 Python Koans：Python的交互式学习工具。官网 Minecraft：用python写的Minecraft游戏。官网 pycrumbs：Python资源大全。官网 python-patterns：使用python实现设计模式。官网 Projects：Python项目大集合。官网 The Hitchhiker’s Guide to Python：旅行者的Python学习指南。官网 Code Like a Pythonista: Idiomatic Python：如何像Python高手(Pythonista)一样编程。官网 知名网站值得关注的 Python 技术站点。 中文站点 伯乐在线 Python 频道：分享 Python 开发技术、相关的行业动态。官网 英文站点 《值得关注的 10 个 Python 英文博客》 微博、微信公众号 Python开发者 微博：@Python开发者 Python开发者：人生苦短，我用 Python。Python 越来越受广大程序员的喜爱。「Python开发者」是最受欢迎的、专注分享Python技术的微信公众号，主要分享 Python 相关的技术文章、工具资源和资讯等。","raw":null,"content":null,"categories":[],"tags":[]},{"title":"xx-net 使用方法","slug":"xxnet","date":"2016-12-17T05:13:13.000Z","updated":"2016-12-19T05:13:13.000Z","comments":true,"path":"xxnet.html/","link":"","permalink":"http://yusank.github.io/xxnet.html/","excerpt":"","text":"注意： 由于封锁严重，软件自带IP已经被封杀殆尽。因此需要数分钟到数小时的初始化IP扫描，方能正常运行。 虽然系统内置了公共appid, 还是建议[[部署自己的appid|how to create my appids]]，公共appid限制看视频。需要注意的是，只有当你能访问Google之后，才能部署自己的APPID。 概述总体来说，使用XX-Net科学上网，大致需要如下步骤： [[获取XX-Net|https://github.com/XX-net/XX-Net/blob/master/code/default/download.md]] 设置和初始化：安装、设置完成后，如果无法翻墙，则需要等待后台程序扫描IP（10分钟到数小时）。 [可选][[创建和使用自己的appid|how to create my appids]] [[设置代理]] [强烈建议]获取和配置可靠的浏览器（[[Firefox火狐浏览器|使用Firefox浏览器]]，或[[Chrome谷歌浏览器|使用Chrome浏览器]]），并使用[[代理切换插件|安装和使用-SwitchyOmega]]。 下面分别介绍各个操作系统平台下的使用方法： Windows系统 双击 start.vbs或者start.bat启动。 Win7/8/10：将提示请求管理员权限（出于[[安装CA证书|GoAgent Import CA]]的需要）。请点击同意。 启动完毕后，将弹出浏览器，访问 http://localhost:8085/ （[[配置页面简介]]） 右下角将出现托盘图标：点击可弹出上述的XX-Net配置页面, 右键可显示[[常用功能菜单|托盘右键菜单]]。 第一次启动, 会提示在桌面建立快捷方式,可根据自己需要选择。 推荐[[使用Chrome浏览器]], [[安装SwichySharp|安装和使用SwichySharp]], 可在XX-Net目录中的SwitchySharp文件夹下找到插件和配置文件。 也可以选择[[使用Firefox（火狐）浏览器|使用Firefox浏览器]]。需[[手动导入证书|GoAgent Import CA#Firefox浏览器手动导入的方式]] 启动失败，请关闭后双击start.bat再次启动程序，把日志发到bug反馈区 WinXP，需要破解tcp连接数，推荐使用tcp-z Win8，win10 的APP，需要使用：https://loopback.codeplex.com/ Windows Server 2008，需要安装 Visual C++ 2008 Redistributable - x86 针对两种常用浏览器，分别有详细的新手图文教程：[[使用Firefox浏览器]]、[[使用Chrome浏览器]] Mac系统 双击 start 启动 证书将被自动导入，如果还有提示非安全连接，请手动导入data/gae_proxy/CA.crt证书 注： 命令行启动方式：./start 推荐[[使用Chrome|使用Chrome浏览器]]和[[SwitchyOmega扩展|安装和使用SwichySharp]] 部分版本可能需要手动升级python。命令为：brew upgrade Linux系统 执行 ./start 启动 自动导入证书，需安装 libnss3-tools 包sudo apt-get install libnss3-tools 没有安装PyGtk的，需要先安装gtk：sudo apt-get install python-gtk2 配置http代理 localhost 8087, 勾选全部协议使用这个代理。如Firefox，如果管理页面弹不出，请在地址栏输入127.0.0.1:8085，注意和代理端口的区别：推荐Chrome + SwitchyOmega ubuntu 下，可能需要安装 sudo apt-get install python-openssl sudo apt-get install libffi-dev sudo apt-get install -y python-gtk2 sudo apt-get install python-appindicator sudo apt-get install libnss3-tools 后台运行：在终端中运行： code/default/xx_net.sh start/stop/restart 开机自启：在/etc/rc.local中添加一行： sudo /home/username/xxnet/code/default/xx_net.sh start 关于 ArchLinux 可能需要的包: python-pyopenssl python2-pyopenssl libffi pygtk python2-notify nss 关于 Fedora 添加 FZUG 源，安装 xx-net 执行 xx-net 或 systemctl --user start xx-net (后台)启动 配置浏览器代理插件 其他平台OpenWrt [[在OpenWrt里运行XX-Net]] [[在装有梅林固件的Netgear R6300V2上安装XX Net]] Android 计划开发中 [[Android技术设计]] 附录关于服务端 服务端兼容 GoAgent 3.1.x/3.2.x的客户端 虽然系统内置了公共appid, 还是建议[[部署自己的appid|how to create my appids]]。 异常处理如果出现异常，请翻阅[[故障速查手册]]，查看常见问题和解决方法。 无法解决的，参考[[异常处理|How-to-get-start-error-log]]，将问题反馈到：https://github.com/XX-net/XX-Net/issueshttps://groups.google.com/forum/#!forum/xx-net 提交issue时请贴出状态页、GAE_proxy日志、部署日志，以便开发者和其他用户更好地帮助你。","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2016-12-16T12:12:02.000Z","updated":"2016-12-16T12:12:02.000Z","comments":true,"path":"hello-world.html/","link":"","permalink":"http://yusank.github.io/hello-world.html/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","raw":null,"content":null,"categories":[],"tags":[]}]}